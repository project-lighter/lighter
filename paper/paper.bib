@software{Falcon_PyTorch_Lightning_2019,
    author = {Falcon, William and {The PyTorch Lightning team}},
    doi = {10.5281/zenodo.3828935},
    license = {Apache-2.0},
    month = mar,
    title = {{PyTorch Lightning}},
    url = {https://github.com/Lightning-AI/lightning},
    version = {1.4},
    year = {2019}
}

@article{Cardoso_MONAI_An_open-source_2022,
    author = {Cardoso, M. Jorge and Li, Wenqi and Brown, Richard and Ma, Nic and Kerfoot, Eric and Wang, Yiheng and Murray, Benjamin and Myronenko, Andriy and Zhao, Can and Yang, Dong and Nath, Vishwesh and He, Yufan and Xu, Ziyue and Hatamizadeh, Ali and Zhu, Wentao and Liu, Yun and Zheng, Mingxin and Tang, Yucheng and Yang, Isaac and Zephyr, Michael and Hashemian, Behrooz and Alle, Sachidanand and Zalbagi Darestani, Mohammad and Budd, Charlie and Modat, Marc and Vercauteren, Tom and Wang, Guotai and Li, Yiwen and Hu, Yipeng and Fu, Yunguan and Gorman, Benjamin and Johnson, Hans and Genereaux, Brad and Erdal, Barbaros S. and Gupta, Vikash and Diaz-Pinto, Andres and Dourson, Andre and Maier-Hein, Lena and Jaeger, Paul F. and Baumgartner, Michael and Kalpathy-Cramer, Jayashree and Flores, Mona and Kirby, Justin and Cooper, Lee A.D. and Roth, Holger R. and Xu, Daguang and Bericat, David and Floca, Ralf and Zhou, S. Kevin and Shuaib, Haris and Farahani, Keyvan and Maier-Hein, Klaus H. and Aylward, Stephen and Dogra, Prerna and Ourselin, Sebastien and Feng, Andrew},
    doi = {10.48550/arXiv.2211.02701},
    month = nov,
    title = {{MONAI: An open-source framework for deep learning in healthcare}},
    year = {2022}
}

@article{Pai2024,
  title     = "Foundation model for cancer imaging biomarkers",
  author    = "Pai, Suraj and Bontempi, Dennis and Hadzic, Ibrahim and
               Prudente, Vasco and Soka{\v c}, Mateo and Chaunzwa, Tafadzwa L
               and Bernatz, Simon and Hosny, Ahmed and Mak, Raymond H and
               Birkbak, Nicolai J and Aerts, Hugo J W L",
  abstract  = "Foundation models in deep learning are characterized by a single
               large-scale model trained on vast amounts of data serving as the
               foundation for various downstream tasks. Foundation models are
               generally trained using self-supervised learning and excel in
               reducing the demand for training samples in downstream
               applications. This is especially important in medicine, where
               large labelled datasets are often scarce. Here, we developed a
               foundation model for cancer imaging biomarker discovery by
               training a convolutional encoder through self-supervised
               learning using a comprehensive dataset of 11,467 radiographic
               lesions. The foundation model was evaluated in distinct and
               clinically relevant applications of cancer imaging-based
               biomarkers. We found that it facilitated better and more
               efficient learning of imaging biomarkers and yielded
               task-specific models that significantly outperformed
               conventional supervised and other state-of-the-art pretrained
               implementations on downstream tasks, especially when training
               dataset sizes were very limited. Furthermore, the foundation
               model was more stable to input variations and showed strong
               associations with underlying biology. Our results demonstrate
               the tremendous potential of foundation models in discovering new
               imaging biomarkers that may extend to other clinical use cases
               and can accelerate the widespread translation of imaging
               biomarkers into clinical settings.",
  journal   = "Nat. Mach. Intell.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  6,
  number    =  3,
  pages     = "354--367",
  month     =  mar,
  year      =  2024,
  keywords  = "Biomarkers; Cancer imaging; Tumour biomarkers",
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en",
  doi       = {10.1038/s42256-024-00807-9}
}

@ARTICLE{Pai2025,
  title        = "Vision foundation models for computed tomography",
  author       = "Pai, Suraj and Hadzic, Ibrahim and Bontempi, Dennis and
                  Bressem, Keno and Kann, Benjamin H and Fedorov, Andriy and
                  Mak, Raymond H and Aerts, Hugo J W L",
  abstract     = "Foundation models (FMs) have shown transformative potential
                  in radiology by performing diverse, complex tasks across
                  imaging modalities. Here, we developed CT-FM, a large-scale
                  3D image-based pre-trained model designed explicitly for
                  various radiological tasks. CT-FM was pre-trained using
                  148,000 computed tomography (CT) scans from the Imaging Data
                  Commons through label-agnostic contrastive learning. We
                  evaluated CT-FM across four categories of tasks, namely,
                  whole-body and tumor segmentation, head CT triage, medical
                  image retrieval, and semantic understanding, showing superior
                  performance against state-of-the-art models. Beyond
                  quantitative success, CT-FM demonstrated the ability to
                  cluster regions anatomically and identify similar anatomical
                  and structural concepts across scans. Furthermore, it
                  remained robust across test-retest settings and indicated
                  reasonable salient regions attached to its embeddings. This
                  study demonstrates the value of large-scale medical imaging
                  foundation models and by open-sourcing the model weights,
                  code, and data, aims to support more adaptable, reliable, and
                  interpretable AI solutions in radiology.",
  year         =  2025,
  primaryClass = "eess.IV",
  eprint       = "2501.09001",
  doi          = {10.48550/arXiv.2501.09001}
}

@article{Ludwig,
  author       = {Piero Molino and
                  Yaroslav Dudin and
                  Sai Sumanth Miryala},
  title        = {Ludwig: a type-based declarative deep learning toolbox},
  journal      = {CoRR},
  volume       = {abs/1909.07930},
  year         = {2019},
  url          = {http://arxiv.org/abs/1909.07930},
  eprinttype    = {arXiv},
  eprint       = {1909.07930},
  timestamp    = {Tue, 24 Sep 2019 11:33:51 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1909-07930.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@software{Quadra,
	title = {orobix/quadra},
	url = {https://github.com/orobix/quadra},
	author = {Mammana, Lorenzo and Malli, Refik Can and Polidori, Alessandro and ebernatene},
	date = {2025-05-20},
	year = {2025},
	month = {5},
	day = {20},
}

@article{Gandlf,
    author={Pati, Sarthak and Thakur, Siddhesh P. and Hamamc{\i}, {\.{I}}brahim Ethem and Baid, Ujjwal and Baheti, Bhakti and Bhalerao, Megh and G{\"u}ley, Orhun and Mouchtaris, Sofia and Lang, David and Thermos, Spyridon and Gotkowski, Karol and Gonz{\'a}lez, Camila and Grenko, Caleb and Getka, Alexander and Edwards, Brandon and Sheller, Micah and Wu, Junwen and Karkada, Deepthi and Panchumarthy, Ravi and Ahluwalia, Vinayak and Zou, Chunrui and Bashyam, Vishnu and Li, Yuemeng and Haghighi, Babak and Chitalia, Rhea and Abousamra, Shahira and Kurc, Tahsin M. and Gastounioti, Aimilia and Er, Sezgin and Bergman, Mark and Saltz, Joel H. and Fan, Yong and Shah, Prashant and Mukhopadhyay, Anirban and Tsaftaris, Sotirios A. and Menze, Bjoern and Davatzikos, Christos and Kontos, Despina and Karargyris, Alexandros and Umeton, Renato and Mattson, Peter and Bakas, Spyridon},
    title={GaNDLF: the generally nuanced deep learning framework for scalable end-to-end clinical workflows},
    journal={Communications Engineering},
    year={2023},
    month={May},
    day={16},
    volume={2},
    number={1},
    pages={23},
    abstract={Deep Learning (DL) has the potential to optimize machine learning in both the scientific and clinical communities. However, greater expertise is required to develop DL algorithms, and the variability of implementations hinders their reproducibility, translation, and deployment. Here we present the community-driven Generally Nuanced Deep Learning Framework (GaNDLF), with the goal of lowering these barriers. GaNDLF makes the mechanism of DL development, training, and inference more stable, reproducible, interpretable, and scalable, without requiring an extensive technical background. GaNDLF aims to provide an end-to-end solution for all DL-related tasks in computational precision medicine. We demonstrate the ability of GaNDLF to analyze both radiology and histology images, with built-in support for k-fold cross-validation, data augmentation, multiple modalities and output classes. Our quantitative performance evaluation on numerous use cases, anatomies, and computational tasks supports GaNDLF as a robust application framework for deployment in clinical workflows.},
    issn={2731-3395},
    doi={10.1038/s44172-023-00066-3},
    url={https://doi.org/10.1038/s44172-023-00066-3}
}
