@software{Falcon_PyTorch_Lightning_2019,
    author = {Falcon, William and {The PyTorch Lightning team}},
    doi = {10.5281/zenodo.3828935},
    license = {Apache-2.0},
    month = mar,
    title = {{PyTorch Lightning}},
    url = {https://github.com/Lightning-AI/lightning},
    version = {1.4},
    year = {2019}
}

@article{Cardoso_MONAI_An_open-source_2022,
    author = {Cardoso, M. Jorge and Li, Wenqi and Brown, Richard and Ma, Nic and Kerfoot, Eric and Wang, Yiheng and Murray, Benjamin and Myronenko, Andriy and Zhao, Can and Yang, Dong and Nath, Vishwesh and He, Yufan and Xu, Ziyue and Hatamizadeh, Ali and Zhu, Wentao and Liu, Yun and Zheng, Mingxin and Tang, Yucheng and Yang, Isaac and Zephyr, Michael and Hashemian, Behrooz and Alle, Sachidanand and Zalbagi Darestani, Mohammad and Budd, Charlie and Modat, Marc and Vercauteren, Tom and Wang, Guotai and Li, Yiwen and Hu, Yipeng and Fu, Yunguan and Gorman, Benjamin and Johnson, Hans and Genereaux, Brad and Erdal, Barbaros S. and Gupta, Vikash and Diaz-Pinto, Andres and Dourson, Andre and Maier-Hein, Lena and Jaeger, Paul F. and Baumgartner, Michael and Kalpathy-Cramer, Jayashree and Flores, Mona and Kirby, Justin and Cooper, Lee A.D. and Roth, Holger R. and Xu, Daguang and Bericat, David and Floca, Ralf and Zhou, S. Kevin and Shuaib, Haris and Farahani, Keyvan and Maier-Hein, Klaus H. and Aylward, Stephen and Dogra, Prerna and Ourselin, Sebastien and Feng, Andrew},
    doi = {https://doi.org/10.48550/arXiv.2211.02701},
    month = nov,
    title = {{MONAI: An open-source framework for deep learning in healthcare}},
    year = {2022}
}

@article{Pai2024,
  title     = "Foundation model for cancer imaging biomarkers",
  author    = "Pai, Suraj and Bontempi, Dennis and Hadzic, Ibrahim and
               Prudente, Vasco and Soka{\v c}, Mateo and Chaunzwa, Tafadzwa L
               and Bernatz, Simon and Hosny, Ahmed and Mak, Raymond H and
               Birkbak, Nicolai J and Aerts, Hugo J W L",
  abstract  = "Foundation models in deep learning are characterized by a single
               large-scale model trained on vast amounts of data serving as the
               foundation for various downstream tasks. Foundation models are
               generally trained using self-supervised learning and excel in
               reducing the demand for training samples in downstream
               applications. This is especially important in medicine, where
               large labelled datasets are often scarce. Here, we developed a
               foundation model for cancer imaging biomarker discovery by
               training a convolutional encoder through self-supervised
               learning using a comprehensive dataset of 11,467 radiographic
               lesions. The foundation model was evaluated in distinct and
               clinically relevant applications of cancer imaging-based
               biomarkers. We found that it facilitated better and more
               efficient learning of imaging biomarkers and yielded
               task-specific models that significantly outperformed
               conventional supervised and other state-of-the-art pretrained
               implementations on downstream tasks, especially when training
               dataset sizes were very limited. Furthermore, the foundation
               model was more stable to input variations and showed strong
               associations with underlying biology. Our results demonstrate
               the tremendous potential of foundation models in discovering new
               imaging biomarkers that may extend to other clinical use cases
               and can accelerate the widespread translation of imaging
               biomarkers into clinical settings.",
  journal   = "Nat. Mach. Intell.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  6,
  number    =  3,
  pages     = "354--367",
  month     =  mar,
  year      =  2024,
  keywords  = "Biomarkers; Cancer imaging; Tumour biomarkers",
  copyright = "https://creativecommons.org/licenses/by/4.0",
  language  = "en"
}

@ARTICLE{Pai2025,
  title        = "Vision foundation models for computed tomography",
  author       = "Pai, Suraj and Hadzic, Ibrahim and Bontempi, Dennis and
                  Bressem, Keno and Kann, Benjamin H and Fedorov, Andriy and
                  Mak, Raymond H and Aerts, Hugo J W L",
  abstract     = "Foundation models (FMs) have shown transformative potential
                  in radiology by performing diverse, complex tasks across
                  imaging modalities. Here, we developed CT-FM, a large-scale
                  3D image-based pre-trained model designed explicitly for
                  various radiological tasks. CT-FM was pre-trained using
                  148,000 computed tomography (CT) scans from the Imaging Data
                  Commons through label-agnostic contrastive learning. We
                  evaluated CT-FM across four categories of tasks, namely,
                  whole-body and tumor segmentation, head CT triage, medical
                  image retrieval, and semantic understanding, showing superior
                  performance against state-of-the-art models. Beyond
                  quantitative success, CT-FM demonstrated the ability to
                  cluster regions anatomically and identify similar anatomical
                  and structural concepts across scans. Furthermore, it
                  remained robust across test-retest settings and indicated
                  reasonable salient regions attached to its embeddings. This
                  study demonstrates the value of large-scale medical imaging
                  foundation models and by open-sourcing the model weights,
                  code, and data, aims to support more adaptable, reliable, and
                  interpretable AI solutions in radiology.",
  year         =  2025,
  primaryClass = "eess.IV",
  eprint       = "2501.09001"
}
