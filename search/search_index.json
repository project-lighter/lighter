{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lighter","text":""},{"location":"#_1","title":"Lighter","text":"<pre><code>pip install lighter\n</code></pre> <ul> <li> <p> From Idea to Experiment in Seconds</p> <p>No boilerplate. No training loops. Just define your model, data, and optimizer in YAML and run <code>lighter fit config.yaml</code>.</p> </li> <li> <p> 100% Reproducible</p> <p>Every experiment is a YAML file. Version control configs like code. Share experiments with collaborators. No hidden state.</p> </li> <li> <p> Hyperparameter Sweeps Made Easy</p> <p>Override any parameter from CLI: <code>lighter fit config.yaml system::optimizer::lr=0.01</code>. Run 100 experiments without editing files.</p> </li> <li> <p> Task-Agnostic Adapters</p> <p>Classification, segmentation, or self-supervised learning? Adapters handle any data format. One system, unlimited tasks.</p> </li> <li> <p> ~1,000 Lines of Code</p> <p>Read the entire framework in an afternoon. Debug easily. Understand exactly what's happening. No magic.</p> </li> <li> <p> Built on PyTorch Lightning</p> <p>Multi-GPU, mixed precision, gradient accumulation, profiling\u2014all Lightning features work out of the box.</p> </li> </ul>"},{"location":"#quick-start-60-seconds","title":"Quick Start: 60 Seconds","text":"<ol> <li> <p>Install Lighter</p> <pre><code>pip install lighter\n</code></pre> </li> <li> <p>Create a config (<code>config.yaml</code>)</p> <pre><code>trainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 10\n\nsystem:\n  _target_: lighter.System\n  model:\n    _target_: torchvision.models.resnet18\n    num_classes: 10\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n  dataloaders:\n    train: # (1)!\n      _target_: torch.utils.data.DataLoader\n      batch_size: 32\n      dataset:\n        _target_: torchvision.datasets.CIFAR10\n        root: ./data\n        train: true\n        download: true\n        transform:\n          _target_: torchvision.transforms.ToTensor\n</code></pre> <ol> <li>Define your data like any PyTorch component</li> </ol> </li> <li> <p>Run training</p> <pre><code>lighter fit config.yaml\n</code></pre> </li> </ol> <p>That's it. Automatic training loops, validation, checkpointing, and logging.</p> <p>Experiment with different hyperparameters</p> <pre><code># Change learning rate without editing files\nlighter fit config.yaml system::optimizer::lr=0.01\n\n# Train longer\nlighter fit config.yaml trainer::max_epochs=100\n\n# Use multiple GPUs\nlighter fit config.yaml trainer::devices=4\n</code></pre>"},{"location":"#lighter-vs-pytorch-lightning","title":"Lighter vs. PyTorch Lightning","text":"<p>Same Power, Different Interface</p> <p>Lighter uses PyTorch Lightning under the hood. You get all Lightning features (multi-GPU, callbacks, profilers) but define experiments in YAML instead of Python classes.</p> <p>See how training a model on CIFAR-10 differs:</p> LighterPyTorch Lightning Terminal<pre><code>lighter fit config.yaml\n</code></pre> config.yaml<pre><code>trainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 2\n\nsystem:\n  _target_: lighter.System\n\n  model:\n    _target_: torchvision.models.resnet18\n    num_classes: 10\n\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n\n  dataloaders:\n    train:\n      _target_: torch.utils.data.DataLoader\n      batch_size: 32\n      shuffle: true\n      dataset:\n        _target_: torchvision.datasets.CIFAR10\n        download: true\n        root: .datasets\n        train: true\n        transform:\n          _target_: torchvision.transforms.Compose\n          transforms:\n            - _target_: torchvision.transforms.ToTensor\n            - _target_: torchvision.transforms.Normalize\n              mean: [0.5, 0.5, 0.5]\n              std: [0.5, 0.5, 0.5]\n</code></pre> <p>Benefits:</p> <ul> <li> Experiment is self-documenting</li> <li> Change hyperparameters from CLI without editing files</li> <li> Version control and compare configs with git diff</li> <li> Share experiments as single files</li> </ul> Terminal<pre><code>python cifar10.py\n</code></pre> cifar10.py<pre><code>from pytorch_lightning import Trainer, LightningModule\nfrom torch.nn import CrossEntropyLoss\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom torchvision.models import resnet18\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor, Normalize, Compose\n\n\nclass Model(LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = resnet18(num_classes=10)\n        self.criterion = CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y)\n        return loss\n\n    def configure_optimizers(self):\n        return Adam(self.model.parameters(), lr=0.001)\n\n\ntransform = Compose([\n    ToTensor(),\n    Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n])\n\ntrain_dataset = CIFAR10(\n    root=\".datasets\",\n    train=True,\n    download=True,\n    transform=transform\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\nmodel = Model()\ntrainer = Trainer(max_epochs=2)\ntrainer.fit(model, train_loader)\n</code></pre> <p>Challenges:</p> <ul> <li> Need to edit Python code for hyperparameter changes</li> <li> Harder to compare experiments (code vs config)</li> <li> More boilerplate for each experiment</li> </ul>"},{"location":"#who-should-use-lighter","title":"Who Should Use Lighter?","text":""},{"location":"#perfect-for","title":"Perfect For","text":"<ul> <li>Researchers running many experiments with hyperparameter variations</li> <li>Teams sharing reproducible experiments and baselines</li> <li>Engineers who value configuration over code for ML pipelines</li> <li>Anyone tired of writing boilerplate training loops</li> </ul> <p>Get Started \u2192</p>"},{"location":"#consider-alternatives-if","title":"Consider Alternatives If","text":"<ul> <li>You need highly custom training loops with exotic logic</li> <li>You prefer pure Python workflows without YAML</li> <li>You're doing rapid prototyping where code is faster than config</li> <li>Your project has few experimental variations</li> </ul> <p>Compare Frameworks \u2192</p>"},{"location":"#key-features-in-depth","title":"Key Features in Depth","text":""},{"location":"#configuration-driven-everything","title":"Configuration-Driven Everything","text":"<p>Every component is defined in YAML. Model, optimizer, scheduler, metrics, data\u2014all configurable.</p> <pre><code># Differential learning rates? Easy.\noptimizer:\n  _target_: torch.optim.SGD\n  params:\n    - params: \"$@system::model.backbone.parameters()\"\n      lr: 0.0001  # Low LR for pretrained backbone\n    - params: \"$@system::model.head.parameters()\"\n      lr: 0.01    # High LR for new head\n</code></pre> <p>Learn Config Syntax \u2192</p>"},{"location":"#task-agnostic-adapters","title":"Task-Agnostic Adapters","text":"<p>Adapters transform data between pipeline stages. This makes Lighter work for any task.</p> <pre><code># Dict-based dataset? No problem.\nsystem:\n  adapters:\n    train:\n      batch:\n        _target_: lighter.adapters.BatchAdapter\n        input_accessor: \"image\"   # Extract from dict\n        target_accessor: \"label\"\n</code></pre> <p>Classification, segmentation, detection, self-supervised learning\u2014adapters handle it all.</p> <p>Learn About Adapters \u2192</p>"},{"location":"#built-on-solid-foundations","title":"Built on Solid Foundations","text":"<ul> <li>PyTorch Lightning - Battle-tested training engine with multi-GPU, profiling, callbacks</li> <li>Sparkwheel - Powerful config system with references, expressions, and validation</li> <li>~1,000 lines - Read the entire framework, understand exactly what's happening</li> </ul> <p>Architecture Deep Dive \u2192</p>"},{"location":"#choose-your-path","title":"Choose Your Path","text":"<ul> <li> <p> New to Lighter?</p> <p>Start here: Follow our comprehensive tutorial from installation to running your first experiments.</p> <p>Time: 15 minutes</p> <p> Get Started Tutorial</p> </li> <li> <p> PyTorch Lightning User?</p> <p>Migration guide: Translate your existing Lightning code to Lighter configs in minutes.</p> <p>Time: 10 minutes</p> <p> Migration Guide</p> </li> <li> <p> Learn the Syntax</p> <p>Configuration reference: Master Sparkwheel syntax: <code>_target_</code>, references (<code>@</code> and <code>%</code>), expressions (<code>$</code>), and path notation (<code>::</code>).</p> <p>Time: 20 minutes</p> <p> Configuration Guide</p> </li> <li> <p> Ready-to-Use Examples</p> <p>Recipes &amp; patterns: Copy-paste configs for common scenarios and best practices.</p> <p>Time: 5 minutes per recipe</p> <p> View Recipes</p> </li> <li> <p> Understand Adapters</p> <p>Core concept: Learn how adapters make Lighter task-agnostic and infinitely flexible.</p> <p>Time: 15 minutes</p> <p> Adapter Pattern</p> </li> <li> <p> Architecture &amp; Philosophy</p> <p>Deep dive: Understand the design decisions and how Lighter works internally.</p> <p>Time: 30 minutes</p> <p> Design Overview</p> </li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":""},{"location":"#get-help","title":"Get Help","text":"<p> Discord - Chat with the community</p> <p> FAQ - Common questions answered</p> <p> GitHub Issues - For bugs and features</p> <p> Troubleshooting - Common problems</p>"},{"location":"#contribute","title":"Contribute","text":"<p> GitHub - Star the repo</p> <p> Documentation - Improve the docs</p> <p> Examples - Share your configs</p>"},{"location":"#cite","title":"Cite","text":"<p>If you find it useful, please cite our Journal of Open Source Software paper:</p> <pre><code>@article{lighter,\n    doi = {10.21105/joss.08101},\n    url = {https://doi.org/10.21105/joss.08101},\n    year = {2025},\n    publisher = {The Open Journal},\n    volume = {10},\n    number = {111},\n    pages = {8101},\n    author = {Hadzic, Ibrahim and Pai, Suraj and Bressem, Keno and Foldyna, Borek and Aerts, Hugo JWL},\n    title = {Lighter: Configuration-Driven Deep Learning},\n    journal = {Journal of Open Source Software}\n}\n</code></pre>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#general","title":"General","text":"<p>What is Lighter?</p> <p>A configuration-driven deep learning framework built on PyTorch Lightning. Define experiments in YAML instead of writing training code. Get Started \u2192</p> <p>How does Lighter compare to PyTorch Lightning?</p> <p>Lighter extends Lightning's <code>LightningModule</code> but uses YAML configs instead of Python classes. You get all Lightning features (multi-GPU, callbacks, loggers) plus config-driven simplicity. Migration Guide \u2192</p> <p>When should I use Lighter?</p> <p>Use Lighter when:</p> <ul> <li>Running many experiments with different hyperparameters</li> <li>Reproducibility and experiment tracking are priorities</li> <li>You prefer configuration over code</li> <li>You want PyTorch's flexibility with structure</li> </ul> <p>Don't use Lighter when:</p> <ul> <li>You need ultra-custom training loops</li> <li>Rapid architecture prototyping (code first, config later)</li> <li>You prefer code-only workflows</li> </ul> <p>Is Lighter only for medical imaging?</p> <p>No. Lighter is task-agnostic and works for any deep learning task: classification, detection, segmentation, NLP, self-supervised learning, etc. See examples \u2192</p> <p>What's the performance overhead?</p> <p>Minimal (&lt;1%). Config resolution happens once at startup. Training speed is identical to PyTorch Lightning.</p>"},{"location":"faq/#configuration","title":"Configuration","text":"<p>What's the difference between <code>@</code>, <code>%</code>, and <code>$</code>?</p> <p>Lighter uses Sparkwheel for configuration:</p> Symbol Purpose Example <code>@</code> Resolved reference (instantiated object) <code>\"@system::optimizer\"</code> <code>%</code> Raw reference (unprocessed YAML) <code>\"%system::metrics::train\"</code> <code>$</code> Evaluate Python expression <code>\"$0.001 * 2\"</code> <ul> <li><code>@</code> gets the final instantiated object after processing</li> <li><code>%</code> copies raw YAML config (creates new instance when used with <code>_target_</code>)</li> <li><code>$</code> evaluates Python code in expressions</li> </ul> <p>Complete syntax guide \u2192 | Sparkwheel docs \u2192</p> <p>How do I pass model parameters to the optimizer?</p> <pre><code>optimizer:\n  _target_: torch.optim.Adam\n  params: \"$@system::model.parameters()\"\n  lr: 0.001\n</code></pre> <p>The <code>$</code> evaluates Python, <code>@</code> gets the resolved model instance, <code>.parameters()</code> calls the method.</p> <p>Can I use Python code in configs?</p> <p>Yes. Use <code>$</code> prefix for expressions:</p> <pre><code>optimizer:\n  lr: \"$0.001 * 2\"  # Evaluates to 0.002\n</code></pre> <p>Advanced configuration \u2192</p> <p>How do I add callbacks without replacing existing ones?</p> <p>By default, configs merge automatically. Later configs add to earlier ones:</p> <pre><code># base.yaml\ntrainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n\n# experiment.yaml (merges automatically)\ntrainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.EarlyStopping\n# Result: Both ModelCheckpoint AND EarlyStopping\n\n# To replace instead of merge, use =\ntrainer:\n  =callbacks:\n    - _target_: pytorch_lightning.callbacks.EarlyStopping\n# Result: Only EarlyStopping\n</code></pre> <p>How do I remove specific items from lists or dicts?</p> <p>Use <code>~</code> with path notation or batch syntax:</p> <pre><code># Delete entire key\ntrainer:\n  ~callbacks: null\n\n# Delete single list item by index\ntrainer:\n  ~callbacks::1: null  # Removes item at index 1\n\n# Delete multiple list items (batch syntax - recommended)\ntrainer:\n  ~callbacks: [1, 3]  # Removes items at indices 1 and 3\n\n# Delete dict keys (batch syntax)\nsystem:\n  ~dataloaders: [\"train\", \"test\"]  # Removes train and test loaders\n\n# Delete nested dict key (path notation)\nsystem:\n  ~model::pretrained: null\n</code></pre> <p>Tip</p> <p>For multiple list items, use batch syntax <code>~key: [indices]</code> to avoid index shifting issues when doing sequential deletions.</p> <p>Merging guide \u2192</p>"},{"location":"faq/#training","title":"Training","text":"<p>How do I resume training?</p> <pre><code>lighter fit config.yaml args::fit::ckpt_path=\"checkpoint.ckpt\"\n</code></pre> <p>How do I use multiple GPUs?</p> <pre><code>lighter fit config.yaml trainer::devices=2 trainer::strategy=ddp\n</code></pre> <p>Multi-GPU recipes \u2192</p> <p>How do I freeze layers?</p> <pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      modules: [\"backbone.layer1\", \"backbone.layer2\"]\n</code></pre> <p>Freezers guide \u2192</p> <p>Can I use custom training loops?</p> <p>Lighter uses Lightning's standard loop. For exotic training logic:</p> <ol> <li>Extend System class and override methods</li> <li>Use Lightning directly</li> </ol> <p>Most customizations achievable through callbacks or System extension. System internals \u2192</p>"},{"location":"faq/#design","title":"Design","text":"<p>Why adapters instead of custom LightningModule?</p> <p>Adapters separate data transformation from model logic, making both reusable. Configure transforms in YAML, reuse models across tasks. Adapter pattern \u2192</p> <p>What's the difference between stages and modes?</p> <ul> <li>Stages: CLI commands (fit, validate, test, predict)</li> <li>Modes: Internal execution contexts (train, val, test, predict)</li> </ul> <p>Example: <code>lighter fit</code> executes train + val modes. Architecture \u2192</p> <p>How does config pruning work?</p> <p>Lighter automatically removes unused components based on stage. <code>lighter test</code> removes train/val dataloaders, optimizer, and scheduler. One config works for all stages. Pruning details \u2192</p>"},{"location":"faq/#troubleshooting","title":"Troubleshooting","text":"<p>Training is slow?</p> <p>Check:</p> <ul> <li>Increase <code>num_workers</code> in dataloaders</li> <li>Enable mixed precision: <code>trainer::precision=\"16-mixed\"</code></li> <li>Profile: <code>trainer::profiler=\"simple\"</code></li> </ul> <p>Performance recipes \u2192</p> <p>Loss is NaN?</p> <p>Common causes:</p> <ol> <li>Learning rate too high \u2192 reduce by 10x</li> <li>Gradient explosion \u2192 <code>trainer::gradient_clip_val=1.0</code></li> <li>Wrong loss function \u2192 verify for your task</li> <li>Bad data \u2192 check for inf/nan in inputs</li> </ol> <p>Full troubleshooting guide \u2192</p> <p>ModuleNotFoundError: No module named 'project'?</p> <p>Ensure:</p> <ol> <li>Project path set: <code>project: ./path</code></li> <li>All directories have <code>__init__.py</code></li> </ol> <p>Project module guide \u2192</p>"},{"location":"faq/#comparisons","title":"Comparisons","text":"<p>Lighter vs Hydra?</p> <ul> <li>Hydra: General config framework for any Python app</li> <li>Lighter: Deep learning-specific with built-in training pipeline</li> </ul> <p>Use Lighter for DL experiments with automatic training loops.</p> <p>Lighter vs Ludwig?</p> <ul> <li>Ludwig: High-level, declarative ML with pre-built flows</li> <li>Lighter: Mid-level, requires standard PyTorch components</li> </ul> <p>Use Ludwig for no-code ML. Use Lighter when you write custom PyTorch but want config-driven experiments.</p> <p>Can I migrate from Lightning to Lighter?</p> <p>Yes. Main steps:</p> <ol> <li>Convert LightningModule to YAML config</li> <li>Move training_step logic to adapters (if needed)</li> <li>Configure dataloaders in YAML</li> </ol> <p>Complete migration guide \u2192</p>"},{"location":"faq/#getting-help","title":"Getting Help","text":"Need Resource Getting started Tutorials Configuration help Configuration Guide Common errors Troubleshooting Examples Recipes Community Discord Bug reports GitHub Issues"},{"location":"design/adapters/","title":"The Adapter Pattern","text":""},{"location":"design/adapters/#the-problem","title":"The Problem","text":"<p>Different ML components may expect different data formats. Consider a scenario where:</p> <ul> <li>Dataset returns dictionaries of tensors</li> <li>Model expects tensors</li> <li>Loss function needs specific argument order</li> <li>Metrics need different format than loss</li> </ul> <p>Traditionally, you'd implement a pipeline specific to this scenario. This tightly couples components, making reuse and experimentation difficult.</p>"},{"location":"design/adapters/#the-solution-adapters","title":"The Solution: Adapters","text":"<p> Data flow through Lighter's System. Adapters bridge components with incompatible interfaces.</p> <p>In software engineering, the adapter pattern allows incompatible interfaces to work together. Lighter uses adapters to handle variability in data formats.</p>"},{"location":"design/adapters/#lighters-adapter-types","title":"Lighter's Adapter Types","text":"Adapter Purpose When to Use BatchAdapter Extract data from batches Different dataset formats CriterionAdapter Format loss inputs Custom loss functions MetricsAdapter Format metric inputs Third-party metrics LoggingAdapter Transform before logging Visualization needs"},{"location":"design/adapters/#example-task-agnostic-configuration","title":"Example: Task-Agnostic Configuration","text":"<pre><code>adapters:\n  train:\n    criterion:\n      _target_: lighter.adapters.CriterionAdapter\n      pred_transforms:   # Apply sigmoid before loss\n        _target_: torch.sigmoid\n      pred_argument: 0   # Map pred to first argument\n      target_argument: 1 # Map target to second argument\n</code></pre> <p>This enables any task\u2014classification, segmentation, self-supervised learning\u2014without framework modifications.</p>"},{"location":"design/adapters/#under-the-hood","title":"Under the Hood","text":"<p>Adapters are invoked in this order during training:</p> <ol> <li>BatchAdapter - Extract input/target from batch</li> <li>Forward pass - Model processes input</li> <li>CriterionAdapter - Format for loss computation</li> <li>MetricsAdapter - Format for metric computation</li> <li>LoggingAdapter - Transform for visualization</li> </ol>"},{"location":"design/adapters/#practical-usage","title":"Practical Usage","text":"<p>For detailed adapter configuration and examples, see:</p> <ul> <li>Adapters How-To Guide - Complete usage guide</li> <li>Metrics Guide - Using MetricsAdapter</li> <li>Writers Guide - Using LoggingAdapter</li> </ul>"},{"location":"design/overview/","title":"Architecture &amp; Design Overview","text":"<p>Lighter is a configuration-driven deep learning framework that separates experimental setup from code implementation.</p>"},{"location":"design/overview/#core-architecture","title":"Core Architecture","text":"<p> Figure: Lighter's three-component (bolded) architecture. Config parses YAML definitions, System encapsulates DL components, and Trainer executes training.</p>"},{"location":"design/overview/#1-config","title":"1. Config","text":"<p>Transforms YAML experiment definitions into Python objects using Sparkwheel. One config file = one reproducible experiment.</p> <p>\u2192 Configuration guide</p>"},{"location":"design/overview/#2-system","title":"2. System","text":"<p>Orchestrates your deep learning pipeline\u2014model, optimizer, loss, metrics, data. Extends PyTorch Lightning's LightningModule.</p> <p>\u2192 System internals</p>"},{"location":"design/overview/#3-trainer","title":"3. Trainer","text":"<p>PyTorch Lightning's Trainer executes experiments with multi-GPU, mixed precision, gradient accumulation, and checkpointing.</p> <p>\u2192 Running experiments</p>"},{"location":"design/overview/#stages-and-modes","title":"Stages and Modes","text":"<p>A key concept in Lighter is the distinction between Stages and Modes:</p>"},{"location":"design/overview/#stages","title":"Stages","text":"<p>Stages are what you invoke from the CLI. They represent high-level operations:</p> <ul> <li><code>lighter fit</code> - Train and validate a model</li> <li><code>lighter validate</code> - Run validation only</li> <li><code>lighter test</code> - Evaluate on test set</li> <li><code>lighter predict</code> - Generate predictions</li> </ul>"},{"location":"design/overview/#modes","title":"Modes","text":"<p>Modes are internal execution contexts that the System uses during a stage. Each mode has its own dataloader, metrics, and adapters:</p> <ul> <li><code>train</code> - Training loop with backpropagation</li> <li><code>val</code> - Validation loop (no gradients)</li> <li><code>test</code> - Testing loop (no gradients)</li> <li><code>predict</code> - Inference loop (no targets or loss)</li> </ul>"},{"location":"design/overview/#stage-to-mode-mapping","title":"Stage-to-Mode Mapping","text":"<p>Each stage executes one or more modes:</p> <pre><code>FIT       \u2192 [train, val]  # Training with validation\nVALIDATE  \u2192 [val]         # Validation only\nTEST      \u2192 [test]        # Testing only\nPREDICT   \u2192 [predict]     # Inference only\n</code></pre> <p>This means when you run <code>lighter fit</code>, the system will execute both training and validation modes. When you run <code>lighter validate</code>, only the validation mode executes.</p> <p>Code reference: <code>src/lighter/engine/runner.py:26-31</code></p>"},{"location":"design/overview/#auto-config-pruning","title":"Auto Config Pruning","text":"<p>Lighter automatically prunes (removes) unused components from your configuration based on the stage you're running. This allows you to define a single comprehensive configuration file that works for all stages.</p>"},{"location":"design/overview/#what-gets-pruned","title":"What Gets Pruned","text":"<p>The Runner (<code>src/lighter/engine/runner.py:80-112</code>) automatically removes:</p> <ol> <li>Unused mode components: Dataloaders and metrics for modes not required by the current stage</li> <li> <p>Example: When running <code>lighter test</code>, train and val dataloaders/metrics are removed</p> </li> <li> <p>Training-only components (for non-FIT stages):</p> </li> <li>Optimizer</li> <li>Learning rate scheduler</li> <li> <p>Criterion (except for VALIDATE stage, which needs it for computing validation loss)</p> </li> <li> <p>Stage-specific arguments: Arguments defined for other stages are removed</p> </li> <li>Example: <code>args::fit</code> is removed when running <code>lighter test</code></li> </ol>"},{"location":"design/overview/#why-this-matters","title":"Why This Matters","text":"<p>Configuration pruning means you can:</p> <ul> <li>Define once, use everywhere: Write one config with train/val/test dataloaders, then use it for any stage</li> <li>Avoid duplication: No need for separate train.yaml, test.yaml, predict.yaml files</li> <li>Reduce errors: The system ensures only relevant components are used for each stage</li> </ul>"},{"location":"design/overview/#example","title":"Example","text":"<pre><code>system:\n  dataloaders:\n    train: # Used only in FIT stage\n      _target_: torch.utils.data.DataLoader\n      # ... config ...\n\n    val: # Used in FIT and VALIDATE stages\n      _target_: torch.utils.data.DataLoader\n      # ... config ...\n\n    test: # Used only in TEST stage\n      _target_: torch.utils.data.DataLoader\n      # ... config ...\n\n    predict: # Used only in PREDICT stage\n      _target_: torch.utils.data.DataLoader\n      # ... config ...\n\n  optimizer: # Pruned for VALIDATE, TEST, PREDICT stages\n    _target_: torch.optim.Adam\n    lr: 0.001\n\n  criterion: # Pruned for TEST, PREDICT stages\n    _target_: torch.nn.CrossEntropyLoss\n</code></pre> <p>When you run <code>lighter test</code>, the Runner automatically removes the train, val, and predict dataloaders, as well as the optimizer and criterion, keeping only what's needed for testing.</p>"},{"location":"design/overview/#system-data-flow","title":"System Data Flow","text":"<p>Understanding how data flows through the System is crucial for working with Lighter effectively. The <code>System._step()</code> method (<code>src/lighter/system.py:74-94</code>) orchestrates this flow:</p>"},{"location":"design/overview/#the-pipeline","title":"The Pipeline","text":"<pre><code>1. Batch (from DataLoader)\n   \u2193\n2. BatchAdapter \u2192 [input, target, identifier]\n   \u2193\n3. Model.forward(input) \u2192 prediction\n   \u2193 (or Inferer in val/test/predict modes)\n   \u2193\n4. CriterionAdapter \u2192 Criterion(pred, target) \u2192 loss\n   \u2193\n5. MetricsAdapter \u2192 Metrics(pred, target) \u2192 metric values\n   \u2193\n6. LoggingAdapter \u2192 Logger\n   \u2193\n7. Output dict returned to callbacks\n</code></pre>"},{"location":"design/overview/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":"<p>1. Batch Preparation (<code>System._prepare_batch</code>) - The raw batch from the DataLoader is passed to the BatchAdapter - Returns: <code>(input, target, identifier)</code> tuple - Identifier is optional and used for tracking samples</p> <p>2. Forward Pass (<code>System.forward</code>) - Input goes through <code>model.forward()</code> to produce predictions - In val/test/predict modes, the Inferer replaces model.forward() if specified - Automatically injects <code>epoch</code> and <code>step</code> arguments if model accepts them</p> <p>3. Loss Calculation (<code>System._calculate_loss</code>) - Only in train and val modes (test/predict skip this) - CriterionAdapter transforms data before passing to criterion - Supports dict-based losses with sublosses (must include 'total' key)</p> <p>4. Metrics Calculation (<code>System._calculate_metrics</code>) - Only in train, val, and test modes (predict skips this) - MetricsAdapter transforms data before passing to metrics - Returns None if no metrics are defined</p> <p>5. Logging (<code>System._log_stats</code>) - Logs loss and metrics to the logger - Automatically logs optimizer stats (lr, momentum, beta) once per epoch in train mode</p> <p>6. Output Preparation (<code>System._prepare_output</code>) - LoggingAdapter can transform data for cleaner callback access - Returns a dictionary with all step information</p>"},{"location":"design/overview/#the-output-dictionary","title":"The Output Dictionary","text":"<p>Each step returns a dictionary with the following keys:</p> <pre><code>{\n    \"identifier\": batch_identifier,  # Optional, for tracking\n    \"input\": input_data,\n    \"target\": target_data,\n    \"pred\": predictions,\n    \"loss\": loss_value,              # None in test/predict\n    \"metrics\": metrics_dict,         # None in predict\n    \"step\": global_step,\n    \"epoch\": current_epoch,\n}\n</code></pre> <p>This dictionary is accessible in callbacks, allowing you to write predictions to disk, visualize results, or perform custom analysis.</p> <p>Code references: - Data flow orchestration: <code>src/lighter/system.py:74-94</code> - Dict-based loss handling: <code>src/lighter/system.py:156-160</code> - Epoch/step injection: <code>src/lighter/system.py:121-126</code></p>"},{"location":"design/overview/#key-behaviors","title":"Key Behaviors","text":"<ul> <li> <p>Inferer replaces forward(): In val/test/predict modes, if an inferer is specified, it's called instead of <code>model.forward()</code>. This is useful for inference-specific logic like sliding window or test-time augmentation.</p> </li> <li> <p>Dict-based losses: If your criterion returns a dictionary of sublosses, it must include a <code>'total'</code> key that combines all sublosses. This is used for backpropagation.</p> </li> <li> <p>Mode-specific adapters: Each mode (train/val/test/predict) has its own set of adapters, allowing different preprocessing for different stages.</p> </li> <li> <p>Automatic optimizer stats: Learning rate, momentum, and beta values are logged automatically once per epoch during training.</p> </li> </ul>"},{"location":"design/overview/#the-adapter-pattern","title":"The Adapter Pattern","text":"<p>Adapters make Lighter task-agnostic by handling data format differences between components.</p> <p>\u2192 Learn more about adapters</p>"},{"location":"design/overview/#design-philosophy","title":"Design Philosophy","text":"<p>Lighter follows four core principles: Configuration over Code, Composition over Inheritance, Convention over Configuration, and Separation of Concerns.</p> <p>\u2192 Understand the philosophy</p>"},{"location":"design/overview/#framework-comparison","title":"Framework Comparison","text":"<p>Lighter's goal is to brings reproducibility and structure, while keeping you in full control of your code. This is different from other configuration-driven frameworks that provide higher-level abstractions.</p> Feature Lighter Ludwig Quadra GaNDLF Primary Focus Config-driven, task-agnostic DL Config-driven, multi-task DL Config-driven computer vision Config-driven medical imaging Configuration YAML (Sparkwheel) YAML (Custom) YAML (Hydra) YAML (Custom) Abstraction Medium. Extends PyTorch Lightning, expects standard PyTorch components. High. Provides pre-built flows for various tasks. High. Pre-defined structures for computer vision. High. Pre-defined structures for medical imaging. Flexibility High. New components are added via project module. Medium. Adding new components requires code editing. Low. Adding new components requires code editing. Low. Adding new components requires code editing. Use Case Organized experimentation Production-level applications Traditional computer vision Established medical imaging methods <p>Lighter is the tool for you if you like PyTorch's flexibility but want to manage your experiments in a structured and reproducible way.</p>"},{"location":"design/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Deep dive into the Adapter Pattern</li> <li>Understand Design Philosophy</li> <li>Get started with the Zero to Hero tutorial</li> </ul>"},{"location":"design/philosophy/","title":"Design Philosophy","text":"<p>Why Lighter is designed the way it is.</p>"},{"location":"design/philosophy/#core-principles","title":"Core Principles","text":""},{"location":"design/philosophy/#1-configuration-over-code","title":"1. Configuration Over Code","text":"<p>Experiments are data, not code. YAML configs are easier to: - Version control and compare - Share and reproduce - Parametrize and sweep - Audit and validate</p>"},{"location":"design/philosophy/#2-composition-over-inheritance","title":"2. Composition Over Inheritance","text":"<p>Instead of subclassing for behavior changes, compose with adapters. More flexible, less coupled.</p>"},{"location":"design/philosophy/#3-convention-over-configuration","title":"3. Convention Over Configuration","text":"<p>Sensible defaults (like BatchAdapter assuming <code>(input, target)</code> tuples) reduce boilerplate. Override when needed.</p>"},{"location":"design/philosophy/#4-separation-of-concerns","title":"4. Separation of Concerns","text":"<p>Clear boundaries: - Config - Experiment definition - System - Component orchestration - Trainer - Execution engine - Adapters - Interface translation</p>"},{"location":"design/philosophy/#5-task-agnostic-by-design","title":"5. Task-Agnostic by Design","text":"<p>No per-task pipelines. Adapters handle variability, enabling unlimited flexibility for novel research.</p>"},{"location":"design/philosophy/#why-1000-lines-of-code","title":"Why ~1,000 Lines of Code?","text":"<p>Benefits: - Read entire codebase in an afternoon - Easy to debug and understand - Simple to extend and maintain - Low long-term maintenance burden</p> <p>Achieved by: - Leveraging PyTorch Lightning (not reinventing training loops) - Using Sparkwheel's config system (powerful, flexible) - Focusing on core value: config-driven experiments + adapters</p>"},{"location":"design/philosophy/#integration-philosophy","title":"Integration Philosophy","text":""},{"location":"design/philosophy/#standing-on-shoulders-of-giants","title":"Standing on Shoulders of Giants","text":"<p>PyTorch Lightning - Battle-tested training engine - Multi-GPU/TPU support - Callbacks, loggers, profilers - Gradient accumulation, mixed precision - \u2192 PL Trainer docs</p> <p>Sparkwheel - Powerful configuration system - Config parsing and validation - Reference resolution - Dynamic instantiation - \u2192 Sparkwheel docs</p> <p>Lighter adds: adapters + System orchestration.</p>"},{"location":"design/philosophy/#trade-offs","title":"Trade-offs","text":""},{"location":"design/philosophy/#when-to-use-lighter","title":"When to Use Lighter","text":"<ul> <li>Configuration-driven experiments are valuable</li> <li>You need task-agnostic flexibility</li> <li>You want minimal framework overhead</li> <li>Reproducibility and sharing are priorities</li> </ul>"},{"location":"design/philosophy/#when-not-to-use-lighter","title":"When NOT to Use Lighter","text":"<ul> <li>Highly custom training loops (use PyTorch directly)</li> <li>Prefer code over configuration</li> <li>Need high-level AutoML (use Ludwig)</li> <li>Domain-specific pipelines sufficient (use GaNDLF/Quadra)</li> </ul>"},{"location":"design/philosophy/#learn-more","title":"Learn More","text":"<ul> <li>Architecture Overview - Component details</li> <li>Adapter Pattern - Deep dive</li> <li>Configuration Guide - Practical usage</li> </ul>"},{"location":"design/system/","title":"System Internals","text":"<p>The <code>System</code> class extends PyTorch Lightning's <code>LightningModule</code> and orchestrates your entire training pipeline. Understanding its operation helps with debugging and customization.</p>"},{"location":"design/system/#overview","title":"Overview","text":"<p>System manages:</p> <ul> <li>Model architecture</li> <li>Optimizer and scheduler</li> <li>Loss function (criterion)</li> <li>Metrics computation</li> <li>Data loading</li> <li>Adapters for data transformation</li> <li>Inference strategies (inferer)</li> </ul>"},{"location":"design/system/#the-unified-_step-method","title":"The Unified <code>_step()</code> Method","text":"<p>All modes (train, val, test, predict) use the same <code>_step()</code> method:</p> <pre><code>1. Batch \u2192 BatchAdapter \u2192 [input, target, identifier]\n2. Model.forward(input) \u2192 prediction\n   (or Inferer in val/test/predict modes)\n3. CriterionAdapter \u2192 Criterion \u2192 loss (train/val only)\n4. MetricsAdapter \u2192 Metrics \u2192 values (train/val/test)\n5. LoggingAdapter \u2192 Logger\n6. Output dict \u2192 callbacks\n</code></pre> <p>This unified approach ensures consistency while allowing mode-specific behavior through adapters.</p>"},{"location":"design/system/#automatic-pruning","title":"Automatic Pruning","text":"<p>The Runner automatically removes unused components based on stage:</p> <pre><code>system:\n  dataloaders:\n    train: ...   # Removed for TEST, PREDICT\n    val: ...     # Removed for TEST, PREDICT\n    test: ...    # Removed for FIT, VALIDATE, PREDICT\n    predict: ... # Removed for FIT, VALIDATE, TEST\n\n  optimizer: ... # Removed for VALIDATE, TEST, PREDICT\n  criterion: ... # Removed for TEST, PREDICT\n</code></pre> <p>This enables one config for all stages.</p>"},{"location":"design/system/#mode-specific-behavior","title":"Mode-Specific Behavior","text":""},{"location":"design/system/#loss-calculation","title":"Loss Calculation","text":"<p>Loss is calculated only in train and val modes:</p> <pre><code>if self.mode in [Mode.TRAIN, Mode.VAL]:\n    loss = adapters.criterion(self.criterion, input, target, pred)\n</code></pre> <p>Test and predict modes return <code>None</code>.</p>"},{"location":"design/system/#dict-based-losses","title":"Dict-Based Losses","text":"<p>For multi-task learning, return a dict with <code>\"total\"</code> key:</p> <pre><code>def my_criterion(pred, target):\n    return {\n        \"total\": loss1 + loss2,  # Required for backprop\n        \"classification\": loss1,\n        \"segmentation\": loss2,\n    }\n</code></pre> <p>All sublosses logged automatically; <code>\"total\"</code> used for gradients.</p>"},{"location":"design/system/#metrics-calculation","title":"Metrics Calculation","text":"<p>Metrics calculated in train, val, and test modes (not predict):</p> <pre><code>if self.mode == Mode.PREDICT or self.metrics[self.mode] is None:\n    return None\n</code></pre>"},{"location":"design/system/#special-features","title":"Special Features","text":""},{"location":"design/system/#epochstep-injection","title":"Epoch/Step Injection","text":"<p>If your model accepts <code>epoch</code> or <code>step</code> parameters, they're injected automatically:</p> <pre><code>class MyModel(nn.Module):\n    def forward(self, x, epoch=None, step=None):\n        # Use for curriculum learning\n        if epoch is not None:\n            difficulty = min(epoch / self.max_epochs, 1.0)\n            x = self.apply_difficulty(x, difficulty)\n        return self.process(x)\n</code></pre> <p>No configuration needed\u2014works automatically.</p>"},{"location":"design/system/#inferer-in-valtestpredict","title":"Inferer in Val/Test/Predict","text":"<p>In validation, testing, and prediction modes, an inferer can replace the forward pass:</p> <pre><code>if self.inferer and self.mode in [Mode.VAL, Mode.TEST, Mode.PREDICT]:\n    return self.inferer(input, self.model, **kwargs)\nreturn self.model(input, **kwargs)\n</code></pre> <p>Use for:</p> <ul> <li>Sliding window inference</li> <li>Test-time augmentation</li> <li>Ensemble methods</li> <li>Custom post-processing</li> </ul>"},{"location":"design/system/#automatic-logging","title":"Automatic Logging","text":"<p>System logs automatically:</p>"},{"location":"design/system/#loss","title":"Loss","text":"<ul> <li>Step and epoch level: <code>{mode}/loss/step</code>, <code>{mode}/loss/epoch</code></li> <li>Individual sublosses for dict-based losses</li> </ul>"},{"location":"design/system/#metrics","title":"Metrics","text":"<ul> <li>Step and epoch level: <code>{mode}/metrics/{name}/step</code>, <code>{mode}/metrics/{name}/epoch</code></li> </ul>"},{"location":"design/system/#optimizer-stats","title":"Optimizer Stats","text":"<p>Once per epoch during training:</p> <ul> <li>Learning rate: <code>train/lr</code></li> <li>Momentum (SGD)</li> <li>Beta values (Adam/AdamW)</li> </ul>"},{"location":"design/system/#output-dictionary","title":"Output Dictionary","text":"<p>Each step returns:</p> <pre><code>{\n    \"identifier\": batch_identifier,  # Optional\n    \"input\": input_data,              # After LoggingAdapter\n    \"target\": target_data,            # After LoggingAdapter\n    \"pred\": predictions,              # After LoggingAdapter\n    \"loss\": loss_value,               # None in test/predict\n    \"metrics\": metrics_dict,          # None in predict\n    \"step\": self.global_step,\n    \"epoch\": self.current_epoch,\n}\n</code></pre> <p>This dictionary is passed to callbacks for custom processing.</p>"},{"location":"design/system/#customization","title":"Customization","text":"<p>Extend System for advanced use cases:</p> <pre><code>from lighter.system import System\n\nclass CustomSystem(System):\n    def _log_stats(self, loss, metrics, batch_idx):\n        super()._log_stats(loss, metrics, batch_idx)\n        # Add custom logging\n        if self.mode == Mode.TRAIN:\n            self.log(\"custom/my_metric\", my_value)\n\n    def on_train_epoch_end(self):\n        # Custom behavior at epoch end\n        pass\n</code></pre> <p>Use in config:</p> <pre><code>system:\n  _target_: project.CustomSystem\n  model: ...\n</code></pre>"},{"location":"design/system/#summary","title":"Summary","text":"<p>System provides:</p> <ol> <li>Unified execution: Same <code>_step()</code> for all modes</li> <li>Automatic pruning: Unused components removed by stage</li> <li>Flexible loss: Scalar or dict-based</li> <li>Smart injection: Epoch/step passed to model automatically</li> <li>Inferer support: Custom inference logic</li> <li>Comprehensive logging: Loss, metrics, optimizer stats</li> <li>Extensibility: Subclass for custom behavior</li> </ol> <p>Understanding System helps you debug issues, optimize performance, and implement advanced training strategies.</p>"},{"location":"design/system/#next-steps","title":"Next Steps","text":"<ul> <li>Adapters - Data transformation</li> <li>Architecture Overview - High-level design</li> <li>API Reference - Complete documentation</li> </ul>"},{"location":"how-to/adapters/","title":"Adapters: Data Flow Control","text":"<p>Adapters are the secret sauce that makes Lighter incredibly flexible. They act as intelligent translators between different components of your pipeline, ensuring data flows correctly regardless of format differences.</p>"},{"location":"how-to/adapters/#the-data-flow-problem","title":"The Data Flow Problem","text":"<p>In a typical training step, data flows sequentially: a batch from the dataloader is fed to the model to produce a prediction. This prediction, along with the target from the batch, is then used by the loss function, metrics, and logger.</p> <p>The problem is that each component might have different expectations for the data it receives:</p> <ul> <li>A <code>Dataset</code> might return a dictionary of tensors, but the <code>model</code> only needs a specific tensor.</li> <li>A <code>loss function</code> might expect <code>(prediction, target)</code>, while another expects <code>(target, prediction)</code>.</li> <li>A <code>metric</code> might need class indices, but the model outputs probabilities.</li> </ul> <p>Without adapters, you would have to write glue code inside your model or training loop to handle these mismatches. This makes your components less reusable.</p> <p>With Lighter's adapters, you define these translations in your configuration, keeping your components clean and independent.</p>"},{"location":"how-to/adapters/#the-solution-adapters","title":"The Solution: Adapters","text":"<p>Lighter provides four types of adapters, each designed to intercept and transform data at a specific point in the data flow:</p> Adapter Purpose When to Use BatchAdapter Extracts and formats data from the dataloader's batch. When your dataset has a different structure than the expected <code>(input, target)</code>. CriterionAdapter Prepares <code>input</code>, <code>target</code>, and <code>pred</code> for the loss function. When your loss function has specific argument or data format requirements. MetricsAdapter Prepares <code>input</code>, <code>target</code>, and <code>pred</code> for metrics. When your metrics have specific argument or data format requirements. LoggingAdapter Prepares <code>input</code>, <code>target</code>, and <code>pred</code> for logging. When you need to transform data for visualization. <p>Here are some common challenges and how adapters solve them. Don't worry about the details yet\u2014we'll dive deeper into each adapter below.:</p> Component / Scenario Common Challenge Adapter Solution Batch \ud83d\udce6 Dataset returns a <code>dict</code> (e.g., <code>{\"x\": ..., \"y\": ...}</code>), but the pipeline needs <code>input</code> and <code>target</code>. Use <code>BatchAdapter</code> to map dictionary keys to <code>input</code> and <code>target</code> (e.g., <code>input_accessor=\"x\"</code>). Batch in Self-Supervision The training step has no <code>target</code>. Use <code>BatchAdapter</code> and set <code>target_accessor</code> to <code>None</code>. Loss Function \ud83d\udcc9 Loss function expects <code>loss(target, pred)</code>, but Lighter's default is <code>loss(pred, target)</code>. Use <code>CriterionAdapter</code> to reorder arguments (e.g., <code>pred_argument=1</code>, <code>target_argument=0</code>). Metrics \ud83d\udccf A metric needs class indices, but the model outputs probabilities. Use <code>MetricsAdapter</code> with <code>pred_transforms</code> to apply <code>torch.argmax</code> before the metric calculation. Logging \ud83d\udcca Logger expects RGB images, but the data is grayscale. Use <code>LoggingAdapter</code> with <code>input_transforms</code> to repeat the channel dimension."},{"location":"how-to/adapters/#execution-order","title":"Execution Order","text":"<p>Understanding when each adapter is called is crucial for debugging and designing your pipeline. Here's the complete data flow during a training step:</p> <pre><code>Step 1: DataLoader produces batch\n        \u2193\nStep 2: BatchAdapter\n        \u2514\u2500\u2192 Extracts: (input, target, identifier)\n        \u2193\nStep 3: Model.forward(input) or Inferer\n        \u2514\u2500\u2192 Produces: prediction\n        \u2193\nStep 4: CriterionAdapter (train/val modes only)\n        \u251c\u2500\u2192 Transforms: input, target, pred\n        \u2514\u2500\u2192 Maps to loss function arguments\n        \u2193\nStep 5: Loss function computes loss\n        \u2193\nStep 6: MetricsAdapter (train/val/test modes)\n        \u251c\u2500\u2192 Transforms: input, target, pred\n        \u2514\u2500\u2192 Maps to metrics arguments\n        \u2193\nStep 7: Metrics compute values\n        \u2193\nStep 8: LoggingAdapter\n        \u251c\u2500\u2192 Transforms: input, target, pred\n        \u2514\u2500\u2192 Prepares for logger/callbacks\n        \u2193\nStep 9: Logger and callbacks receive data\n</code></pre>"},{"location":"how-to/adapters/#key-points","title":"Key Points","text":"<ul> <li>BatchAdapter runs first, before the model sees any data</li> <li>CriterionAdapter runs only in train and val modes (skipped in test/predict)</li> <li>MetricsAdapter runs only in train, val, and test modes (skipped in predict)</li> <li>LoggingAdapter runs last, after all computations are done</li> <li>Each mode (train/val/test/predict) can have its own set of adapters</li> </ul>"},{"location":"how-to/adapters/#practical-implications","title":"Practical Implications","text":"<ol> <li> <p>BatchAdapter transforms are executed on every batch: Keep them lightweight, or move expensive operations to your Dataset's <code>__getitem__</code>.</p> </li> <li> <p>CriterionAdapter and MetricsAdapter run after model forward: You can safely apply post-processing like <code>argmax</code> or <code>sigmoid</code> here without affecting the model.</p> </li> <li> <p>LoggingAdapter is for visualization only: Transforms here don't affect training\u2014use them for detaching tensors, converting to CPU, or formatting for display.</p> </li> <li> <p>Mode-specific adapters: You can configure different adapters for train vs val vs test:    <pre><code>system:\n  adapters:\n    train:\n      batch: ...\n      criterion: ...\n    val:\n      batch: ...  # Can be different from train\n      criterion: ...\n</code></pre></p> </li> </ol> <p>For a deeper understanding of the complete System data flow, see System Internals.</p>"},{"location":"how-to/adapters/#deep-dive","title":"Deep Dive","text":""},{"location":"how-to/adapters/#batchadapter","title":"BatchAdapter","text":"<p>The <code>BatchAdapter</code> is responsible for extracting <code>input</code>, <code>target</code>, and an optional <code>identifier</code> from each batch produced by your <code>DataLoader</code>. This is the first and most common adapter you'll use.</p> <p>Lighter needs to know how to get the following from a batch:</p> Item Description Input The data fed into the model (e.g., images, text). Target (optional) The ground truth data (e.g., labels, masks) used for loss calculation. Identifier (optional) A unique ID for the data point (e.g., filename, patient ID). <p>Note</p> <p>By default, Lighter assumes the batch is an <code>(input, target)</code> tuple: <code>BatchAdapter(input_accessor=0, target_accessor=1)</code></p> <p>You can specify <code>accessors</code> to handle different batch structures:</p> Accessor Type Description Example Integer Index Access elements by position in a list or tuple batch. <code>input_accessor: 0</code> String Key Access elements by key in a dictionary batch. <code>input_accessor: \"image\"</code> Callable Use a function for complex logic. <code>target_accessor: $lambda batch: one_hot(batch[1])</code>"},{"location":"how-to/adapters/#example-1-dictionary-based-dataset","title":"Example 1: Dictionary-based Dataset","text":"<p>If your dataset returns a dictionary, you can map the keys to <code>input</code>, <code>target</code>, and <code>identifier</code>.</p> <pre><code># Problem: Dataset returns a dict, but the model needs tensors.\nsystem:\n  adapters:\n    train:\n      batch:\n        _target_: lighter.adapters.BatchAdapter\n        input_accessor: \"image\"\n        target_accessor: \"mask\"\n        identifier_accessor: \"patient_id\"\n</code></pre>"},{"location":"how-to/adapters/#example-2-self-supervised-learning","title":"Example 2: Self-Supervised Learning","text":"<p>In self-supervised learning, you might not have a <code>target</code>. You can set its accessor to <code>None</code>.</p> <pre><code># Problem: No targets in this training phase.\nsystem:\n  adapters:\n    train:\n      batch:\n        _target_: lighter.adapters.BatchAdapter\n        input_accessor: 0\n        target_accessor: null  # No targets!\n</code></pre> <p>For more details, see the <code>BatchAdapter</code> documentation.</p>"},{"location":"how-to/adapters/#criterionadapter","title":"CriterionAdapter","text":"<p>The <code>CriterionAdapter</code> acts as a bridge between your model's prediction and your loss function. It allows you to:</p> <ol> <li>Map <code>pred</code>, <code>target</code>, and <code>input</code> to the arguments of your loss function.</li> <li>Transform these tensors before they are passed to the loss function.</li> </ol> <p>Argument Mappers can be:</p> Mapper Type Description Example Integer Index Map to a positional argument. <code>pred_argument: 1</code>, <code>target_argument: 0</code> String Key Map to a keyword argument. <code>pred_argument: \"prediction\"</code> <code>None</code> Don't pass this tensor to the loss function. <code>input_argument: None</code> <p>Transforms are functions applied to the tensors before mapping.</p> Transform Type Description Example Callable A function or list of functions to apply. <code>pred_transforms: [_target_: torch.sigmoid]</code>"},{"location":"how-to/adapters/#example-custom-argument-order-and-activation","title":"Example: Custom Argument Order and Activation","text":"<p>If your loss function expects <code>(target, pred)</code> and requires sigmoid on the predictions:</p> <pre><code># Problem: Loss function has a non-standard signature and needs activated predictions.\nsystem:\n  adapters:\n    train:\n      criterion:\n        _target_: lighter.adapters.CriterionAdapter\n        pred_argument: 1  # Pass 'pred' as the 2nd argument\n        target_argument: 0 # Pass 'target' as the 1st argument\n        pred_transforms:\n          - _target_: torch.sigmoid\n</code></pre> <p>For more details, see the <code>CriterionAdapter</code> documentation.</p>"},{"location":"how-to/adapters/#metricsadapter","title":"MetricsAdapter","text":"<p>The <code>MetricsAdapter</code> is identical in configuration to the <code>CriterionAdapter</code>, but for your metrics. You can use it to map and transform <code>pred</code>, <code>target</code>, and <code>input</code> before they are fed into your <code>torchmetrics</code> functions.</p>"},{"location":"how-to/adapters/#example-preparing-predictions-for-a-metric","title":"Example: Preparing Predictions for a Metric","text":"<p>If a metric requires class indices from your model's output probabilities:</p> <pre><code># Problem: Metric expects class indices, not probabilities.\nsystem:\n  adapters:\n    val:\n      metrics:\n        _target_: lighter.adapters.MetricsAdapter\n        pred_argument: \"preds\"\n        target_argument: \"target\"\n        pred_transforms:\n          - _target_: torch.argmax\n            dim: 1\n</code></pre> <p>For more details, see the <code>MetricsAdapter</code> documentation.</p>"},{"location":"how-to/adapters/#loggingadapter","title":"LoggingAdapter","text":"<p>The <code>LoggingAdapter</code> is used to transform <code>input</code>, <code>target</code>, and <code>pred</code> tensors just before they are sent to the logger (e.g., for image visualization in TensorBoard). It only supports transforms, not argument mapping.</p>"},{"location":"how-to/adapters/#example-visualizing-grayscale-images","title":"Example: Visualizing Grayscale Images","text":"<p>If you want to log a single-channel image and your logger expects a 3-channel RGB image:</p> <pre><code># Problem: Logger expects a 3-channel image, but data is grayscale.\nsystem:\n  adapters:\n    train:\n      logging:\n        _target_: lighter.adapters.LoggingAdapter\n        input_transforms: \"$lambda x: x.repeat(1, 3, 1, 1)\" # Convert to 3-channel\n</code></pre> <p>For more details, see the <code>LoggingAdapter</code> documentation.</p>"},{"location":"how-to/adapters/#advanced-usage","title":"Advanced Usage","text":""},{"location":"how-to/adapters/#custom-adapters","title":"Custom Adapters","text":"<p>For highly complex scenarios, you can implement your own adapter by inheriting from Lighter's base adapters.</p> <pre><code># my_project/adapters.py\nfrom lighter.adapters import BatchAdapter\n\nclass MultiModalBatchAdapter(BatchAdapter):\n    \"\"\"A custom adapter for multi-modal data.\"\"\"\n    def __call__(self, batch):\n        # Custom logic to unpack a complex batch\n        return {\n            \"image\": batch[\"image_data\"],\n            \"text\": batch[\"text_embeddings\"],\n            \"tabular\": batch[\"clinical_features\"]\n        }, batch[\"diagnosis\"], batch[\"id\"]\n</code></pre> <p>Then, use it in your config:</p> <pre><code>system:\n  adapters:\n    train:\n      batch:\n        _target_: my_project.adapters.MultiModalBatchAdapter\n</code></pre>"},{"location":"how-to/adapters/#tips-and-troubleshooting","title":"Tips and Troubleshooting","text":"Tip / Issue Solution Performance Put expensive transforms in your <code>Dataset</code>, not in adapters, to leverage multi-worker data loading. Debugging Add a print transform (<code>$lambda x: print(x.shape) or x</code>) to inspect tensor shapes at any point in the flow. <code>KeyError</code> in batch Your <code>input_accessor</code> or <code>target_accessor</code> might be wrong. Use a print transform to inspect the batch keys/indices. Wrong argument order Double-check the signature of your loss/metric function and use named arguments in <code>CriterionAdapter</code> or <code>MetricsAdapter</code> for clarity. Reusing configs Use raw references (<code>%</code>) to reuse adapters: <code>val: \"%system::adapters::train::batch\"</code> creates a new instance with the same config."},{"location":"how-to/adapters/#complete-example-segmentation-pipeline","title":"Complete Example: Segmentation Pipeline","text":"<p>Here\u2019s how adapters work together in a complete segmentation pipeline:</p> <pre><code>system:\n  adapters:\n    train:\n      # 1. Extract 'image' and 'mask' from the batch dictionary.\n      batch:\n        _target_: lighter.adapters.BatchAdapter\n        input_accessor: \"image\"\n        target_accessor: \"mask\"\n        identifier_accessor: \"patient_id\"\n\n      # 2. Pass prediction and target to the loss function and apply softmax.\n      criterion:\n        _target_: lighter.adapters.CriterionAdapter\n        pred_argument: 0\n        target_argument: 1\n        pred_transforms:\n          - _target_: torch.nn.functional.softmax\n            dim: 1\n\n      # 3. Pass prediction and target to metrics by name and apply argmax.\n      metrics:\n        _target_: lighter.adapters.MetricsAdapter\n        pred_argument: \"preds\"\n        target_argument: \"target\"\n        pred_transforms:\n          - _target_: torch.argmax\n            dim: 1\n\n    # 4. Reuse the same batch adapter for validation.\n    val:\n      batch: \"%system::adapters::train::batch\"\n      # Criterion and Metrics adapters for 'val' would also be defined here.\n</code></pre>"},{"location":"how-to/adapters/#recap-and-next-steps","title":"Recap and Next Steps","text":"<p>Adapters are what make Lighter truly flexible:</p> <p>\u2705 Key Benefits:</p> <ul> <li>Handle any data format without code changes</li> <li>Connect incompatible components seamlessly</li> <li>Transform data at the right pipeline stage</li> <li>Debug and monitor data flow easily</li> </ul> <p>\ud83c\udfaf Best Practices:</p> <ul> <li>Keep transforms simple and composable</li> <li>Move expensive operations to datasets</li> <li>Use debug prints during development</li> <li>Reuse configurations with YAML anchors</li> </ul>"},{"location":"how-to/adapters/#related-guides","title":"Related Guides","text":"<ul> <li>Metrics - Using MetricsAdapter</li> <li>Writers - Using LoggingAdapter</li> <li>Inferers - Inference-time adaptation</li> </ul>"},{"location":"how-to/configuration/","title":"Configuration Reference","text":"<p>Lighter uses Sparkwheel for configuration\u2014a powerful YAML-based system supporting references, expressions, and object instantiation.</p> <p>Complete Documentation</p> <p>This page covers Lighter-specific patterns and common usage. For complete Sparkwheel syntax, advanced features, and detailed examples, see the Sparkwheel documentation.</p>"},{"location":"how-to/configuration/#quick-reference","title":"Quick Reference","text":"Symbol Purpose Sparkwheel Docs <code>_target_</code> Instantiate a class Instantiation <code>@path::to::value</code> Resolved reference (instantiated object) References <code>%path::to::value</code> Raw reference (unprocessed YAML) References <code>$expression</code> Evaluate Python expression Expressions <code>::</code> Path notation (navigate config) Basics <code>.</code> Access Python attributes Expressions <code>=key:</code> Replace operator (override merge) Operators <code>~key:</code> Delete operator Operators"},{"location":"how-to/configuration/#lighter-configuration-structure","title":"Lighter Configuration Structure","text":"<p>Every Lighter config has two mandatory sections:</p> <pre><code>trainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 10\n\nsystem:\n  _target_: lighter.System\n  model: ...\n  criterion: ...\n  optimizer: ...\n  dataloaders: ...\n</code></pre> <p>Optional sections: <pre><code>_requires_:        # Import Python modules\nproject: ./path    # Custom module directory\nvars: ...          # Variables for reuse\nargs: ...          # Stage-specific arguments (fit, test, etc.)\n</code></pre></p>"},{"location":"how-to/configuration/#essential-syntax","title":"Essential Syntax","text":""},{"location":"how-to/configuration/#_target_-instantiate-classes","title":"<code>_target_</code>: Instantiate Classes","text":"<pre><code>model:\n  _target_: torchvision.models.resnet18\n  num_classes: 10\n</code></pre> <p>Equivalent to: <code>torchvision.models.resnet18(num_classes=10)</code></p> <p>Learn more \u2192</p>"},{"location":"how-to/configuration/#and-references","title":"<code>@</code> and <code>%</code>: References","text":"Type Syntax Use Case Resolved (<code>@</code>) <code>@system::optimizer</code> Pass actual object instances Raw (<code>%</code>) <code>%system::metrics::train</code> Reuse config to create new instances <p>Example: <pre><code>scheduler:\n  _target_: torch.optim.lr_scheduler.StepLR\n  optimizer: \"@system::optimizer\"  # Resolved: actual optimizer object\n\nmetrics:\n  train:\n    - _target_: torchmetrics.Accuracy\n      task: multiclass\n      num_classes: 10\n  val: \"%system::metrics::train\"  # Raw: creates new instance\n</code></pre></p> <p>Learn more \u2192</p>"},{"location":"how-to/configuration/#expressions","title":"<code>$</code>: Expressions","text":"<p>Evaluate Python in configs:</p> <pre><code>optimizer:\n  _target_: torch.optim.Adam\n  params: \"$@system::model.parameters()\"  # Call model.parameters()\n  lr: \"$0.001 * 2\"  # Result: 0.002\n</code></pre> <p>Learn more \u2192</p>"},{"location":"how-to/configuration/#path-notation","title":"<code>::</code>: Path Notation","text":"<p>Navigate nested configs:</p> <pre><code>@system::model                    # Access model\n@system::optimizer::lr            # Access nested value\n%::train::batch_size              # Relative reference (sibling)\n</code></pre> <p>Learn more \u2192</p>"},{"location":"how-to/configuration/#cli-overrides","title":"CLI Overrides","text":"<p>Override any config value from command line:</p> <pre><code># Simple override\nlighter fit config.yaml trainer::max_epochs=100\n\n# Nested values\nlighter fit config.yaml system::optimizer::lr=0.001\n\n# Multiple overrides\nlighter fit config.yaml \\\n  trainer::max_epochs=100 \\\n  system::optimizer::lr=0.001 \\\n  trainer::devices=4\n</code></pre> <p>Learn more \u2192</p>"},{"location":"how-to/configuration/#merging-configs","title":"Merging Configs","text":"<p>Combine multiple YAML files for modular experiments:</p> <pre><code># Merge base + experiment\nlighter fit base.yaml,experiment.yaml\n\n# Compose from modules\nlighter fit base.yaml,models/resnet.yaml,data/cifar10.yaml\n</code></pre>"},{"location":"how-to/configuration/#default-merging-behavior","title":"Default Merging Behavior","text":"<p>Dictionaries merge recursively: <pre><code># base.yaml\ntrainer:\n  max_epochs: 10\n  devices: 1\n\n# experiment.yaml\ntrainer:\n  max_epochs: 100  # Overrides\n  accelerator: gpu  # Adds\n\n# Result: max_epochs=100, devices=1, accelerator=gpu\n</code></pre></p> <p>Lists extend (append): <pre><code># base.yaml\ntrainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n\n# experiment.yaml\ntrainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.EarlyStopping\n\n# Result: Both callbacks present\n</code></pre></p>"},{"location":"how-to/configuration/#override-merging-and","title":"Override Merging: <code>=</code> and <code>~</code>","text":"<p>Replace with <code>=</code>: <pre><code># experiment.yaml\ntrainer:\n  =callbacks:  # Replace instead of extend\n    - _target_: pytorch_lightning.callbacks.RichProgressBar\n</code></pre></p> <p>Delete with <code>~</code>: <pre><code># Delete entire key\ntrainer:\n  ~callbacks: null\n\n# Delete list items\ntrainer:\n  ~callbacks: [1, 3]  # Delete indices 1 and 3\n\n# Delete dict keys\nsystem:\n  ~dataloaders: [\"train\", \"test\"]\n</code></pre></p> <p>Complete merging reference \u2192</p>"},{"location":"how-to/configuration/#common-lighter-patterns","title":"Common Lighter Patterns","text":""},{"location":"how-to/configuration/#pattern-1-model-optimizer","title":"Pattern 1: Model \u2192 Optimizer","text":"<pre><code>system:\n  model:\n    _target_: torchvision.models.resnet18\n    num_classes: 10\n\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n</code></pre>"},{"location":"how-to/configuration/#pattern-2-optimizer-scheduler","title":"Pattern 2: Optimizer \u2192 Scheduler","text":"<pre><code>system:\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n\n  scheduler:\n    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n    optimizer: \"@system::optimizer\"\n    factor: 0.5\n</code></pre>"},{"location":"how-to/configuration/#pattern-3-reusing-configurations","title":"Pattern 3: Reusing Configurations","text":"<pre><code>system:\n  metrics:\n    train:\n      - _target_: torchmetrics.Accuracy\n        task: multiclass\n        num_classes: 10\n    val: \"%system::metrics::train\"  # Reuse\n\n  dataloaders:\n    train:\n      _target_: torch.utils.data.DataLoader\n      batch_size: 128\n      num_workers: 4\n    val:\n      _target_: torch.utils.data.DataLoader\n      batch_size: \"%::train::batch_size\"  # Relative reference\n      num_workers: \"%::train::num_workers\"\n</code></pre>"},{"location":"how-to/configuration/#pattern-4-variables-for-reuse","title":"Pattern 4: Variables for Reuse","text":"<pre><code>vars:\n  batch_size: 32\n  num_classes: 10\n  base_lr: 0.001\n\nsystem:\n  model:\n    _target_: torchvision.models.resnet18\n    num_classes: \"%vars::num_classes\"\n\n  optimizer:\n    lr: \"%vars::base_lr\"\n\n  dataloaders:\n    train:\n      batch_size: \"%vars::batch_size\"\n</code></pre>"},{"location":"how-to/configuration/#pattern-5-stage-specific-arguments","title":"Pattern 5: Stage-Specific Arguments","text":"<pre><code>args:\n  fit:\n    ckpt_path: null  # Start from scratch\n  test:\n    ckpt_path: \"checkpoints/best.ckpt\"\n  predict:\n    ckpt_path: \"checkpoints/best.ckpt\"\n    return_predictions: true\n</code></pre> <p>Override from CLI: <pre><code>lighter test config.yaml args::test::ckpt_path=\"other.ckpt\"\n</code></pre></p>"},{"location":"how-to/configuration/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"how-to/configuration/#1-resolved-vs-raw-reference","title":"1. Resolved vs Raw Reference","text":"<pre><code># \u274c Wrong: Shares same instance\nmetrics:\n  val: \"@system::metrics::train\"\n\n# \u2705 Correct: Creates new instance\nmetrics:\n  val: \"%system::metrics::train\"\n</code></pre>"},{"location":"how-to/configuration/#2-path-notation-vs-python-attributes","title":"2. Path Notation vs Python Attributes","text":"<pre><code># \u274c Wrong: :: is for config paths\nparams: \"$@system::model::parameters()\"\n\n# \u2705 Correct: . is for Python attributes\nparams: \"$@system::model.parameters()\"\n</code></pre>"},{"location":"how-to/configuration/#3-missing-for-expressions","title":"3. Missing $ for Expressions","text":"<pre><code># \u274c Wrong: Treated as string\nbatch_size: \"@vars::base_batch * 2\"\n\n# \u2705 Correct: Evaluated\nbatch_size: \"$%vars::base_batch * 2\"\n</code></pre>"},{"location":"how-to/configuration/#advanced-features","title":"Advanced Features","text":"<p>Refer to Sparkwheel documentation for advanced usage.</p>"},{"location":"how-to/configuration/#next-steps","title":"Next Steps","text":"<ul> <li>Running Experiments - Execute training, testing, prediction</li> <li>Configuration Recipes - Ready-to-use patterns</li> <li>Troubleshooting - Debug config errors</li> <li>Sparkwheel Documentation - Complete reference</li> </ul>"},{"location":"how-to/experiment_tracking/","title":"Experiment Tracking","text":"<p>Lighter provides comprehensive experiment tracking through PyTorch Lightning loggers and Writer callbacks. This guide covers what's logged automatically, how to configure loggers, and how to add custom logging.</p>"},{"location":"how-to/experiment_tracking/#what-lighter-logs-automatically","title":"What Lighter Logs Automatically","text":"<p>Lighter's System class automatically logs the following metrics without any configuration:</p>"},{"location":"how-to/experiment_tracking/#1-loss-values","title":"1. Loss Values","text":"<p>Logged in: train and val modes (test mode doesn't compute loss by default)</p> <pre><code>{mode}/loss/step    # Per-batch loss\n{mode}/loss/epoch   # Epoch-averaged loss\n</code></pre> <p>For dict-based losses (multi-task learning), all sublosses are logged:</p> <pre><code>{mode}/loss/total/step\n{mode}/loss/total/epoch\n{mode}/loss/classification/step\n{mode}/loss/classification/epoch\n{mode}/loss/segmentation/step\n{mode}/loss/segmentation/epoch\n</code></pre> <p>Code reference: <code>src/lighter/system.py:194-202</code></p>"},{"location":"how-to/experiment_tracking/#2-metrics","title":"2. Metrics","text":"<p>Logged in: train, val, and test modes (predict mode doesn't compute metrics)</p> <pre><code>{mode}/metrics/{metric_name}/step\n{mode}/metrics/{metric_name}/epoch\n</code></pre> <p>All metrics defined in your config are automatically logged with both step-level and epoch-level aggregation.</p> <p>Code reference: <code>src/lighter/system.py:205-208</code></p>"},{"location":"how-to/experiment_tracking/#3-optimizer-statistics","title":"3. Optimizer Statistics","text":"<p>Logged in: train mode only, once per epoch (at the beginning)</p> <pre><code>train/lr         # Learning rate\ntrain/momentum   # If using SGD with momentum\ntrain/beta1      # If using Adam/AdamW\ntrain/beta2      # If using Adam/AdamW\n</code></pre> <p>This automatic logging helps you track learning rate schedules and optimizer behavior without any additional configuration.</p> <p>Code reference: <code>src/lighter/system.py:210-213</code></p>"},{"location":"how-to/experiment_tracking/#4-hyperparameters","title":"4. Hyperparameters","text":"<p>The Runner automatically logs all configuration parameters (the entire YAML config) to the logger at the start of training. This ensures full reproducibility.</p> <p>Code reference: <code>src/lighter/engine/runner.py:143-146</code></p>"},{"location":"how-to/experiment_tracking/#logger-configuration","title":"Logger Configuration","text":"<p>Lighter uses PyTorch Lightning's logger system. You can configure any Lightning-compatible logger in your config.</p>"},{"location":"how-to/experiment_tracking/#tensorboard-built-in","title":"TensorBoard (Built-in)","text":"<pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.TensorBoardLogger\n    save_dir: logs\n    name: my_experiment\n    version: null  # Auto-incrementing version\n</code></pre> <pre><code># View logs\ntensorboard --logdir logs\n</code></pre>"},{"location":"how-to/experiment_tracking/#weights-biases","title":"Weights &amp; Biases","text":"<pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.WandbLogger\n    project: my_project\n    name: experiment_name\n    save_dir: logs\n</code></pre>"},{"location":"how-to/experiment_tracking/#mlflow","title":"MLflow","text":"<pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.MLFlowLogger\n    experiment_name: my_experiment\n    tracking_uri: file:./mlruns\n</code></pre>"},{"location":"how-to/experiment_tracking/#csv-logger","title":"CSV Logger","text":"<pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.CSVLogger\n    save_dir: logs\n    name: my_experiment\n</code></pre>"},{"location":"how-to/experiment_tracking/#multiple-loggers","title":"Multiple Loggers","text":"<pre><code>trainer:\n  logger:\n    - _target_: pytorch_lightning.loggers.TensorBoardLogger\n      save_dir: logs\n    - _target_: pytorch_lightning.loggers.WandbLogger\n      project: my_project\n</code></pre> <p>For advanced logging features, see PyTorch Lightning Logger docs.</p>"},{"location":"how-to/experiment_tracking/#writer-callbacks-for-predictions","title":"Writer Callbacks for Predictions","text":"<p>While loggers handle scalar metrics, Writer callbacks save predictions, inputs, and targets to disk. Writers are triggered automatically after each batch in val, test, and predict modes.</p>"},{"location":"how-to/experiment_tracking/#available-writers","title":"Available Writers","text":"<p>Lighter provides several built-in writers in <code>lighter.callbacks.writer</code>:</p> <ul> <li>FileWriter: Save individual files (images, arrays)</li> <li>TableWriter: Save predictions in tabular format (CSV, Parquet)</li> </ul> <p>For detailed usage, see the Writers Guide.</p>"},{"location":"how-to/experiment_tracking/#when-writers-are-triggered","title":"When Writers Are Triggered","text":"<p>Writers are batch-level callbacks that run after each batch in val/test/predict modes:</p> <pre><code>For each batch in validation/test/predict:\n  1. System._step() computes predictions\n  2. Output dict is returned to callbacks\n  3. Writer callbacks process the dict\n  4. Files are written to disk\n</code></pre> <p>This allows you to save all predictions without accumulating them in memory.</p>"},{"location":"how-to/experiment_tracking/#writer-memory-management","title":"Writer Memory Management","text":"<p>Writers actively clear predictions from the output dictionary after processing to save CPU memory. This is especially important for large-scale inference.</p> <p>Code reference: <code>src/lighter/callbacks/writer.py:141-143</code></p>"},{"location":"how-to/experiment_tracking/#custom-logging-strategies","title":"Custom Logging Strategies","text":""},{"location":"how-to/experiment_tracking/#strategy-1-logging-additional-scalars","title":"Strategy 1: Logging Additional Scalars","text":"<p>To log custom values, extend the System class and override <code>_log_stats</code>:</p> my_project/custom_system.py<pre><code>from lighter.system import System\n\nclass CustomSystem(System):\n    def _log_stats(self, loss, metrics, batch_idx):\n        # Call parent to log standard metrics\n        super()._log_stats(loss, metrics, batch_idx)\n\n        # Log custom values\n        if self.mode == \"train\":\n            # Example: Log gradient norms\n            grad_norm = self._compute_gradient_norm()\n            self.log(f\"{self.mode}/grad_norm\", grad_norm)\n\n            # Example: Log model statistics\n            self.log(f\"{self.mode}/model_mean_weight\",\n                    self.model.fc.weight.mean())\n\n    def _compute_gradient_norm(self):\n        total_norm = 0.0\n        for p in self.model.parameters():\n            if p.grad is not None:\n                total_norm += p.grad.data.norm(2).item() ** 2\n        return total_norm ** 0.5\n</code></pre> <p>Use in config:</p> <pre><code>system:\n  _target_: my_project.custom_system.CustomSystem\n  model: ...\n  # ... other components\n</code></pre>"},{"location":"how-to/experiment_tracking/#strategy-2-conditional-logging","title":"Strategy 2: Conditional Logging","text":"<p>Log different metrics based on mode or epoch:</p> my_project/conditional_system.py<pre><code>from lighter.system import System\n\nclass ConditionalSystem(System):\n    def _log_stats(self, loss, metrics, batch_idx):\n        super()._log_stats(loss, metrics, batch_idx)\n\n        # Only log expensive metrics every N epochs\n        if self.current_epoch % 10 == 0:\n            if self.mode == \"val\":\n                self.log(f\"{self.mode}/expensive_metric\",\n                        self._compute_expensive_metric())\n\n    def _compute_expensive_metric(self):\n        # Expensive computation here\n        pass\n</code></pre>"},{"location":"how-to/experiment_tracking/#strategy-3-logging-imagesmedia","title":"Strategy 3: Logging Images/Media","text":"<p>For image logging, use the logger directly:</p> my_project/vision_system.py<pre><code>from lighter.system import System\nimport torch\n\nclass VisionSystem(System):\n    def on_validation_epoch_end(self):\n        # Log sample predictions as images\n        if self.trainer.logger is not None:\n            sample_input = self.validation_samples[:8]  # 8 images\n            sample_pred = self.model(sample_input)\n\n            # Log to TensorBoard\n            if hasattr(self.trainer.logger.experiment, 'add_images'):\n                self.trainer.logger.experiment.add_images(\n                    'val/predictions',\n                    sample_pred,\n                    self.current_epoch\n                )\n</code></pre>"},{"location":"how-to/experiment_tracking/#integration-system-logger-and-writers","title":"Integration: System, Logger, and Writers","text":"<p>Understanding how these components work together:</p> <pre><code>Training Loop (System)\n  \u2193\nAutomatic Logging (System._log_stats)\n  \u251c\u2500\u2192 Logger receives scalar metrics\n  \u2514\u2500\u2192 TensorBoard/W&amp;B/MLflow displays them\n  \u2193\nStep Output (System._step returns dict)\n  \u2193\nCallbacks (Writers)\n  \u2514\u2500\u2192 Save predictions/inputs/targets to files\n</code></pre>"},{"location":"how-to/experiment_tracking/#example-complete-tracking-setup","title":"Example: Complete Tracking Setup","text":"complete_tracking.yaml<pre><code>trainer:\n  _target_: pytorch_lightning.Trainer\n\n  # Multiple loggers for comprehensive tracking\n  logger:\n    - _target_: pytorch_lightning.loggers.TensorBoardLogger\n      save_dir: logs\n      name: my_experiment\n      version: null\n\n    - _target_: pytorch_lightning.loggers.WandbLogger\n      project: my_project\n      name: my_experiment\n      save_dir: logs\n      log_model: true\n\n  # Logging frequency\n  log_every_n_steps: 50\n\n  # Callbacks for saving predictions\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.LearningRateMonitor\n      logging_interval: epoch\n\n    - _target_: lighter.callbacks.writer.FileWriter\n      write_dir: predictions\n      predicates: [\"val\", \"test\"]\n\nsystem:\n  _target_: lighter.System\n  # ... rest of config\n</code></pre>"},{"location":"how-to/experiment_tracking/#advanced-logger-specific-features","title":"Advanced: Logger-Specific Features","text":""},{"location":"how-to/experiment_tracking/#tensorboard-hyperparameter-tuning","title":"TensorBoard: Hyperparameter Tuning","text":"<p>TensorBoard can visualize hyperparameter search results:</p> <pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.TensorBoardLogger\n    save_dir: logs\n    name: hparam_search\n    default_hp_metric: true  # Enable HP tracking\n\n# Vary hyperparameters across runs\nsystem:\n  optimizer:\n    lr: 0.001  # Change this across experiments\n</code></pre> <p>View in TensorBoard: <pre><code>tensorboard --logdir logs\n# Navigate to HPARAMS tab\n</code></pre></p>"},{"location":"how-to/experiment_tracking/#wb-artifact-tracking","title":"W&amp;B: Artifact Tracking","text":"<p>Track model checkpoints as W&amp;B artifacts:</p> <pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.WandbLogger\n    project: my_project\n    log_model: all  # 'all', True, False\n\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n      dirpath: checkpoints\n      save_top_k: 3\n</code></pre>"},{"location":"how-to/experiment_tracking/#mlflow-model-registry","title":"MLflow: Model Registry","text":"<p>Integrate with MLflow's model registry:</p> <pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.MLFlowLogger\n    experiment_name: my_experiment\n    tracking_uri: file:./mlruns\n    log_model: true  # Log as MLflow model\n</code></pre>"},{"location":"how-to/experiment_tracking/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/experiment_tracking/#issue-no-logs-appearing","title":"Issue: No logs appearing","text":"<p>Solution: Check that logger is not None:</p> <pre><code>trainer:\n  logger: ...  # Make sure this is configured\n</code></pre>"},{"location":"how-to/experiment_tracking/#issue-metrics-not-syncing-across-gpus","title":"Issue: Metrics not syncing across GPUs","text":"<p>Solution: Lighter automatically sets <code>sync_dist=True</code> for epoch-level metrics. For custom metrics, ensure you use <code>on_epoch=True</code>:</p> <pre><code>self.log(\"custom_metric\", value, on_epoch=True, sync_dist=True)\n</code></pre>"},{"location":"how-to/experiment_tracking/#issue-too-much-logging-slowing-down-training","title":"Issue: Too much logging slowing down training","text":"<p>Solution: Reduce logging frequency:</p> <pre><code>trainer:\n  log_every_n_steps: 100  # Default is 50\n</code></pre>"},{"location":"how-to/experiment_tracking/#issue-writer-memory-usage-too-high","title":"Issue: Writer memory usage too high","text":"<p>Solution: Writers automatically clear predictions. If still high, process predictions in smaller batches:</p> <pre><code>system:\n  dataloaders:\n    predict:\n      batch_size: 16  # Reduce batch size\n</code></pre>"},{"location":"how-to/experiment_tracking/#best-practices","title":"Best Practices","text":"<ol> <li>Use multiple loggers: Combine TensorBoard (local) with W&amp;B/MLflow (team)</li> <li>Log hyperparameters: Automatic in Lighter, but verify they appear in your logger</li> <li>Monitor optimizer stats: Use <code>LearningRateMonitor</code> callback for detailed tracking</li> <li>Separate concerns: Use Logger for scalars, Writers for predictions</li> <li>Version your experiments: Use timestamps or version numbers in logger names</li> <li>Document runs: Add notes/tags to experiments in W&amp;B or MLflow</li> </ol>"},{"location":"how-to/experiment_tracking/#summary","title":"Summary","text":"<p>Lighter provides comprehensive tracking out of the box:</p> <ul> <li>Automatic: Loss, metrics, optimizer stats, hyperparameters</li> <li>Flexible: Support for all PyTorch Lightning loggers</li> <li>Scalable: Batch-level Writers prevent memory issues</li> <li>Extensible: Easy to add custom logging via System subclassing</li> </ul> <p>For most use cases, you just need to configure a logger\u2014everything else is automatic!</p>"},{"location":"how-to/experiment_tracking/#related-guides","title":"Related Guides","text":"<ul> <li>System Internals - Understanding automatic logging</li> <li>Writers - Saving predictions to disk</li> <li>Configuration Guide - Logger configuration syntax</li> <li>Run Guide - Running experiments</li> </ul>"},{"location":"how-to/freezers/","title":"Freezers: Smart Layer Management for Transfer Learning","text":"<p>Freezing layers is a powerful technique that can accelerate training, prevent catastrophic forgetting, and improve model performance. Lighter's <code>Freezer</code> callback gives you fine-grained control over which layers train and when.</p>"},{"location":"how-to/freezers/#quick-start","title":"Quick Start \ud83d\ude80","text":"config.yaml<pre><code># Freeze encoder for first 10 epochs, then unfreeze\ntrainer:\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.encoder\"]  # What to freeze\n      until_epoch: 10                      # When to unfreeze\n</code></pre>"},{"location":"how-to/freezers/#why-freeze-layers","title":"Why Freeze Layers? \ud83e\udd14","text":"Scenario Strategy Benefit Transfer Learning Freeze pretrained layers initially Preserve learned features Limited Data Freeze most layers Prevent overfitting Fine-tuning Gradual unfreezing Stable adaptation Multi-stage Training Stage-wise freezing Focused learning <p>Freezing Strategies:</p> <p><code>Freezer</code> callback offers flexible layer freezing strategies:</p> <ol> <li> <p>Freeze by Name Prefix (<code>name_starts_with</code>):</p> <ul> <li>Freeze parameters with names starting with prefix/prefixes in <code>name_starts_with</code> arg.</li> <li>Useful for freezing modules or layer groups.</li> <li> <p>Example:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.encoder\", \"model.embedding\"] # Freeze encoder/embedding layers\n      until_epoch: 5\n</code></pre> <p>Config freezes parameters starting with <code>\"model.encoder\"</code> or <code>\"model.embedding\"</code> until epoch 5.</p> </li> </ul> </li> <li> <p>Freeze by Exact Name (<code>names</code>):</p> <ul> <li>Freeze specific parameters by name using <code>names</code> arg.</li> <li>For fine-grained control over individual layers/parameters.</li> <li> <p>Example:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      names: [\"model.classifier.weight\", \"model.classifier.bias\"] # Freeze classifier layer weights/bias\n      until_step: 1000\n</code></pre> <p>Config freezes parameters named <code>\"model.classifier.weight\"</code> and <code>\"model.classifier.bias\"</code> until step 1000.</p> </li> </ul> </li> <li> <p>Exclude Layers from Freezing (<code>except_names</code>, <code>except_name_starts_with</code>):</p> <ul> <li>Exclude layers from freezing (even if matched by <code>name_starts_with</code> or <code>names</code>) using <code>except_names</code>/<code>except_name_starts_with</code>.</li> <li>Selectively unfreeze parts of otherwise frozen module.</li> <li> <p>Example:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.encoder\"]           # Freeze all encoder layers\n      except_name_starts_with: [\"model.encoder.layer5\"] # Except \"model.encoder.layer5\" layers\n      until_epoch: 7\n</code></pre> <p>Config freezes <code>\"model.encoder\"</code> layers except <code>\"model.encoder.layer5\"</code>, keeping layer5 trainable.</p> </li> </ul> </li> <li> <p>Unfreezing after Condition (<code>until_step</code>, <code>until_epoch</code>):</p> <ul> <li><code>until_step</code>: Unfreeze layers after training step.</li> <li><code>until_epoch</code>: Unfreeze layers after epoch.</li> <li>Use either/both <code>until_step</code>/<code>until_epoch</code>. Unfreezes when either condition met.</li> <li>Omit <code>until_step</code>/<code>until_epoch</code> to freeze layers for entire training (or manual unfreezing).</li> <li> <p>Example:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.backbone\"]\n      until_epoch: 5    # Unfreeze after epoch 5\n      until_step: 5000  # OR after step 5000\n</code></pre> <p>Config unfreezes <code>\"model.backbone\"</code> layers after epoch 5 OR step 5000 (whichever first).</p> </li> </ul> </li> </ol> <p>Combining Freezing Strategies:</p> <p>Combine <code>Freezer</code> callbacks in <code>config.yaml</code> for complex freezing schedules. E.g., initial backbone freeze, gradual part unfreezing.</p> <p>Example: Gradual Layer Unfreezing</p> config.yaml<pre><code>trainer:\n  callbacks:\n    # Unfreeze backbone layers at epoch 5\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.backbone\"]\n      until_epoch: 5\n    # Unfreeze early encoder layers at epoch 10\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.encoder.layer1\", \"model.encoder.layer2\"]\n      until_epoch: 10\n</code></pre> <p>Example: 2 <code>Freezer</code> callbacks for gradual unfreezing - initial backbone freeze, gradual encoder layer unfreezing.</p> <p>Inspecting Frozen Layers:</p> <p><code>Freezer</code> callback logs freezing info during training. Check logs (TensorBoard/console) to verify.</p> <p><code>Freezer</code> Callback Use Cases:</p> <ul> <li>Transfer Learning: Freeze pre-trained model's early layers, train head.</li> <li>Fine-tuning: Gradually unfreeze pre-trained layers.</li> <li>Training Stability: Initial layer freezing.</li> <li>Regularization: Layer freezing for regularization.</li> <li>Efficient Training: Reduce training time/memory.</li> </ul>"},{"location":"how-to/freezers/#practical-example-transfer-learning","title":"Practical Example: Transfer Learning","text":"<pre><code>trainer:\n  callbacks:\n    # Stage 1: Train only the classifier head\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.backbone\"]  # Freeze pretrained backbone\n      until_epoch: 5\n\n    # Stage 2: Fine-tune top layers\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.backbone.layer1\", \"model.backbone.layer2\"]\n      until_epoch: 10  # Keep early layers frozen longer\n</code></pre> <p>This progressive unfreezing strategy: 1. Epochs 0-5: Only train the classifier head 2. Epochs 5-10: Unfreeze and train top backbone layers 3. Epochs 10+: Train entire model</p>"},{"location":"how-to/freezers/#advanced-pattern-discriminative-learning-rates","title":"Advanced Pattern: Discriminative Learning Rates","text":"<pre><code># Combine freezing with different learning rates\ntrainer:\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      name_starts_with: [\"model.backbone\"]\n      until_epoch: 5\n\nsystem:\n  optimizer:\n    _target_: torch.optim.Adam\n    params:\n      - params: \"$[p for n, p in @system::model.named_parameters() if 'backbone' in n]\"\n        lr: 0.0001  # Lower LR for pretrained layers\n      - params: \"$[p for n, p in @system::model.named_parameters() if 'head' in n]\"\n        lr: 0.001   # Higher LR for new layers\n</code></pre>"},{"location":"how-to/freezers/#troubleshooting-guide","title":"Troubleshooting Guide \ud83d\udd27","text":"Issue Solution Parameters not freezing Print parameter names to verify: <code>for n, p in model.named_parameters(): print(n, p.requires_grad)</code> Performance drops after unfreezing Reduce LR with scheduler at unfreeze epoch BatchNorm issues Keep BN layers in eval mode even when unfrozen Memory increases Use gradient checkpointing or accumulation Don't know what to freeze Print model structure with <code>model.named_children()</code>"},{"location":"how-to/freezers/#best-practices","title":"Best Practices \ud83c\udfc6","text":"<ol> <li>Start Conservative: Freeze more layers initially, then gradually unfreeze</li> <li>Monitor Metrics: Track validation loss when layers unfreeze</li> <li>Use Warmup: Apply learning rate warmup after unfreezing</li> <li>Reduce LR: Lower learning rate when unfreezing pretrained layers</li> <li>Test First: Verify which layers to freeze by printing model structure</li> </ol>"},{"location":"how-to/freezers/#quick-reference-card","title":"Quick Reference Card \ud83d\udcc4","text":"<pre><code># Freeze by prefix\nname_starts_with: [\"model.encoder\", \"model.embeddings\"]\n\n# Freeze specific layers\nnames: [\"model.layer1.weight\", \"model.layer1.bias\"]\n\n# Exclude from freezing\nexcept_names: [\"model.encoder.final_layer.weight\"]\nexcept_name_starts_with: [\"model.encoder.norm\"]\n\n# Unfreeze timing\nuntil_epoch: 10        # After epoch 10\nuntil_step: 1000       # After step 1000\n# Both: unfreeze when EITHER condition is met\n</code></pre>"},{"location":"how-to/freezers/#recap-and-next-steps","title":"Recap and Next Steps","text":"<p>\u2705 You've Mastered:</p> <ul> <li>Strategic layer freezing for transfer learning</li> <li>Progressive unfreezing techniques</li> <li>Troubleshooting common freezing issues</li> <li>Best practices for stable training</li> </ul> <p>\ud83c\udfaf Key Insights:</p> <ul> <li>Freezing preserves pretrained knowledge</li> <li>Gradual unfreezing prevents catastrophic forgetting</li> <li>Monitor performance when changing freeze status</li> <li>Combine with appropriate learning rates</li> </ul> <p>\ud83d\udca1 Pro Tip: Log which layers are frozen/unfrozen at each epoch for reproducibility!</p>"},{"location":"how-to/freezers/#related-guides","title":"Related Guides","text":"<ul> <li>Run Guide - Training workflows</li> <li>Configuration - Advanced config patterns</li> </ul>"},{"location":"how-to/inferers/","title":"Inferers: Bridging Training and Inference","text":"<p>Inferers adapt how your model processes data at inference time based on how it was trained and what your deployment needs are. Lighter's inferer system handles these adaptations seamlessly.</p>"},{"location":"how-to/inferers/#why-inferers-matter","title":"Why Inferers Matter \ud83c\udfaf","text":"<p>The way you train a model often differs from how you need to use it:</p> Training Scenario Inference Challenge Solution (Inferer) Trained on fixed-size patches Need to process full images Sliding Window - breaks large images into patches Trained on clean data Noisy test data Test-Time Augmentation - average multiple predictions Single model Need confidence scores Monte Carlo Dropout - uncertainty estimation Multiple models trained Want best performance Ensemble - combine predictions"},{"location":"how-to/inferers/#common-inference-patterns","title":"Common Inference Patterns","text":""},{"location":"how-to/inferers/#sliding-window-inference","title":"Sliding Window Inference","text":"<p>When to use: Your model was trained on fixed-size patches but you need to process larger images/volumes</p> <p>Why it works: The model only knows how to process the patch size it was trained on</p> <p>Example: A model trained on 256\u00d7256 patches from CT scans needs to process full 512\u00d7512\u00d7400 volumes</p>"},{"location":"how-to/inferers/#test-time-augmentation-tta","title":"Test-Time Augmentation (TTA)","text":"<p>When to use: You want more robust predictions and can afford extra compute time</p> <p>Why it works: Averaging predictions from augmented inputs reduces noise</p> <p>Example: Medical image segmentation where rotation/flip invariance improves boundaries</p>"},{"location":"how-to/inferers/#monte-carlo-dropout","title":"Monte Carlo Dropout","text":"<p>When to use: You need uncertainty estimates along with predictions</p> <p>Why it works: Dropout at inference creates an ensemble effect</p> <p>Example: Medical diagnosis where you need to know prediction confidence</p>"},{"location":"how-to/inferers/#configuring-inferers-in-lighter","title":"Configuring Inferers in Lighter","text":"<p>You can configure any custom inferer within the <code>system.inferer</code> section of your <code>config.yaml</code> file. The inferer can be any callable that takes the model and input, then returns predictions.</p>"},{"location":"how-to/inferers/#configuration","title":"Configuration","text":"<p>Here's an example of a basic inferer configuration:</p> config.yaml<pre><code>system:\n  inferer:\n    _target_: my_project.inferers.CustomInferer\n    # Add any arguments your inferer needs\n</code></pre> <p>When an inferer is configured, Lighter automatically uses it during the <code>forward</code> pass in validation, test, and predict modes.</p>"},{"location":"how-to/inferers/#implementing-a-custom-inferer","title":"Implementing a Custom Inferer","text":"<p>You can implement custom inference logic to handle:</p> <ul> <li>Advanced Ensembling Strategies: Implementing ensembling techniques beyond simple averaging.</li> <li>Sliding Window Inference: Processing large images in patches.</li> <li>Test-Time Augmentation: Averaging predictions across augmentations.</li> <li>Highly Specialized Output Processing: Tailoring output processing to your unique research problem.</li> </ul> <p>To implement a custom inferer in Lighter, you'll create a Python class that adheres to a specific structure.</p>"},{"location":"how-to/inferers/#custom-inferer-class-structure","title":"Custom Inferer Class Structure","text":"my_project/inferers/my_custom_inferer.py<pre><code>from typing import Any\n\nimport torch\nfrom torch.nn import Module\n\nclass MyCustomInferer:\n    def __init__(self, arg1, arg2, **kwargs):\n        \"\"\"\n        Initialize your custom inferer.\n\n        Args:\n            arg1: Custom argument 1.\n            arg2: Custom argument 2.\n            **kwargs: Additional keyword arguments.\n        \"\"\"\n        self.arg1 = arg1\n        self.arg2 = arg2\n        #... initialize any internal components...\n\n    def __call__(self, inputs: torch.Tensor, network: Module, *args: Any, **kwargs: Any) -&gt; torch.Tensor:\n        \"\"\"\n        Perform inference using your custom logic.\n\n        Args:\n            inputs: Input tensor(s) to the model.\n            network: The deep learning model (torch.nn.Module).\n            *args: Additional positional arguments (if needed).\n            **kwargs: Additional keyword arguments (if needed).\n\n        Returns:\n            torch.Tensor: The processed prediction tensor(s).\n        \"\"\"\n        # Implement your custom inference logic here\n        # This could include:\n        #   - Test-time augmentation\n        #   - Model ensembling\n        #   - Sliding window or patch-based inference\n        #   - Any other custom processing\n\n        # Example: Simple forward pass with optional post-processing\n        outputs = network(inputs, *args, **kwargs)\n        processed_outputs = self.post_process(outputs)\n        return processed_outputs\n\n    def post_process(self, outputs: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Optional post-processing of model outputs.\n\n        Args:\n            outputs (torch.Tensor): Raw model output tensor(s).\n\n        Returns:\n            torch.Tensor: Processed output tensor(s).\n        \"\"\"\n        # Implement post-processing logic if needed (e.g., thresholding, softmax)\n        return outputs\n</code></pre>"},{"location":"how-to/inferers/#key-components","title":"Key Components","text":"<ol> <li> <p><code>__init__</code>:</p> <ul> <li>This is the constructor of your inferer class.</li> <li>It takes any custom arguments that you can define in your <code>config.yaml</code>.</li> <li>Use this method to initialize any internal components or parameters your inferer needs.</li> </ul> </li> <li> <p><code>__call__</code>:</p> <ul> <li>This method makes your class callable like a function, enabling it to be used directly for inference.</li> <li>Arguments:<ul> <li><code>inputs (torch.Tensor)</code>: The input tensor(s) to your model.</li> <li><code>network (torch.nn.Module)</code>: Your deep learning model (equivalent to <code>self.model</code> in your <code>System</code>).</li> <li><code>*args</code>, <code>**kwargs</code>:  These allow you to pass additional arguments if required, although they are not typically used in inferers.</li> </ul> </li> <li>Logic:<ul> <li>This is where you implement your core inference logic.</li> <li>A common pattern is to perform a forward pass through your <code>network</code> using  <code>outputs = network(inputs)</code>.</li> <li>You can integrate various inference techniques here, such as TTA, ensembling, or sliding window inference.</li> <li>You can also call a <code>post_process</code> method to further refine the model's raw outputs.</li> </ul> </li> <li>Return Value:<ul> <li>This method must return the processed prediction tensor(s) as a <code>torch.Tensor</code>. This output will be used as the <code>pred</code> value in your validation, testing, or prediction steps.</li> </ul> </li> </ul> </li> <li> <p><code>post_process</code> (Optional):</p> <ul> <li>This is an optional method for applying post-processing operations to the model's raw outputs.</li> <li>You can use it for tasks like thresholding, applying a softmax function, or any other custom processing relevant to your problem.</li> <li>If no post-processing is required, you can simply return the <code>outputs</code> tensor directly.</li> </ul> </li> </ol>"},{"location":"how-to/inferers/#integrating-a-custom-inferer","title":"Integrating a Custom Inferer","text":"<ol> <li> <p>Save: Save your custom inferer class (e.g., <code>MyCustomInferer</code>) in a Python file within your project (e.g., <code>my_project/inferers/my_custom_inferer.py</code>).</p> </li> <li> <p>Configure:  In your <code>config.yaml</code>, specify the inferer within the <code>system.inferer</code> section, providing the path to your class and any necessary arguments for its <code>__init__</code> method:</p> config.yaml<pre><code>system:\n  inferer:\n    _target_: my_project.inferers.my_custom_inferer.MyCustomInferer\n    arg1: value1\n    arg2: value2\n</code></pre> <ul> <li><code>_target_</code>: Points to your custom inferer class.</li> <li><code>arg1</code> and <code>arg2</code>:  Arguments passed to your inferer's <code>__init__</code> method.</li> </ul> </li> </ol> <p>With this configuration, Lighter will create an instance of your custom inferer and use it during the appropriate stages of your experiment.</p>"},{"location":"how-to/inferers/#example-test-time-augmentation-inferer","title":"Example: Test-Time Augmentation Inferer","text":"<pre><code># my_project/inferers/tta_inferer.py\nimport torch\nimport torchvision.transforms.functional as TF\nfrom torch.nn import Module\n\nclass TTAInferer:\n    \"\"\"Test-Time Augmentation for robust predictions.\"\"\"\n    def __init__(self, num_augmentations=4, aggregate=\"mean\"):\n        self.num_augmentations = num_augmentations\n        self.aggregate = aggregate\n\n    def __call__(self, inputs: torch.Tensor, network: Module) -&gt; torch.Tensor:\n        predictions = []\n\n        # Define augmentations\n        augmentations = [\n            lambda x: x,  # Original\n            lambda x: TF.hflip(x),  # Horizontal flip\n            lambda x: TF.vflip(x),  # Vertical flip\n            lambda x: torch.rot90(x, k=2, dims=[-2, -1])  # 180 rotation\n        ]\n\n        for aug_fn in augmentations[:self.num_augmentations]:\n            # Apply augmentation\n            aug_input = aug_fn(inputs)\n\n            # Get prediction\n            with torch.no_grad():\n                pred = network(aug_input)\n\n            # Reverse augmentation on prediction\n            if aug_fn != augmentations[0]:  # Skip original\n                pred = aug_fn(pred)  # Most augmentations are self-inverse\n\n            predictions.append(pred)\n\n        # Aggregate predictions\n        stacked = torch.stack(predictions)\n        if self.aggregate == \"mean\":\n            return stacked.mean(dim=0)\n        elif self.aggregate == \"voting\":\n            votes = stacked.argmax(dim=-1)\n            return torch.mode(votes, dim=0)[0]\n        else:\n            return stacked.mean(dim=0)\n</code></pre> <p>Use in config: <pre><code>system:\n    inferer:\n        _target_: my_project.inferers.TTAInferer\n        num_augmentations: 4\n        aggregate: mean\n</code></pre></p>"},{"location":"how-to/inferers/#performance-tips","title":"Performance Tips \u26a1","text":"Optimization Technique Impact Batch TTA Process all augmentations in one batch 2-3x faster Mixed Precision Use <code>torch.cuda.amp.autocast()</code> 30-50% speedup Reduce Augmentations Use only most impactful transforms Proportional speedup"},{"location":"how-to/inferers/#choosing-the-right-inferer","title":"Choosing the Right Inferer","text":"<pre><code>graph TD\n    A[What was your model trained on?] --&gt; B{Training Setup}\n    B --&gt;|Fixed patches| C[Use Sliding Window]\n    B --&gt;|Full images| D{Memory constraints?}\n    D --&gt;|Yes| C\n    D --&gt;|No| E[Use Simple Inferer]\n\n    A --&gt; F{Need uncertainty?}\n    F --&gt;|Yes| G[Add MC Dropout]\n\n    A --&gt; H{Want robustness?}\n    H --&gt;|Yes| I[Add TTA]\n\n    A --&gt; J{Have multiple models?}\n    J --&gt;|Yes| K[Use Ensemble]\n</code></pre>"},{"location":"how-to/inferers/#configuration-examples","title":"Configuration Examples","text":""},{"location":"how-to/inferers/#model-trained-on-patches-full-image-inference","title":"Model Trained on Patches \u2192 Full Image Inference","text":"<pre><code># Model was trained on 128\u00d7128\u00d7128 patches\n# Now need to process 512\u00d7512\u00d7200 volumes\nsystem:\n  inferer:\n    _target_: monai.inferers.SlidingWindowInferer\n    roi_size: [128, 128, 128]  # Must match training patch size!\n    sw_batch_size: 4\n    overlap: 0.5  # 50% overlap for smooth predictions\n    mode: gaussian  # Smooth blending at boundaries\n</code></pre>"},{"location":"how-to/inferers/#adding-robustness-with-tta","title":"Adding Robustness with TTA","text":"<pre><code># Model trained normally, but test data is noisier\nsystem:\n  inferer:\n    _target_: my_project.inferers.TTAInferer\n    num_augmentations: 4  # Balance speed vs robustness\n    aggregate: mean  # Average predictions\n</code></pre>"},{"location":"how-to/inferers/#uncertainty-quantification-with-mc-dropout","title":"Uncertainty Quantification with MC Dropout","text":"<pre><code># Model has dropout layers, need confidence intervals\nsystem:\n  inferer:\n    _target_: my_project.inferers.MCDropoutInferer\n    num_samples: 20  # Multiple forward passes\n    return_std: true  # Return standard deviation as uncertainty\n</code></pre>"},{"location":"how-to/inferers/#related-guides","title":"Related Guides","text":"<ul> <li>Adapters - Transform inference outputs</li> <li>Writers - Save predictions</li> </ul>"},{"location":"how-to/metrics/","title":"Custom Metrics: Beyond Standard Evaluation","text":"<p>Metrics are the compass that guides your model development. While <code>torchmetrics</code> provides excellent built-in metrics, real-world projects often need custom evaluation logic. This guide shows you how to create powerful custom metrics that provide deep insights into your model's behavior.</p>"},{"location":"how-to/metrics/#quick-start-your-first-custom-metric-in-30-seconds","title":"Quick Start: Your First Custom Metric in 30 Seconds \ud83d\ude80","text":"<pre><code># my_project/metrics/weighted_accuracy.py\nfrom torchmetrics import Metric\nimport torch\n\nclass WeightedAccuracy(Metric):\n    \"\"\"Accuracy that cares more about certain classes.\"\"\"\n    def __init__(self, class_weights):\n        super().__init__()\n        self.class_weights = class_weights\n        self.add_state(\"weighted_correct\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n        self.add_state(\"total_weight\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n\n    def update(self, preds: torch.Tensor, target: torch.Tensor):\n        pred_classes = preds.argmax(dim=1)\n        correct = pred_classes == target\n        weights = torch.tensor([self.class_weights[t.item()] for t in target])\n        self.weighted_correct += (correct * weights).sum()\n        self.total_weight += weights.sum()\n\n    def compute(self):\n        return self.weighted_correct / self.total_weight\n</code></pre> <p>Use it in your config: <pre><code>system:\n  metrics:\n    val:\n      - _target_: my_project.metrics.WeightedAccuracy\n        class_weights: [1.0, 2.0, 5.0]  # Class 2 is 5x more important\n</code></pre></p>"},{"location":"how-to/metrics/#core-concepts-the-metric-trinity","title":"Core Concepts: The Metric Trinity \ud83c\udfc6","text":"<p>Every custom metric needs three essential components:</p> Component Purpose When Called 1. <code>add_state()</code> Register variables to track Once at initialization 2. <code>update()</code> Process batch &amp; accumulate stats Every batch 3. <code>compute()</code> Calculate final metric value End of epoch/validation <p>The lifecycle flow: 1. Initialize \u2192 Set up state variables 2. Update (repeated) \u2192 Process each batch 3. Compute \u2192 Calculate final metric</p>"},{"location":"how-to/metrics/#creating-a-custom-metric-step-by-step","title":"Creating a Custom Metric: Step-by-Step","text":"<p>Let's walk through the steps of creating a custom metric in Lighter using <code>torchmetrics</code>. We'll create a simple example custom metric called <code>MyCustomMetric</code> for binary classification, which calculates a variation of accuracy.</p> <ol> <li> <p>Subclass <code>torchmetrics.Metric</code>:     First, create a new Python file (e.g., <code>my_project/metrics/my_custom_metric.py</code>) within your project to define your custom metric class. Start by importing <code>torchmetrics.Metric</code> and subclassing it.</p> my_project/metrics/my_custom_metric.py<pre><code>from torchmetrics import Metric\nimport torch\n\nclass MyCustomMetric(Metric):\n    def __init__(self):\n        super().__init__()\n        # ... (state initialization will be added in the next step) ...\n\n    def update(self, preds: torch.Tensor, target: torch.Tensor):\n        # ... (update logic will be added in the next step) ...\n        pass\n\n    def compute(self):\n        # ... (compute logic will be added in the next step) ...\n        pass\n</code></pre> </li> <li> <p>Initialize Metric State with <code>add_state()</code>:     In the <code>__init__</code> method, use <code>self.add_state()</code> to initialize state variables for accumulated statistics. For <code>MyCustomMetric</code>, track correct and total predictions:</p> my_project/metrics/my_custom_metric.py<pre><code>from torchmetrics import Metric\nimport torch\n\nclass MyCustomMetric(Metric):\n    def __init__(self):\n        super().__init__()\n    self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\") # Tracks correct predictions\n    self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")   # Tracks total predictions\n</code></pre> <ul> <li>Registers \"correct\" state variable:<ul> <li>Initializes to a PyTorch tensor of 0.</li> <li><code>dist_reduce_fx=\"sum\"</code>: Reduces state across distributed processes by summing.</li> </ul> </li> <li>Registers \"total\" state variable:<ul> <li>Initializes to a PyTorch tensor of 0.</li> <li><code>dist_reduce_fx=\"sum\"</code>: Reduces state across distributed processes similarly.</li> </ul> </li> </ul> </li> <li> <p>Implement <code>update()</code> Method:     The <code>update()</code> method processes each batch of predictions and targets. For <code>MyCustomMetric</code>, implement the following:</p> <ol> <li>Convert probability predictions to binary (0/1).</li> <li>Count correct predictions and update state variables.</li> </ol> my_project/metrics/my_custom_metric.py<pre><code>from torchmetrics import Metric\nimport torch\n\nclass MyCustomMetric(Metric):\n    def __init__(self):\n        super().__init__()\n    self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n    self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n\ndef update(self, preds: torch.Tensor, target: torch.Tensor):\n    # 1. Convert probabilities to binary predictions\n    # Convert probabilities to binary (0/1).\n    #   - `binary_preds = (preds &gt;= 0.5).int()`: Converts probabilities to binary predictions (0 or 1). # commented out to avoid repetition\n\n    # 2. Count correct predictions and update state variables.\n    # Count correct predictions and update state variables.\n    #   - `self.correct += torch.sum(binary_preds == target)`: Increments `correct` state with batch's correct predictions. # commented out to avoid repetition\n    #   - `self.total += target.numel()`: Increments `total` state with batch size. # commented out to avoid repetition\n    self.correct += torch.sum(binary_preds == target)\n    self.total += target.numel()\n</code></pre> <ul> <li> <ol> <li>Convert probability predictions to binary (0/1).</li> </ol> </li> <li> <ol> <li>Count correct predictions and update state variables.</li> </ol> </li> </ul> </li> <li> <p>Implement <code>compute()</code> Method:     The <code>compute()</code> method calculates the final metric value at the epoch end. For <code>MyCustomMetric</code>, calculate custom accuracy:</p> <p>```python title=\"my_project/metrics/my_custom_metric.py\" from torchmetrics import Metric import torch</p> <p>class MyCustomMetric(Metric):     def init(self):         super().init()     self.add_state(\"correct\", default=torch.tensor(0), dist_reduce_fx=\"sum\")     self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")</p> <p>def update(self, preds: torch.Tensor, target: torch.Tensor):     binary_preds = (preds &gt;= 0.5).int()     self.correct += torch.sum(binary_preds == target)     self.total += target.numel()</p> <p>def compute(self):     # Returns custom accuracy: correct predictions / total predictions     return self.correct.float() / self.total ```</p> <ul> <li>Returns custom accuracy: correct predictions / total predictions</li> </ul> </li> <li> <p>Integrate with Lighter Configuration:     Reference your custom metric in <code>config.yaml</code> to use it during train/val/test.</p> <p>Example <code>config.yaml</code>:</p> config.yaml<pre><code>project: my_project/ # Project root directory\n\nsystem:\n  metrics:\n    train:\n      - _target_: torchmetrics.Accuracy\n      - _target_: my_project.metrics.MyCustomMetric # Use custom metric\n\n    val:\n      - _target_: torchmetrics.Accuracy\n      - _target_: my_project.metrics.MyCustomMetric\n</code></pre> <p>This config uses both built-in <code>Accuracy</code> and <code>MyCustomMetric</code> during train/val stages.</p> </li> </ol>"},{"location":"how-to/metrics/#practical-example-domain-specific-metric","title":"Practical Example: Domain-Specific Metric","text":"<pre><code>from torchmetrics import Metric\nimport torch\n\nclass DiceScore(Metric):\n    \"\"\"Dice coefficient for segmentation tasks.\"\"\"\n    def __init__(self, smooth=1e-6):\n        super().__init__()\n        self.smooth = smooth\n        self.add_state(\"intersection\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n        self.add_state(\"union\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n\n    def update(self, preds: torch.Tensor, target: torch.Tensor):\n        # Flatten predictions and targets\n        preds = preds.view(-1)\n        target = target.view(-1)\n\n        # Calculate intersection and union\n        intersection = (preds * target).sum()\n        union = preds.sum() + target.sum()\n\n        self.intersection += intersection\n        self.union += union\n\n    def compute(self):\n        # Calculate Dice score\n        dice = (2 * self.intersection + self.smooth) / (self.union + self.smooth)\n        return dice\n</code></pre> <p>Use in config: <pre><code>system:\n  metrics:\n    val:\n      - _target_: my_project.metrics.DiceScore\n        smooth: 1e-6\n</code></pre></p>"},{"location":"how-to/metrics/#key-optimization-tips","title":"Key Optimization Tips \u26a1","text":"Tip Do Don't Use Vectorization <code>(preds == target).sum()</code> Loop through elements Accumulate Stats Store sums and counts Store all predictions Handle Edge Cases Check for zero division Assume valid inputs"},{"location":"how-to/metrics/#common-pitfalls","title":"Common Pitfalls \ud83d\udee1\ufe0f","text":"Pitfall Solution State accumulation across epochs Lighter resets automatically Wrong distributed reduction Use <code>dist_reduce_fx=\"sum\"</code> for counts Type mismatches Convert tensors to same dtype"},{"location":"how-to/metrics/#quick-reference-card","title":"Quick Reference Card \ud83d\udcc4","text":"<pre><code># Minimal custom metric template\nfrom torchmetrics import Metric\nimport torch\n\nclass YourMetric(Metric):\n    def __init__(self, your_param=1.0):\n        super().__init__()\n        # 1. Register state variables\n        self.add_state(\"state_var\", default=torch.tensor(0.0), dist_reduce_fx=\"sum\")\n\n    def update(self, preds: torch.Tensor, target: torch.Tensor):\n        # 2. Process batch and update state\n        self.state_var += your_computation(preds, target)\n\n    def compute(self):\n        # 3. Calculate final metric\n        return self.state_var / normalization_factor\n</code></pre>"},{"location":"how-to/metrics/#recap-and-next-steps","title":"Recap and Next Steps","text":"<p>You now have the power to create sophisticated custom metrics:</p> <p>\ud83c\udfa8 What You Learned:</p> <ul> <li>Core metric lifecycle: <code>add_state()</code> \u2192 <code>update()</code> \u2192 <code>compute()</code></li> <li>Performance optimization techniques</li> <li>Testing strategies for robust metrics</li> <li>Common patterns for classification, regression, and calibration</li> </ul> <p>\ud83d\udca1 Pro Tip: Start simple, test thoroughly, optimize later!</p>"},{"location":"how-to/metrics/#related-guides","title":"Related Guides","text":"<ul> <li>Adapters - Transform data for metrics</li> <li>Writers - Save metric results</li> </ul>"},{"location":"how-to/project_module/","title":"Project Module: Seamless Custom Code Integration","text":"<p>As an ML practitioner, you often develop custom components like models, datasets, or metrics. Integrating these efficiently into your training framework, while maintaining a clean and reusable structure, is key for rapid experimentation. Lighter solves this with its Project Module system.</p>"},{"location":"how-to/project_module/#what-is-a-project-module","title":"What is a Project Module? \ud83c\udfaf","text":"<p>A Project Module in Lighter utilizes Python's native module system. In Python, a module can be a single <code>.py</code> file, or a directory containing an <code>__init__.py</code> file, used to organize related code hierarchically.</p> <p>Lighter lets you designate a directory as your \"project root.\" This root and its subdirectories (if they contain <code>__init__.py</code>) become dynamically importable in your Lighter configurations. This allows you to reference and instantiate custom classes and functions directly from your YAML files.</p> <p>This integration enables you to define and manage:</p> <ul> <li>\ud83e\udde0 Custom Models: Your neural network architectures.</li> <li>\ud83d\udce6 Custom Datasets: Your data loading logic.</li> <li>\ud83c\udfaf Custom Metrics: Your evaluation methods.</li> <li>\ud83d\udd04 Custom Transforms: Your data preprocessing.</li> <li>\ud83c\udf9b\ufe0f Custom Callbacks: Your training hooks.</li> </ul> <p>Key Benefits:</p> <ul> <li>\ud83d\udce6 Encapsulation: Project-specific code.</li> <li>\ud83d\ude80 Rapid Prototyping: Test ideas quickly without changing other code.</li> </ul>"},{"location":"how-to/project_module/#project-structure-organizing-your-custom-code","title":"Project Structure: Organizing Your Custom Code","text":"<p>Key Principle: For Lighter to import your custom code, it must be a valid Python module.</p> <ul> <li>Python Module (File): A single <code>.py</code> file (e.g., <code>my_model.py</code>).</li> <li>Python Module (Directory): A directory with an <code>__init__.py</code> file (e.g., <code>models/</code> with <code>models/__init__.py</code>). This groups related submodules.</li> </ul> <p>Example: <code>my_project/</code> is a Python module due to <code>__init__.py</code>. <code>models/</code> and <code>datasets/</code> are also modules. <code>experiments/</code> is not a module, typically holding config files.</p> <pre><code>my_project/\n\u251c\u2500\u2500 __init__.py         # Makes 'my_project' a module\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py     # Makes 'models' a module\n\u2502   \u2514\u2500\u2500 my_model.py     # A module within the 'models' module\n\u251c\u2500\u2500 datasets/\n\u2502   \u251c\u2500\u2500 __init__.py     # Makes 'datasets' a module\n\u2502   \u2514\u2500\u2500 my_dataset.py   # A module within the 'datasets' module\n\u2514\u2500\u2500 experiments/        # Not a Python; typically for config files\n    \u251c\u2500\u2500 finetune_full.yaml\n    \u2514\u2500\u2500 finetune_decoder.yaml\n</code></pre>"},{"location":"how-to/project_module/#defining-project-modules","title":"Defining Project Modules","text":"<p>With your project structure set up, defining custom components is straightforward. Within your module directories (e.g., <code>models/</code>, <code>datasets/</code>), define your custom Python modules as regular <code>.py</code> files. For example, define <code>MyModel</code> in <code>my_model.py</code>:</p> my_project/models/my_model.py<pre><code>import torch.nn as nn\n\nclass MyModel(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super().__init__()\n        # Define a linear layer\n        self.linear = nn.Linear(input_size, num_classes)\n\n    def forward(self, x):\n        # Forward pass through the linear layer\n        return self.linear(x)\n</code></pre> <p>and a custom dataset <code>MyDataset</code> in <code>my_dataset.py</code>:</p> my_project/datasets/my_dataset.py<pre><code>from torch.utils.data import Dataset\n\nclass MyDataset(Dataset):\n    def __init__(self, data_path, transform=None):\n        self.data_path = data_path\n        self.transform = transform\n        # Load data from data_path (implementation not shown)\n        self.samples = [...] # List of data samples (replace [...] with actual data loading)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample = self.samples[idx]\n        # Preprocess sample (implementation not shown)\n        # ...\n        if self.transform:\n            sample = self.transform(sample)\n        return sample\n</code></pre>"},{"location":"how-to/project_module/#importing-project-module-in-the-config","title":"Importing Project Module in the Config","text":"<p>After defining your custom modules, make them accessible to Lighter by configuring it to dynamically load your project. Lighter's <code>import_module_from_path</code> function imports your designated project root as a top-level module named <code>project</code>.</p>"},{"location":"how-to/project_module/#specifying-project-path","title":"Specifying <code>project</code> Path","text":"<p>Specify your project's root directory in <code>config.yaml</code> using the <code>project</code> key. This tells Lighter the path to your custom module collection.</p> <p>Example:</p> config.yaml<pre><code>project: my_project/ # Project root path\n</code></pre> <p>Relative Path Behavior</p> <p>The <code>project</code> path is relative to your current working directory when running the <code>lighter</code> command, not relative to the config file location.</p> <pre><code># If you run from parent directory\ncd /path/to/parent &amp;&amp; lighter fit /path/to/my_project/experiments/config.yaml project=/path/to/my_project/\n\n# If you run from project directory\ncd /path/to/parent/my_project &amp;&amp; lighter fit experiments/config.yaml project=.\n</code></pre> <p>Tip: Use absolute paths to avoid confusion, or be mindful of your current working directory.</p>"},{"location":"how-to/project_module/#referencing-your-project-module","title":"Referencing Your Project Module","text":"<p>With the <code>project</code> path specified, Lighter makes your custom modules available under the top-level module name <code>project</code>. Reference your project's modules and classes like any other Python module. See <code>system::model</code> and <code>system::dataloaders::train::dataset</code> in the config below:</p> <p>Example:</p> config.yaml<pre><code>project: my_project/\n\nsystem:\n  model:\n    _target_: project.models.MyModel\n    input_size: 784\n    num_classes: 10\n\n  dataloaders:\n    train:\n      _target_: torch.utils.data.DataLoader\n      dataset:\n        _target_: project.datasets.MyDataset\n        data_path: \"data/train.csv\"\n        # ... dataset arguments ...\n      batch_size: 32\n      shuffle: True\n</code></pre>"},{"location":"how-to/project_module/#practical-example-custom-model-architecture","title":"Practical Example: Custom Model Architecture","text":"<pre><code># my_project/models/custom_unet.py\nimport torch\nimport torch.nn as nn\n\nclass CustomUNet(nn.Module):\n    \"\"\"U-Net for segmentation tasks.\"\"\"\n    def __init__(self, in_channels=3, num_classes=2, features=[64, 128, 256, 512]):\n        super().__init__()\n        self.encoder = nn.ModuleList()\n        self.decoder = nn.ModuleList()\n        self.pool = nn.MaxPool2d(2, 2)\n\n        # Encoder\n        for feature in features:\n            self.encoder.append(self._block(in_channels, feature))\n            in_channels = feature\n\n        # Decoder\n        for feature in reversed(features[:-1]):\n            self.decoder.append(\n                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n            )\n            self.decoder.append(self._block(feature*2, feature))\n\n        self.final = nn.Conv2d(features[0], num_classes, kernel_size=1)\n\n    def _block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n    def forward(self, x):\n        skip_connections = []\n\n        # Encoder\n        for encode in self.encoder:\n            x = encode(x)\n            skip_connections.append(x)\n            x = self.pool(x)\n\n        skip_connections = skip_connections[::-1]\n\n        # Decoder\n        for idx in range(0, len(self.decoder), 2):\n            x = self.decoder[idx](x)\n            skip = skip_connections[idx//2]\n            x = torch.cat((skip, x), dim=1)\n            x = self.decoder[idx+1](x)\n\n        return self.final(x)\n</code></pre> <p>Use in config: <pre><code>project: my_project/\n\nsystem:\n  model:\n    _target_: project.models.custom_unet.CustomUNet\n    in_channels: 3\n    num_classes: 10\n    features: [64, 128, 256, 512]\n</code></pre></p>"},{"location":"how-to/project_module/#best-practices-for-project-organization","title":"Best Practices for Project Organization \ud83c\udfc6","text":""},{"location":"how-to/project_module/#recommended-structure","title":"Recommended Structure","text":"<pre><code>my_project/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 models/           # Neural network architectures\n\u251c\u2500\u2500 datasets/         # Data loading and processing\n\u251c\u2500\u2500 metrics/          # Custom evaluation metrics\n\u251c\u2500\u2500 callbacks/        # Training callbacks\n\u2514\u2500\u2500 utils/            # Helper functions\n</code></pre>"},{"location":"how-to/project_module/#key-guidelines","title":"Key Guidelines","text":"<ol> <li>Ensure <code>__init__.py</code> files are present in all directories intended to be Python modules (i.e., containing code you wish to import).</li> <li>Use type hints for better IDE support</li> <li>Write tests for critical components</li> <li>Document with docstrings for team collaboration</li> <li>Keep modules focused - one concept per file</li> </ol>"},{"location":"how-to/project_module/#running-with-custom-modules","title":"Running with Custom Modules","text":"<pre><code># Basic training\nlighter fit config.yaml\n\n# With module path override\nlighter fit config.yaml project=./my_research_project\n\n# Multiple configs with custom modules\nlighter fit base.yaml,models/unet.yaml,data/custom.yaml\n</code></pre>"},{"location":"how-to/project_module/#common-issues-solutions","title":"Common Issues &amp; Solutions","text":"Issue Solution ModuleNotFoundError Check <code>__init__.py</code> files and project path AttributeError Ensure classes/functions are correctly imported or exposed in <code>__init__.py</code> files if accessing them directly from the package. Circular imports Use lazy imports inside functions Path issues Use absolute imports or <code>project: ./my_project</code>"},{"location":"how-to/project_module/#recap-and-next-steps","title":"Recap and Next Steps","text":"<p>You're now equipped to build sophisticated custom modules:</p> <p>\ud83c\udfaf Key Takeaways:</p> <ul> <li>Structure projects with clear module organization</li> <li>Use type hints and documentation for maintainability</li> <li>Leverage advanced patterns (multi-modal, caching, custom augmentations)</li> <li>Test your modules for reliability</li> </ul> <p>\ud83d\udca1 Remember: Great research code is modular, tested, and reusable!</p>"},{"location":"how-to/project_module/#related-guides","title":"Related Guides","text":"<ul> <li>Configuration - Referencing the project module</li> <li>Adapters - Custom adapter creation</li> <li>Metrics - Custom metric creation</li> </ul>"},{"location":"how-to/recipes/","title":"Configuration Recipes","text":"<p>Ready-to-use configurations for common scenarios. Copy, adapt, and run.</p>"},{"location":"how-to/recipes/#training-infrastructure","title":"Training Infrastructure","text":""},{"location":"how-to/recipes/#multi-gpu-ddp","title":"Multi-GPU: DDP","text":"<pre><code>trainer:\n  devices: -1  # All GPUs (or specify: devices: 4)\n  accelerator: gpu\n  strategy: ddp\n  precision: \"16-mixed\"\n  max_epochs: 100\n  sync_batchnorm: true  # Synchronize batch norm across GPUs\n\nsystem:\n  dataloaders:\n    train:\n      batch_size: 32  # Per GPU! Effective = 32 * num_gpus\n      num_workers: 4  # Per GPU\n      pin_memory: true\n      persistent_workers: true\n</code></pre>"},{"location":"how-to/recipes/#multi-gpu-deepspeed-large-models","title":"Multi-GPU: DeepSpeed (Large Models)","text":"<pre><code>trainer:\n  devices: -1\n  accelerator: gpu\n  strategy: deepspeed_stage_2  # or deepspeed_stage_3\n  precision: \"16-mixed\"\n\nsystem:\n  dataloaders:\n    train:\n      batch_size: 8  # Smaller for large models\n</code></pre>"},{"location":"how-to/recipes/#multi-gpu-fsdp-very-large-models","title":"Multi-GPU: FSDP (Very Large Models)","text":"<pre><code>trainer:\n  devices: -1\n  accelerator: gpu\n  strategy: fsdp\n  precision: \"bf16-mixed\"  # BFloat16 often better for FSDP\n</code></pre>"},{"location":"how-to/recipes/#experiment-tracking-tensorboard","title":"Experiment Tracking: TensorBoard","text":"<pre><code>trainer:\n  logger:\n    _target_: pytorch_lightning.loggers.TensorBoardLogger\n    save_dir: logs\n    name: my_experiment\n    version: null  # Auto-increment\n\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.LearningRateMonitor\n      logging_interval: step\n</code></pre>"},{"location":"how-to/recipes/#experiment-tracking-weights-biases","title":"Experiment Tracking: Weights &amp; Biases","text":"<pre><code>_requires_:\n  - \"$import datetime\"\n\ntrainer:\n  logger:\n    _target_: pytorch_lightning.loggers.WandbLogger\n    project: my_project\n    name: \"$'exp_' + datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\"\n    save_dir: logs\n    log_model: true  # Save checkpoints to W&amp;B\n\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.LearningRateMonitor\n      logging_interval: epoch\n</code></pre>"},{"location":"how-to/recipes/#multiple-loggers","title":"Multiple Loggers","text":"<pre><code>trainer:\n  logger:\n    - _target_: pytorch_lightning.loggers.TensorBoardLogger\n      save_dir: logs\n      name: experiment\n    - _target_: pytorch_lightning.loggers.WandbLogger\n      project: my_project\n      name: experiment\n    - _target_: pytorch_lightning.loggers.CSVLogger\n      save_dir: logs\n</code></pre>"},{"location":"how-to/recipes/#best-model-checkpointing","title":"Best Model Checkpointing","text":"<pre><code>trainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n      dirpath: checkpoints\n      filename: \"best-{epoch:02d}-{val_loss:.4f}\"\n      monitor: val_loss\n      mode: min\n      save_top_k: 3  # Keep best 3\n      save_last: true\n</code></pre>"},{"location":"how-to/recipes/#monitor-multiple-metrics","title":"Monitor Multiple Metrics","text":"<pre><code>trainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n      dirpath: checkpoints/loss\n      filename: \"loss-{epoch:02d}-{val_loss:.4f}\"\n      monitor: val_loss\n      mode: min\n      save_top_k: 2\n\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n      dirpath: checkpoints/acc\n      filename: \"acc-{epoch:02d}-{val_acc:.4f}\"\n      monitor: val_acc\n      mode: max\n      save_top_k: 2\n</code></pre>"},{"location":"how-to/recipes/#early-stopping","title":"Early Stopping","text":"<pre><code>trainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.EarlyStopping\n      monitor: val_loss\n      patience: 10\n      mode: min\n      min_delta: 0.001\n      verbose: true\n\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n      monitor: val_loss\n      mode: min\n      save_top_k: 1\n</code></pre>"},{"location":"how-to/recipes/#data-augmentation","title":"Data Augmentation","text":""},{"location":"how-to/recipes/#image-classification","title":"Image Classification","text":"<pre><code>system:\n  dataloaders:\n    train:\n      dataset:\n        transform:\n          _target_: torchvision.transforms.Compose\n          transforms:\n            - _target_: torchvision.transforms.RandomResizedCrop\n              size: 224\n              scale: [0.8, 1.0]\n            - _target_: torchvision.transforms.RandomHorizontalFlip\n              p: 0.5\n            - _target_: torchvision.transforms.RandomRotation\n              degrees: 15\n            - _target_: torchvision.transforms.ColorJitter\n              brightness: 0.4\n              contrast: 0.4\n              saturation: 0.4\n              hue: 0.1\n            - _target_: torchvision.transforms.ToTensor\n            - _target_: torchvision.transforms.Normalize\n              mean: [0.485, 0.456, 0.406]\n              std: [0.229, 0.224, 0.225]\n\n    val:\n      dataset:\n        transform:\n          _target_: torchvision.transforms.Compose\n          transforms:\n            - _target_: torchvision.transforms.Resize\n              size: 256\n            - _target_: torchvision.transforms.CenterCrop\n              size: 224\n            - _target_: torchvision.transforms.ToTensor\n            - _target_: torchvision.transforms.Normalize\n              mean: [0.485, 0.456, 0.406]\n              std: [0.229, 0.224, 0.225]\n</code></pre>"},{"location":"how-to/recipes/#randaugment","title":"RandAugment","text":"<pre><code>_requires_:\n  - \"$from torchvision.transforms import RandAugment\"\n\nsystem:\n  dataloaders:\n    train:\n      dataset:\n        transform:\n          _target_: torchvision.transforms.Compose\n          transforms:\n            - _target_: torchvision.transforms.RandomResizedCrop\n              size: 224\n            - _target_: torchvision.transforms.RandAugment\n              num_ops: 2\n              magnitude: 9\n            - _target_: torchvision.transforms.ToTensor\n            - _target_: torchvision.transforms.Normalize\n              mean: [0.485, 0.456, 0.406]\n              std: [0.229, 0.224, 0.225]\n</code></pre>"},{"location":"how-to/recipes/#learning-rate-schedules","title":"Learning Rate Schedules","text":""},{"location":"how-to/recipes/#cosine-annealing","title":"Cosine Annealing","text":"<pre><code>vars:\n  max_epochs: 100\n\nsystem:\n  optimizer:\n    _target_: torch.optim.AdamW\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n    weight_decay: 0.01\n\n  scheduler:\n    _target_: torch.optim.lr_scheduler.CosineAnnealingLR\n    optimizer: \"@system::optimizer\"\n    T_max: \"%vars::max_epochs\"\n    eta_min: 0.00001\n</code></pre>"},{"location":"how-to/recipes/#reducelronplateau","title":"ReduceLROnPlateau","text":"<pre><code>system:\n  scheduler:\n    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n    optimizer: \"@system::optimizer\"\n    mode: min\n    factor: 0.5\n    patience: 5\n    min_lr: 0.00001\n    verbose: true\n</code></pre>"},{"location":"how-to/recipes/#step-decay","title":"Step Decay","text":"<pre><code>system:\n  scheduler:\n    _target_: torch.optim.lr_scheduler.MultiStepLR\n    optimizer: \"@system::optimizer\"\n    milestones: [30, 60, 90]\n    gamma: 0.1\n</code></pre>"},{"location":"how-to/recipes/#transfer-learning","title":"Transfer Learning","text":""},{"location":"how-to/recipes/#fine-tuning-pretrained-models","title":"Fine-tuning Pretrained Models","text":"<pre><code>system:\n  model:\n    _target_: torchvision.models.resnet50\n    weights: IMAGENET1K_V2\n    num_classes: 10\n\n  optimizer:\n    _target_: torch.optim.SGD\n    params: \"$@system::model.parameters()\"\n    lr: 0.001  # Lower LR for fine-tuning\n    momentum: 0.9\n\n  callbacks:\n    - _target_: lighter.callbacks.Freezer\n      modules: [\"layer1\", \"layer2\"]  # Freeze early layers\n</code></pre>"},{"location":"how-to/recipes/#differential-learning-rates","title":"Differential Learning Rates","text":"<pre><code>system:\n  model:\n    _target_: torchvision.models.resnet50\n    weights: IMAGENET1K_V2\n    num_classes: 10\n\n  optimizer:\n    _target_: torch.optim.SGD\n    params:\n      - params: \"$@system::model.layer1.parameters()\"\n        lr: 0.0001\n      - params: \"$@system::model.layer4.parameters()\"\n        lr: 0.001\n      - params: \"$@system::model.fc.parameters()\"\n        lr: 0.01\n    momentum: 0.9\n</code></pre>"},{"location":"how-to/recipes/#gradient-handling","title":"Gradient Handling","text":""},{"location":"how-to/recipes/#gradient-clipping","title":"Gradient Clipping","text":"<pre><code>trainer:\n  gradient_clip_val: 1.0\n  gradient_clip_algorithm: norm  # or 'value'\n</code></pre>"},{"location":"how-to/recipes/#gradient-accumulation","title":"Gradient Accumulation","text":"<pre><code>trainer:\n  accumulate_grad_batches: 4\n\nsystem:\n  dataloaders:\n    train:\n      batch_size: 8  # Effective: 8 * 4 = 32\n</code></pre>"},{"location":"how-to/recipes/#performance-optimization","title":"Performance Optimization","text":""},{"location":"how-to/recipes/#fast-training","title":"Fast Training","text":"<pre><code>trainer:\n  precision: \"16-mixed\"\n  devices: -1\n  accelerator: gpu\n  benchmark: true  # cudnn.benchmark\n\nsystem:\n  dataloaders:\n    train:\n      num_workers: 8\n      pin_memory: true\n      persistent_workers: true\n      prefetch_factor: 2\n      batch_size: 64\n</code></pre>"},{"location":"how-to/recipes/#memory-optimization","title":"Memory Optimization","text":"<pre><code>trainer:\n  precision: \"16-mixed\"\n  accumulate_grad_batches: 8\n\nsystem:\n  dataloaders:\n    train:\n      batch_size: 4  # Effective: 4 * 8 = 32\n      num_workers: 2\n</code></pre>"},{"location":"how-to/recipes/#development-debugging","title":"Development &amp; Debugging","text":""},{"location":"how-to/recipes/#fast-development-run","title":"Fast Development Run","text":"<pre><code>trainer:\n  fast_dev_run: true  # 1 batch of train/val/test\n</code></pre>"},{"location":"how-to/recipes/#overfit-single-batch","title":"Overfit Single Batch","text":"<pre><code>trainer:\n  overfit_batches: 1\n  max_epochs: 100\n  logger: false\n</code></pre>"},{"location":"how-to/recipes/#profiling","title":"Profiling","text":"<pre><code>trainer:\n  profiler: simple  # or 'advanced', 'pytorch'\n  max_epochs: 1\n  limit_train_batches: 10\n</code></pre>"},{"location":"how-to/recipes/#machine-learning-paradigms","title":"Machine Learning Paradigms","text":""},{"location":"how-to/recipes/#multi-task-learning","title":"Multi-Task Learning","text":"<p>Train one model on multiple tasks with shared representations.</p> <pre><code>system:\n  model:\n    _target_: my_project.MultiTaskModel\n    backbone: resnet50\n    num_classes_classification: 10\n    num_classes_segmentation: 2\n\n  criterion:\n    _target_: my_project.MultiTaskLoss\n    classification_weight: 1.0\n    segmentation_weight: 0.5\n\n  metrics:\n    train:\n      classification:\n        - _target_: torchmetrics.Accuracy\n          task: multiclass\n          num_classes: 10\n      segmentation:\n        - _target_: torchmetrics.JaccardIndex\n          task: binary\n    val: \"%system::metrics::train\"\n</code></pre> my_project/losses.py<pre><code>import torch.nn as nn\n\nclass MultiTaskLoss(nn.Module):\n    def __init__(self, classification_weight=1.0, segmentation_weight=1.0):\n        super().__init__()\n        self.cls_loss = nn.CrossEntropyLoss()\n        self.seg_loss = nn.BCEWithLogitsLoss()\n        self.cls_weight = classification_weight\n        self.seg_weight = segmentation_weight\n\n    def forward(self, pred, target):\n        cls_loss = self.cls_loss(pred['classification'], target['class'])\n        seg_loss = self.seg_loss(pred['segmentation'], target['mask'])\n\n        return {\n            \"total\": self.cls_weight * cls_loss + self.seg_weight * seg_loss,\n            \"classification\": cls_loss,\n            \"segmentation\": seg_loss,\n        }\n</code></pre> <p>All sublosses logged automatically.</p>"},{"location":"how-to/recipes/#self-supervised-learning-contrastive","title":"Self-Supervised Learning (Contrastive)","text":"<pre><code>system:\n  model:\n    _target_: my_project.SimCLRModel\n    backbone: resnet18\n    projection_dim: 128\n\n  criterion:\n    _target_: my_project.NTXentLoss\n    temperature: 0.5\n\n  adapters:\n    train:\n      batch:\n        _target_: lighter.adapters.BatchAdapter\n        input_accessor: 0\n        target_accessor: null  # No labels\n</code></pre> my_project/model.py<pre><code>import torch.nn as nn\n\nclass SimCLRModel(nn.Module):\n    def __init__(self, backbone='resnet18', projection_dim=128):\n        super().__init__()\n        self.encoder = torch.hub.load('pytorch/vision', backbone, weights=None)\n        self.encoder.fc = nn.Identity()\n        self.projector = nn.Sequential(\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, projection_dim)\n        )\n\n    def forward(self, x):\n        features = self.encoder(x)\n        return self.projector(features)\n</code></pre>"},{"location":"how-to/recipes/#knowledge-distillation","title":"Knowledge Distillation","text":"<p>Train small student model from large teacher.</p> <pre><code>system:\n  model:\n    _target_: my_project.DistillationModel\n    student:\n      _target_: torchvision.models.resnet18\n      num_classes: 10\n    teacher:\n      _target_: torchvision.models.resnet50\n      num_classes: 10\n    teacher_weights: checkpoints/teacher.ckpt\n\n  criterion:\n    _target_: my_project.DistillationLoss\n    temperature: 3.0\n    alpha: 0.7  # Distillation loss weight\n</code></pre> my_project/model.py<pre><code>import torch.nn as nn\n\nclass DistillationModel(nn.Module):\n    def __init__(self, student, teacher, teacher_weights=None):\n        super().__init__()\n        self.student = student\n        self.teacher = teacher\n\n        if teacher_weights:\n            self.teacher.load_state_dict(torch.load(teacher_weights))\n\n        for param in self.teacher.parameters():\n            param.requires_grad = False\n        self.teacher.eval()\n\n    def forward(self, x):\n        student_logits = self.student(x)\n        with torch.no_grad():\n            teacher_logits = self.teacher(x)\n        return {\"student\": student_logits, \"teacher\": teacher_logits}\n</code></pre>"},{"location":"how-to/recipes/#curriculum-learning","title":"Curriculum Learning","text":"<p>Progressively increase task difficulty.</p> my_project/model.py<pre><code>class CurriculumModel(nn.Module):\n    def __init__(self, num_classes=10, max_epochs=100):\n        super().__init__()\n        self.backbone = nn.Sequential(...)\n        self.classifier = nn.Linear(512, num_classes)\n        self.max_epochs = max_epochs\n\n    def forward(self, x, epoch=None):\n        # Lighter automatically injects epoch\n        if epoch is not None:\n            difficulty = min(epoch / self.max_epochs, 1.0)\n            x = self.apply_difficulty(x, difficulty)\n\n        features = self.backbone(x)\n        return self.classifier(features)\n</code></pre> <p>No config needed\u2014epoch injection is automatic.</p>"},{"location":"how-to/recipes/#model-ensembling","title":"Model Ensembling","text":"<pre><code>system:\n  model:\n    _target_: my_project.EnsembleModel\n    models:\n      - _target_: torchvision.models.resnet18\n        num_classes: 10\n      - _target_: torchvision.models.resnet34\n        num_classes: 10\n    checkpoints:\n      - checkpoints/model1.ckpt\n      - checkpoints/model2.ckpt\n\n  inferer:\n    _target_: my_project.EnsembleInferer\n    ensemble_method: \"average\"  # or \"voting\"\n</code></pre> my_project/model.py<pre><code>class EnsembleInferer:\n    def __init__(self, ensemble_method=\"average\"):\n        self.method = ensemble_method\n\n    def __call__(self, x, model, **kwargs):\n        predictions = []\n        for m in model.models:\n            m.eval()\n            with torch.no_grad():\n                predictions.append(m(x))\n\n        if self.method == \"average\":\n            return torch.stack(predictions).mean(dim=0)\n        elif self.method == \"voting\":\n            return torch.stack(predictions).mode(dim=0)[0]\n</code></pre>"},{"location":"how-to/recipes/#cross-validation","title":"Cross-Validation","text":"cross_validation.py<pre><code>import subprocess\n\ndef run_kfold(base_config=\"config.yaml\", k=5):\n    for fold in range(k):\n        subprocess.run([\n            \"lighter\", \"fit\", base_config,\n            f\"system::dataloaders::train::dataset::fold={fold}\",\n            f\"trainer::logger::version=fold_{fold}\"\n        ])\n\nif __name__ == \"__main__\":\n    run_kfold()\n</code></pre> config.yaml<pre><code>system:\n  dataloaders:\n    train:\n      dataset:\n        _target_: my_project.KFoldDataset\n        k: 5\n        fold: 0  # Overridden from CLI\n</code></pre>"},{"location":"how-to/recipes/#production-setup","title":"Production Setup","text":"<p>Complete production-ready configuration:</p> <pre><code>_requires_:\n  - \"$import datetime\"\n\nvars:\n  experiment_name: \"production_run\"\n  timestamp: \"$datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\"\n\ntrainer:\n  _target_: pytorch_lightning.Trainer\n  devices: -1\n  accelerator: gpu\n  strategy: ddp\n  precision: \"16-mixed\"\n  max_epochs: 200\n  gradient_clip_val: 1.0\n\n  logger:\n    - _target_: pytorch_lightning.loggers.TensorBoardLogger\n      save_dir: logs\n      name: \"%vars::experiment_name\"\n      version: \"%vars::timestamp\"\n    - _target_: pytorch_lightning.loggers.WandbLogger\n      project: production\n      name: \"$%vars::experiment_name + '_' + %vars::timestamp\"\n\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.ModelCheckpoint\n      dirpath: \"$'checkpoints/' + %vars::experiment_name\"\n      filename: \"best-{epoch:02d}-{val_loss:.4f}\"\n      monitor: val_loss\n      mode: min\n      save_top_k: 3\n      save_last: true\n\n    - _target_: pytorch_lightning.callbacks.EarlyStopping\n      monitor: val_loss\n      patience: 20\n      mode: min\n\n    - _target_: pytorch_lightning.callbacks.LearningRateMonitor\n      logging_interval: epoch\n\nsystem:\n  _target_: lighter.System\n\n  model:\n    _target_: torchvision.models.resnet50\n    weights: IMAGENET1K_V2\n    num_classes: 10\n\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n\n  optimizer:\n    _target_: torch.optim.AdamW\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n    weight_decay: 0.01\n\n  scheduler:\n    _target_: torch.optim.lr_scheduler.CosineAnnealingLR\n    optimizer: \"@system::optimizer\"\n    T_max: 200\n\n  dataloaders:\n    train:\n      batch_size: 64\n      num_workers: 8\n      pin_memory: true\n      persistent_workers: true\n    val:\n      batch_size: 128\n      num_workers: 4\n      pin_memory: true\n</code></pre>"},{"location":"how-to/recipes/#next-steps","title":"Next Steps","text":"<ul> <li>Configuration Reference - Complete syntax guide</li> <li>Troubleshooting - Debug issues</li> <li>Adapters - Handle any data format</li> <li>System Internals - Understanding the pipeline</li> </ul>"},{"location":"how-to/run/","title":"Running Experiments","text":"<p>Lighter streamlines deep learning experiments through well-defined stages. This guide covers everything from basic runs to advanced workflows.</p>"},{"location":"how-to/run/#stages-overview","title":"Stages Overview","text":"<p>Lighter orchestrates experiments through four distinct stages, each serving a specific purpose:</p> Stage Purpose Common Use Cases <code>fit</code> Train model on training data Initial training, fine-tuning, transfer learning <code>validate</code> Evaluate on validation data Hyperparameter tuning, model selection <code>test</code> Final evaluation on test data Performance benchmarking, final metrics <code>predict</code> Generate predictions on new data Inference, deployment, data analysis"},{"location":"how-to/run/#quick-start","title":"Quick Start","text":""},{"location":"how-to/run/#basic-commands","title":"Basic Commands","text":"<pre><code># Train a model\nlighter fit config.yaml\n\n# Validate a trained model\nlighter validate config.yaml\n\n# Test final performance\nlighter test config.yaml\n\n# Generate predictions\nlighter predict config.yaml\n</code></pre>"},{"location":"how-to/run/#common-workflows","title":"Common Workflows","text":""},{"location":"how-to/run/#1-full-training-pipeline","title":"1. Full Training Pipeline","text":"<pre><code># Train + validate (automatic validation during training)\nlighter fit config.yaml\n\n# Then test on held-out data - equivalent to Trainer.test(..., ckpt_path=\"best\")\nlighter test config.yaml args::test::ckpt_path=\"best.ckpt\"\n</code></pre>"},{"location":"how-to/run/#2-resume-training-from-checkpoint","title":"2. Resume Training from Checkpoint","text":"<pre><code>lighter fit config.yaml args::fit::ckpt_path=\"last.ckpt\"\n</code></pre>"},{"location":"how-to/run/#3-fine-tuning-pre-trained-model","title":"3. Fine-tuning Pre-trained Model","text":"<pre><code># Use base config + fine-tuning overrides\nlighter fit base_config.yaml,finetune_config.yaml\n</code></pre>"},{"location":"how-to/run/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"how-to/run/#stage-specific-arguments","title":"Stage-Specific Arguments","text":"<p>The <code>args</code> key provides a way to pass arguments directly to the PyTorch Lightning <code>Trainer</code>'s stage methods: <code>fit</code>, <code>validate</code>, <code>test</code>, and <code>predict</code>. Each key under <code>args</code> corresponds to a stage, and the arguments within it are passed to that stage's method. For instance, <code>args.test.ckpt_path</code> is passed as <code>Trainer.test(ckpt_path=...)</code>.</p> <p>Configure stage arguments in your YAML or via CLI:</p> config.yaml<pre><code>args:\n    fit:\n        ckpt_path: null  # Start from scratch\n    validate:\n        ckpt_path: \"checkpoints/best.ckpt\"\n    test:\n        ckpt_path: \"checkpoints/best.ckpt\"\n    predict:\n        ckpt_path: \"checkpoints/best.ckpt\"\n        return_predictions: true\n</code></pre>"},{"location":"how-to/run/#cli-override-patterns","title":"CLI Override Patterns","text":"<pre><code># Override any config parameter\nlighter fit config.yaml trainer::max_epochs=50\n\n# Override nested parameters\nlighter fit config.yaml system::optimizer::lr=0.001\n\n# Override list elements\nlighter fit config.yaml trainer::callbacks::0::patience=10\n\n# Multiple overrides\nlighter fit config.yaml \\\n    trainer::max_epochs=100 \\\n    system::optimizer::lr=0.0001 \\\n    trainer::devices=2\n</code></pre>"},{"location":"how-to/run/#pro-tips","title":"Pro Tips \ud83d\udca1","text":""},{"location":"how-to/run/#1-config-composition","title":"1. Config Composition","text":"<p>Combine multiple configs for modular experiments: <pre><code># Base + dataset + model + training configs\nlighter fit base.yaml,data/cifar10.yaml,models/resnet.yaml,train/sgd.yaml\n</code></pre></p>"},{"location":"how-to/run/#2-quick-experimentation","title":"2. Quick Experimentation","text":"<p>Test configurations without full training: <pre><code># Fast run with 2 batches\nlighter fit config.yaml trainer::fast_dev_run=2\n</code></pre></p>"},{"location":"how-to/run/#3-gpu-management","title":"3. GPU Management","text":"<pre><code># Use specific GPUs\nlighter fit config.yaml trainer::devices=[0,1]\n\n# Use all available GPUs\nlighter fit config.yaml trainer::devices=-1\n</code></pre>"},{"location":"how-to/run/#4-debugging-runs","title":"4. Debugging Runs","text":"<pre><code># Enable detailed logging\nlighter fit config.yaml trainer::log_every_n_steps=1\n\n# Profile your code\nlighter fit config.yaml trainer::profiler=\"simple\"\n</code></pre>"},{"location":"how-to/run/#common-patterns","title":"Common Patterns","text":""},{"location":"how-to/run/#pattern-1-hyperparameter-search","title":"Pattern 1: Hyperparameter Search","text":"<pre><code># Run multiple experiments with different learning rates\nfor lr in 0.001 0.01 0.1; do\n    lighter fit config.yaml \\\n        system::optimizer::lr=$lr \\\n        trainer::logger::name=\"lr_$lr\"\ndone\n</code></pre>"},{"location":"how-to/run/#pattern-2-cross-validation","title":"Pattern 2: Cross-Validation","text":"<pre><code># Run k-fold cross-validation\nfor fold in {1..5}; do\n    lighter fit config.yaml \\\n        system::dataloaders::train::dataset::fold=$fold \\\n        trainer::logger::name=\"fold_$fold\"\ndone\n</code></pre>"},{"location":"how-to/run/#pattern-3-progressive-training","title":"Pattern 3: Progressive Training","text":"<pre><code># Start with small resolution, then increase\nlighter fit config.yaml vars::image_size=128 trainer::max_epochs=10\nlighter fit config.yaml vars::image_size=256 args::fit::ckpt_path=\"last.ckpt\"\nlighter fit config.yaml vars::image_size=512 args::fit::ckpt_path=\"last.ckpt\"\n</code></pre>"},{"location":"how-to/run/#troubleshooting","title":"Troubleshooting","text":""},{"location":"how-to/run/#issue-out-of-memory","title":"Issue: Out of Memory","text":"<pre><code># Reduce batch size\nlighter fit config.yaml system::dataloaders::train::batch_size=8\n\n# Enable gradient accumulation\nlighter fit config.yaml trainer::accumulate_grad_batches=4\n\n# Use mixed precision\nlighter fit config.yaml trainer::precision=\"16-mixed\"\n</code></pre>"},{"location":"how-to/run/#issue-training-too-slow","title":"Issue: Training Too Slow","text":"<pre><code># Increase number of workers\nlighter fit config.yaml system::dataloaders::train::num_workers=8\n\n# Enable compile mode (PyTorch 2.0+)\nlighter fit config.yaml system::model::compile=true\n</code></pre>"},{"location":"how-to/run/#issue-validation-takes-too-long","title":"Issue: Validation Takes Too Long","text":"<pre><code># Reduce validation frequency\nlighter fit config.yaml trainer::check_val_every_n_epoch=5\n\n# Limit validation batches\nlighter fit config.yaml trainer::limit_val_batches=0.25\n</code></pre>"},{"location":"how-to/run/#environment-variables","title":"Environment Variables","text":"<p>Control Lighter behavior with environment variables:</p> <pre><code># Set random seed for reproducibility via Pytorch Lightning\nPL_GLOBAL_SEED=42 lighter fit config.yaml\n\n# Enable debugging mode\nLIGHTER_DEBUG=1 lighter fit config.yaml\n</code></pre>"},{"location":"how-to/run/#quick-reference","title":"Quick Reference","text":"Task Command Train from scratch <code>lighter fit config.yaml</code> Resume training <code>lighter fit config.yaml args::fit::ckpt_path=\"last.ckpt\"</code> Validate checkpoint <code>lighter validate config.yaml args::validate::ckpt_path=\"best.ckpt\"</code> Test model <code>lighter test config.yaml args::test::ckpt_path=\"best.ckpt\"</code> Generate predictions <code>lighter predict config.yaml args::predict::ckpt_path=\"best.ckpt\"</code> Fast debugging <code>lighter fit config.yaml trainer::fast_dev_run=true</code> Multi-GPU training <code>lighter fit config.yaml trainer::devices=4</code> Mixed precision <code>lighter fit config.yaml trainer::precision=\"16-mixed\"</code>"},{"location":"how-to/run/#recap-and-next-steps","title":"Recap and Next Steps","text":"<p>You now have a comprehensive understanding of running experiments with Lighter. Key takeaways:</p> <ul> <li>Four stages (<code>fit</code>, <code>validate</code>, <code>test</code>, <code>predict</code>) cover the full ML lifecycle</li> <li>Flexible configuration through YAML files and CLI overrides</li> <li>Powerful composition and workflow patterns</li> <li>Built-in solutions for common issues</li> </ul>"},{"location":"how-to/run/#related-guides","title":"Related Guides","text":"<ul> <li>Configuration Guide - Config syntax and patterns</li> <li>Troubleshooting - Common errors and solutions</li> <li>Experiment Tracking - Logging experiments</li> </ul>"},{"location":"how-to/troubleshooting/","title":"Troubleshooting","text":"<p>Comprehensive guide to debugging errors and issues in Lighter. Includes actual error messages and step-by-step solutions.</p>"},{"location":"how-to/troubleshooting/#configuration-errors","title":"Configuration Errors","text":""},{"location":"how-to/troubleshooting/#modulenotfounderror-no-module-named-project","title":"ModuleNotFoundError: No module named 'project'","text":"<p>Cause: Missing <code>__init__.py</code> files or incorrect project path</p> <p>Solution: <pre><code># In your config.yaml\nproject: ./my_project  # Ensure path is correct\n\n# Ensure all module directories have __init__.py:\nmy_project/\n\u251c\u2500\u2500 __init__.py       # Required!\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py   # Required!\n\u2502   \u2514\u2500\u2500 my_model.py\n</code></pre></p>"},{"location":"how-to/troubleshooting/#config-reference-errors","title":"Config Reference Errors","text":"<p>Wrong: <code>\"$@system::model::parameters()\"</code> - Using <code>::</code> for attributes Correct: <code>\"$@system::model.parameters()\"</code> - Use <code>.</code> for Python attributes</p> <p>Wrong: Circular references <pre><code>model:\n  lr: \"@system::optimizer::lr\"  # Circular!\noptimizer:\n  lr: \"@system::model.lr\"      # Circular!\n</code></pre></p> <p>Correct: Use <code>vars</code> section <pre><code>vars:\n  lr: 0.001\nmodel:\n  lr: \"%vars::lr\"\noptimizer:\n  lr: \"%vars::lr\"\n</code></pre></p>"},{"location":"how-to/troubleshooting/#yaml-syntax-errors","title":"YAML Syntax Errors","text":"<p>Common mistakes: - Missing colons after keys - Inconsistent indentation (use spaces, not tabs) - Missing quotes around values with special characters - Missing values (like the <code>roi_size</code> example in inferers)</p>"},{"location":"how-to/troubleshooting/#sparkwheel-validation-errors","title":"Sparkwheel Validation Errors","text":"<p>Lighter uses Sparkwheel for config validation. Here's how to interpret validation errors:</p> <p>Error Example: <pre><code>ValueError: Configuration validation failed:\nsystem.model: Missing required field '_target_'\nsystem.optimizer.lr: Expected float, got str\n</code></pre></p> <p>Solution: Check the schema in <code>src/lighter/engine/schema.py</code> or add missing fields: <pre><code>system:\n  model:\n    _target_: torch.nn.Linear  # Must have _target_\n  optimizer:\n    lr: 0.001  # Not \"0.001\" (string)\n</code></pre></p> <p>Error: Missing required component <pre><code>ValueError: Configuration validation failed:\nsystem.optimizer: Required field missing\n</code></pre></p> <p>Solution: Lighter requires certain components depending on the stage: - FIT stage: model, optimizer, criterion, train dataloader required - VALIDATE stage: model, criterion, val dataloader required - TEST stage: model, test dataloader required - PREDICT stage: model, predict dataloader required</p>"},{"location":"how-to/troubleshooting/#reference-resolution-errors","title":"Reference Resolution Errors","text":"<p>Error: Reference not found <pre><code>KeyError: 'Could not resolve reference @system::modell'\n</code></pre></p> <p>Solution: Typo in reference path. Check spelling: <pre><code>optimizer:\n  params: \"$@system::model.parameters()\"  # Not 'modell'\n</code></pre></p> <p>Error: Attribute not found <pre><code>AttributeError: 'ResNet' object has no attribute 'paramters'\n</code></pre></p> <p>Solution: Typo in method name: <pre><code>optimizer:\n  params: \"$@system::model.parameters()\"  # Not 'paramters'\n</code></pre></p> <p>Error: Using :: for Python attributes <pre><code># Wrong\nparams: \"$@system::model::parameters()\"\n\n# Correct\nparams: \"$@system::model.parameters()\"\n</code></pre></p> <p>Rule: Use <code>::</code> for config navigation, <code>.</code> for Python attributes</p>"},{"location":"how-to/troubleshooting/#training-issues","title":"Training Issues","text":""},{"location":"how-to/troubleshooting/#cuda-out-of-memory","title":"CUDA Out of Memory","text":"<p>Solutions: <pre><code># Reduce batch size\nlighter fit config.yaml system::dataloaders::train::batch_size=8\n\n# Enable gradient accumulation\nlighter fit config.yaml trainer::accumulate_grad_batches=4\n\n# Use mixed precision\nlighter fit config.yaml trainer::precision=\"16-mixed\"\n</code></pre></p> <p>For distributed strategies, see PyTorch Lightning docs.</p>"},{"location":"how-to/troubleshooting/#loss-is-nan","title":"Loss is NaN","text":"<p>Check: 1. Learning rate too high \u2192 Reduce by 10x 2. Missing data normalization \u2192 Add transforms 3. Wrong loss function for task \u2192 Verify criterion 4. Gradient explosion \u2192 Add gradient clipping in Trainer config</p>"},{"location":"how-to/troubleshooting/#slow-training","title":"Slow Training","text":"<p>Optimize: <pre><code>system:\n  dataloaders:\n    train:\n      num_workers: 8      # Increase for faster data loading\n      pin_memory: true    # For GPU training\n      persistent_workers: true  # Reduce worker startup overhead\n</code></pre></p> <p>For profiling and optimization, see PyTorch Lightning performance docs.</p>"},{"location":"how-to/troubleshooting/#metrics-not-computing","title":"Metrics Not Computing","text":"<p>Error: No metrics logged to TensorBoard/W&amp;B</p> <p>Cause 1: Metrics not defined for the mode <pre><code># Wrong: No val metrics\nsystem:\n  metrics:\n    train:\n      - _target_: torchmetrics.Accuracy\n</code></pre></p> <p>Solution: Add metrics for each mode <pre><code>system:\n  metrics:\n    train:\n      - _target_: torchmetrics.Accuracy\n        task: multiclass\n        num_classes: 10\n    val: \"%system::metrics::train\"  # Reuse train config\n</code></pre></p> <p>Cause 2: MetricsAdapter argument mismatch <pre><code># Wrong: Metric expects 'preds', but adapter uses default (positional)\nsystem:\n  adapters:\n    train:\n      metrics:\n        _target_: lighter.adapters.MetricsAdapter\n        # Missing pred_argument and target_argument\n</code></pre></p> <p>Solution: Match metric signature <pre><code>system:\n  adapters:\n    train:\n      metrics:\n        _target_: lighter.adapters.MetricsAdapter\n        pred_argument: \"preds\"\n        target_argument: \"target\"\n</code></pre></p>"},{"location":"how-to/troubleshooting/#model-not-learning-loss-not-decreasing","title":"Model Not Learning (Loss Not Decreasing)","text":"<p>Check 1: Are gradients flowing?</p> <p>Add to config temporarily: <pre><code>_requires_:\n  - \"$import torch\"\n\nsystem:\n  model:\n    _target_: MyModel\n    # Check grad flow after first batch\n    _debug: \"$print('Has grad:', next(iter(@system::model.parameters())).grad is not None)\"\n</code></pre></p> <p>Check 2: Is optimizer updating weights?</p> <p>Enable optimizer stats logging (automatic in Lighter): <pre><code>trainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.LearningRateMonitor\n      logging_interval: step\n</code></pre></p> <p>Check <code>train/lr</code> in logs. If it's not changing with a scheduler, scheduler may be misconfigured.</p> <p>Check 3: Is loss function appropriate?</p> <ul> <li>Classification: Use <code>CrossEntropyLoss</code> (takes logits, not probabilities)</li> <li>Regression: Use <code>MSELoss</code></li> <li>Binary: Use <code>BCEWithLogitsLoss</code> (takes logits)</li> </ul> <p>Common mistake: <pre><code># Wrong: Applying softmax before CrossEntropyLoss\nsystem:\n  adapters:\n    train:\n      criterion:\n        pred_transforms:\n          - _target_: torch.nn.functional.softmax  # \u274c Don't do this!\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n</code></pre></p> <p>Correct: <pre><code># CrossEntropyLoss applies softmax internally\nsystem:\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss  # No softmax needed\n</code></pre></p>"},{"location":"how-to/troubleshooting/#distributed-training-issues-ddp","title":"Distributed Training Issues (DDP)","text":""},{"location":"how-to/troubleshooting/#error-address-already-in-use","title":"Error: Address already in use","text":"<p>Error: <pre><code>RuntimeError: Address already in use\n</code></pre></p> <p>Cause: Previous DDP process didn't terminate cleanly</p> <p>Solution: <pre><code># Find and kill lingering processes\nps aux | grep python\nkill -9 &lt;PID&gt;\n\n# Or restart your terminal/jupyter kernel\n</code></pre></p>"},{"location":"how-to/troubleshooting/#file-writing-conflicts","title":"File Writing Conflicts","text":"<p>Error: Multiple processes writing to same file causing corruption</p> <p>Cause: Writers in predict mode running on all GPUs</p> <p>Solution: Use rank-zero only for file operations <pre><code># In custom callback\nfrom pytorch_lightning.utilities import rank_zero_only\n\nclass MyWriter(Callback):\n    @rank_zero_only\n    def on_predict_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):\n        # Only rank 0 writes\n        save_predictions(outputs)\n</code></pre></p> <p>Lighter's built-in Writers handle this automatically.</p>"},{"location":"how-to/troubleshooting/#metrics-aggregation-issues","title":"Metrics Aggregation Issues","text":"<p>Error: Metrics values differ across GPUs</p> <p>Solution: Lighter automatically sets <code>sync_dist=True</code> for epoch-level metrics. For manual logging: <pre><code>self.log(\"custom_metric\", value, on_epoch=True, sync_dist=True)\n</code></pre></p>"},{"location":"how-to/troubleshooting/#different-behavior-on-single-vs-multi-gpu","title":"Different Behavior on Single vs Multi-GPU","text":"<p>Cause: Batch normalization or dropout behaving differently</p> <p>Solution: Use <code>sync_batchnorm</code> for BN: <pre><code>trainer:\n  strategy: ddp\n  sync_batchnorm: true  # Synchronize BN statistics\n</code></pre></p>"},{"location":"how-to/troubleshooting/#adapter-debugging","title":"Adapter Debugging","text":""},{"location":"how-to/troubleshooting/#inspecting-tensor-shapes","title":"Inspecting Tensor Shapes","text":"<p>Add print transforms to see tensor shapes at each stage:</p> <pre><code>system:\n  adapters:\n    train:\n      batch:\n        _target_: lighter.adapters.BatchAdapter\n        input_accessor: \"image\"\n        target_accessor: \"mask\"\n        # Debug: Print shapes after extraction\n        input_transforms:\n          - \"$lambda x: print(f'Input shape: {x.shape}') or x\"\n        target_transforms:\n          - \"$lambda x: print(f'Target shape: {x.shape}') or x\"\n\n      criterion:\n        _target_: lighter.adapters.CriterionAdapter\n        pred_transforms:\n          - \"$lambda x: print(f'Pred before softmax: {x.shape}') or x\"\n          - _target_: torch.nn.functional.softmax\n            dim: 1\n          - \"$lambda x: print(f'Pred after softmax: {x.shape}') or x\"\n</code></pre>"},{"location":"how-to/troubleshooting/#common-adapter-errors","title":"Common Adapter Errors","text":"<p>Error: Wrong argument order <pre><code>TypeError: forward() got an unexpected keyword argument 'prediction'\n</code></pre></p> <p>Solution: Check loss function signature and match adapter: <pre><code># If loss expects loss(pred, target)\ndef my_loss(pred, target):\n    ...\n\n# Adapter config (default is correct)\nsystem:\n  adapters:\n    train:\n      criterion:\n        _target_: lighter.adapters.CriterionAdapter\n        pred_argument: 0\n        target_argument: 1\n</code></pre></p> <p>Error: KeyError in batch <pre><code>KeyError: 'image'\n</code></pre></p> <p>Solution: Check dataset output: <pre><code># Temporarily add to dataset\ndef __getitem__(self, idx):\n    batch = {...}\n    print(f\"Batch keys: {batch.keys()}\")  # Debug\n    return batch\n</code></pre></p> <p>Then match <code>input_accessor</code> to actual key.</p>"},{"location":"how-to/troubleshooting/#performance-profiling","title":"Performance Profiling","text":""},{"location":"how-to/troubleshooting/#identify-bottlenecks","title":"Identify Bottlenecks","text":"<p>Use PyTorch Lightning profiler:</p> <pre><code>trainer:\n  profiler: simple  # or 'advanced', 'pytorch'\n  max_epochs: 1\n  limit_train_batches: 100\n</code></pre> <p>Output shows time spent in each method: <pre><code>\u2552\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2555\n\u2502 Action                \u2502 Mean    \u2502 Total   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 run_training_batch    \u2502 0.105   \u2502 10.5    \u2502\n\u2502 get_train_batch       \u2502 0.095   \u2502 9.5     \u2502\n\u2502 training_step         \u2502 0.008   \u2502 0.8     \u2502\n\u2558\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255b\n</code></pre></p> <p>If <code>get_train_batch</code> is slow: Increase <code>num_workers</code> in dataloader</p> <p>If <code>training_step</code> is slow: Profile model forward/loss computation</p>"},{"location":"how-to/troubleshooting/#data-loading-bottleneck","title":"Data Loading Bottleneck","text":"<p>Symptom: GPU underutilized, low GPU usage</p> <p>Solution: <pre><code>system:\n  dataloaders:\n    train:\n      num_workers: 8          # Increase (up to CPU cores)\n      prefetch_factor: 4      # Prefetch more batches\n      persistent_workers: true # Reuse workers\n      pin_memory: true        # Faster GPU transfer\n</code></pre></p> <p>Test different num_workers: <pre><code>for i in 2 4 8 16; do\n  echo \"Testing num_workers=$i\"\n  lighter fit config.yaml \\\n    system::dataloaders::train::num_workers=$i \\\n    trainer::limit_train_batches=100 \\\n    trainer::max_epochs=1\ndone\n</code></pre></p>"},{"location":"how-to/troubleshooting/#model-bottleneck","title":"Model Bottleneck","text":"<p>Symptom: High GPU usage, slow batches</p> <p>Solutions:</p> <ol> <li> <p>Mixed precision training: <pre><code>trainer:\n  precision: \"16-mixed\"  # ~2x speedup, less memory\n</code></pre></p> </li> <li> <p>Gradient accumulation (simulate larger batch): <pre><code>trainer:\n  accumulate_grad_batches: 4  # Update every 4 batches\n\nsystem:\n  dataloaders:\n    train:\n      batch_size: 8  # Effective: 8 * 4 = 32\n</code></pre></p> </li> <li> <p>Compile model (PyTorch 2.0+): <pre><code>_requires_:\n  - \"$import torch\"\n\nsystem:\n  model:\n    _target_: torchvision.models.resnet50\n    # Compile for faster execution\n    _post_init_: \"$lambda m: torch.compile(m)\"\n</code></pre></p> </li> </ol>"},{"location":"how-to/troubleshooting/#memory-optimization","title":"Memory Optimization","text":""},{"location":"how-to/troubleshooting/#beyond-reducing-batch-size","title":"Beyond Reducing Batch Size","text":"<p>Strategy 1: Gradient Checkpointing</p> <p>Trade compute for memory (recompute activations during backward):</p> my_project/model.py<pre><code>from torch.utils.checkpoint import checkpoint_sequential\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layers = nn.Sequential(*[\n            ResidualBlock() for _ in range(50)\n        ])\n\n    def forward(self, x):\n        # Checkpoint every 10 layers\n        return checkpoint_sequential(self.layers, 10, x)\n</code></pre> <p>Strategy 2: CPU Offloading</p> <p>Move intermediate results to CPU:</p> <pre><code>system:\n  adapters:\n    val:\n      logging:\n        _target_: lighter.adapters.LoggingAdapter\n        # Move to CPU for callbacks\n        pred_transforms:\n          - \"$lambda x: x.cpu()\"\n</code></pre> <p>Strategy 3: Clear Cache Periodically</p> my_project/custom_system.py<pre><code>from lighter.system import System\nimport torch\n\nclass MemoryEfficientSystem(System):\n    def on_train_batch_end(self, outputs, batch, batch_idx):\n        # Clear cache every 100 batches\n        if batch_idx % 100 == 0:\n            torch.cuda.empty_cache()\n</code></pre> <p>Strategy 4: Use Smaller Precision</p> <pre><code>trainer:\n  precision: \"bf16-mixed\"  # BFloat16 (less memory than fp16 in some cases)\n</code></pre>"},{"location":"how-to/troubleshooting/#debugging-strategies","title":"Debugging Strategies","text":""},{"location":"how-to/troubleshooting/#quick-testing","title":"Quick Testing","text":"<pre><code># Test with 2 batches only\nlighter fit config.yaml trainer::fast_dev_run=2\n</code></pre>"},{"location":"how-to/troubleshooting/#debug-config-values","title":"Debug Config Values","text":"<pre><code># Print values during config resolution\noptimizer:\n  lr: \"$print('LR:', 0.001) or 0.001\"\n</code></pre>"},{"location":"how-to/troubleshooting/#check-adapter-outputs","title":"Check Adapter Outputs","text":"<p>Temporarily add print transforms in adapters: <pre><code>adapters:\n  train:\n    criterion:\n      pred_transforms:\n        - \"$lambda x: print('Pred shape:', x.shape) or x\"\n</code></pre></p>"},{"location":"how-to/troubleshooting/#debug-mode-checklist","title":"Debug Mode Checklist","text":"<p>When encountering an error:</p> <ol> <li> <p>Test with fast_dev_run: <pre><code>lighter fit config.yaml trainer::fast_dev_run=true\n</code></pre></p> </li> <li> <p>Verify config resolves: <pre><code>_requires_:\n  - \"$import sys\"\nvars:\n  _debug: \"$print('Config loaded successfully', file=sys.stderr)\"\n</code></pre></p> </li> <li> <p>Check tensor shapes:    Add print transforms in adapters (see Adapter Debugging above)</p> </li> <li> <p>Isolate the component:    Test individual components in Python:    <pre><code>from sparkwheel import Config\nconfig = Config.from_file(\"config.yaml\")\nmodel = config.resolve(\"system::model\")\nprint(model)  # Does it instantiate correctly?\n</code></pre></p> </li> <li> <p>Check logs:    Look for warnings/errors in the console output</p> </li> </ol>"},{"location":"how-to/troubleshooting/#common-error-messages-reference","title":"Common Error Messages Reference","text":""},{"location":"how-to/troubleshooting/#typeerror-unhashable-type-dict","title":"TypeError: unhashable type: 'dict'","text":"<p>Cause: Passing a dict where Lighter expects a hashable key</p> <p>Common scenario: Using dict-based batch in metric that expects tensors</p> <p>Solution: Use MetricsAdapter to extract tensors: <pre><code>system:\n  adapters:\n    train:\n      metrics:\n        pred_transforms:\n          - \"$lambda x: x['logits']\"  # Extract tensor from dict\n</code></pre></p>"},{"location":"how-to/troubleshooting/#runtimeerror-expected-all-tensors-to-be-on-the-same-device","title":"RuntimeError: Expected all tensors to be on the same device","text":"<p>Cause: Model on GPU but data on CPU (or vice versa)</p> <p>Solution: Lighter handles this automatically. If you see this: - Check custom transforms aren't moving data - Ensure model is properly registered in System - For manual operations, use <code>self.device</code>:   <pre><code>def custom_operation(self):\n    tensor = torch.tensor([1, 2, 3]).to(self.device)\n</code></pre></p>"},{"location":"how-to/troubleshooting/#valueerror-the-loss-dictionary-must-include-a-total-key","title":"ValueError: The loss dictionary must include a 'total' key","text":"<p>Cause: Dict-based loss missing required 'total' key</p> <p>Solution: <pre><code>def my_criterion(pred, target):\n    loss1 = ...\n    loss2 = ...\n    return {\n        \"total\": loss1 + loss2,  # Required!\n        \"classification\": loss1,\n        \"segmentation\": loss2,\n    }\n</code></pre></p>"},{"location":"how-to/troubleshooting/#oserror-errno-24-too-many-open-files","title":"OSError: [Errno 24] Too many open files","text":"<p>Cause: Too many num_workers, system limit reached</p> <p>Solution: <pre><code># Temporary fix (macOS/Linux)\nulimit -n 4096\n\n# Or reduce num_workers\nlighter fit config.yaml system::dataloaders::train::num_workers=4\n</code></pre></p>"},{"location":"how-to/troubleshooting/#real-error-examples-from-users","title":"Real Error Examples from Users","text":""},{"location":"how-to/troubleshooting/#example-1-circular-reference","title":"Example 1: Circular Reference","text":"<p>Error: <pre><code>RecursionError: maximum recursion depth exceeded\n</code></pre></p> <p>User's config: <pre><code>system:\n  model:\n    _target_: MyModel\n    optimizer: \"@system::optimizer\"  # \u274c Circular!\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"  # \u274c Circular!\n</code></pre></p> <p>Fix: <pre><code>vars:\n  lr: 0.001\n\nsystem:\n  model:\n    _target_: MyModel\n    lr: \"%vars::lr\"  # Use var instead\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: \"%vars::lr\"\n</code></pre></p>"},{"location":"how-to/troubleshooting/#example-2-wrong-loss-function-for-task","title":"Example 2: Wrong Loss Function for Task","text":"<p>Error: Loss is negative or NaN</p> <p>User's config: <pre><code># Binary classification with CrossEntropyLoss (wrong!)\nsystem:\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss  # For multi-class!\n</code></pre></p> <p>Fix: <pre><code># Use BCEWithLogitsLoss for binary\nsystem:\n  criterion:\n    _target_: torch.nn.BCEWithLogitsLoss  # For binary classification\n</code></pre></p>"},{"location":"how-to/troubleshooting/#example-3-adapter-argument-mismatch","title":"Example 3: Adapter Argument Mismatch","text":"<p>Error: <pre><code>TypeError: __call__() got an unexpected keyword argument 'preds'\n</code></pre></p> <p>User's config: <pre><code>system:\n  metrics:\n    train:\n      - _target_: torchmetrics.Accuracy\n        # Expects 'preds' and 'target' kwargs\n  adapters:\n    train:\n      metrics:\n        _target_: lighter.adapters.MetricsAdapter\n        # Using positional (default) instead of kwargs\n</code></pre></p> <p>Fix: <pre><code>system:\n  adapters:\n    train:\n      metrics:\n        _target_: lighter.adapters.MetricsAdapter\n        pred_argument: \"preds\"    # Match metric signature\n        target_argument: \"target\"\n</code></pre></p>"},{"location":"how-to/troubleshooting/#getting-help","title":"Getting Help","text":"<p>When asking for help, include:</p> <ol> <li>Your config file (or relevant section)</li> <li>Full error message (including traceback)</li> <li>Lighter version: <code>lighter --version</code></li> <li>Python/PyTorch versions: <code>python --version</code>, <code>python -c \"import torch; print(torch.__version__)\"</code></li> <li>What you've tried so far</li> </ol>"},{"location":"how-to/troubleshooting/#resources","title":"Resources","text":"<ol> <li>Documentation: Search this site</li> <li>FAQ: Common questions</li> <li>Examples: Check <code>projects/</code> directory in the repo</li> <li>PyTorch Lightning: Lightning docs for Trainer issues</li> <li>Discord: Join community</li> <li>GitHub Issues: Report bugs</li> </ol>"},{"location":"how-to/troubleshooting/#summary","title":"Summary","text":"<p>Most issues fall into these categories:</p> Category Quick Fix Config syntax Check YAML indentation, quotes, colons References Use <code>::</code> for config, <code>.</code> for Python Memory Reduce batch size, use mixed precision Speed Increase num_workers, enable pin_memory DDP Enable sync_batchnorm, use rank_zero_only Adapters Add print transforms to inspect shapes Metrics Check mode has metrics, verify adapter args <p>Pro tip: Most errors can be caught early with <code>trainer::fast_dev_run=true</code>!</p>"},{"location":"how-to/writers/","title":"Writers: Save Your Results Like a Pro","text":"<p>Writers are your data persistence layer\u2014they capture model outputs and save them in formats ready for analysis, visualization, or deployment.</p>"},{"location":"how-to/writers/#quick-start","title":"Quick Start \ud83d\ude80","text":"<pre><code># Save predictions as images\ntrainer:\n  callbacks:\n    - _target_: lighter.callbacks.FileWriter\n      path: \"outputs/predictions\"\n      writer: \"image\"  # PNG for 2D, MP4 for 3D\n\n# Save metrics to CSV\ntrainer:\n  callbacks:\n    - _target_: lighter.callbacks.TableWriter\n      path: \"outputs/metrics.csv\"\n</code></pre>"},{"location":"how-to/writers/#writer-types-at-a-glance","title":"Writer Types at a Glance","text":"Writer Purpose Output Format Best For FileWriter Save predictions/tensors PNG, MP4, PT Images, videos, tensors TableWriter Save tabular data CSV Metrics, statistics, results"},{"location":"how-to/writers/#using-filewriter","title":"Using <code>FileWriter</code>","text":"<p><code>FileWriter</code> callback saves tensors to files, supports various formats, and is customizable.</p> <p>Configuration:</p> <p>Configure <code>FileWriter</code> in <code>config.yaml</code> within <code>trainer.callbacks</code> section:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.FileWriter # Use the FileWriter callback\n      path: \"outputs/predictions\"          # Directory to save output files\n      writer: \"tensor\"                     # Writer function to use\n</code></pre> <ul> <li><code>_target_: lighter.callbacks.FileWriter</code>: Specifies that you want to use the <code>FileWriter</code> callback.</li> <li><code>path: \"outputs/predictions\"</code>: Defines the directory where the output files will be saved. Lighter will create this directory if it doesn't exist.</li> <li><code>writer: \"tensor\"</code>: Specifies the writer function to be used for saving tensors.</li> </ul> <p>Built-in Writer Functions:</p> <p><code>FileWriter</code> has built-in writer functions for different formats:</p> <ul> <li><code>\"tensor\"</code>: Raw PyTorch <code>.pt</code> files (general tensor saving).</li> <li><code>\"image\"</code>: PNG images for 2D tensors.</li> <li><code>\"video\"</code>: MP4 videos for 4D tensor time-series (CTHW format).</li> </ul> <p>Usage:</p> <p>Once configured, <code>FileWriter</code> is used by Lighter in validation, test, and predict stages (if enabled).</p> <p>In these stages, per batch, <code>FileWriter</code>:</p> <ol> <li>Receives <code>pred</code> tensor from <code>predict_step</code>, <code>validation_step</code>, or <code>test_step</code>.</li> <li>Applies <code>LoggingAdapter</code> transforms (if configured).</li> <li>Uses writer function (e.g., <code>\"tensor\"</code>) to save <code>pred</code> tensor to file in <code>path</code> dir.</li> <li>Names file using batch <code>identifier</code> (if available) or generates unique name.</li> </ol> <p>Example: Saving Predictions as Tensors</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.FileWriter\n      path: \"outputs/predictions\"\n      writer: \"tensor\" # Save as .pt files\n\nsystem:\n  # ... (other system configurations) ...\n  dataloaders:\n    val:\n      _target_: torch.utils.data.DataLoader\n      dataset:\n        _target_: my_project.datasets.MyDataset\n        root: \"data/\"\n      batch_size: 1\n</code></pre> <p>Example config: <code>FileWriter</code> saves predictions during validation stage as PyTorch tensor files in <code>outputs/predictions</code> dir.</p>"},{"location":"how-to/writers/#extending-filewriter-with-custom-writers","title":"Extending <code>FileWriter</code> with Custom Writers","text":"<p>Extend <code>FileWriter</code> by creating custom writer functions or classes for specific needs.</p> <p>1. Create Custom Writer Function:</p> <p>Define a custom writer function with two arguments:</p> <ul> <li><code>path</code>: Full file path for saving tensor (filename &amp; extension).</li> <li><code>tensor</code>: PyTorch tensor to save.</li> </ul> <p>Example: Custom Writer Function for Text Files</p> my_project/writers/my_custom_writer.py<pre><code>import torch\nimport numpy as np\n\ndef write_tensor_as_text(path: str, tensor: torch.Tensor):\n    \"\"\"Saves tensor to text file.\"\"\"\n    tensor_numpy = tensor.cpu().numpy() # Convert to NumPy array\n    np.savetxt(path, tensor_numpy)      # Save as text file\n</code></pre> <p>2. Register Custom Writer Function:</p> <p>Register custom writer function in <code>config.yaml</code> to use with <code>FileWriter</code>:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.FileWriter\n      path: \"outputs/text_tensors\"\n      writer: my_project.writers.my_custom_writer.write_tensor_as_text # Path to custom writer\n</code></pre> <ul> <li><code>writer</code>: Path to custom writer function. Replace <code>\"my_project.writers.my_custom_writer\"</code> with your module path.</li> </ul> <p>3. Create Custom Writer Class (Advanced):</p> <p>For complex logic or stateful writers, create a custom class inheriting from <code>lighter.callbacks.writer.BaseWriter</code>.</p> <p>Example: Custom Writer Class for Tensors with Metadata</p> my_project/writers/my_custom_writer_class.py<pre><code>from lighter.callbacks.writer import BaseWriter\nimport torch\nimport json\nimport os\n\nclass MyCustomClassWriter(BaseWriter):\n    @property\n    def writers(self):\n        return {\"tensor_with_metadata\": self.write_tensor_with_metadata} # Register writer function\n\n    def write(self, tensor: torch.Tensor, identifier: str):\n        \"\"\"Main write method called by FileWriter.\"\"\"\n        path = os.path.join(self.path, f\"{identifier}.json\") # Define output path\n        self.write_tensor_with_metadata(path, tensor, identifier=identifier) # Call writer function\n\n    def write_tensor_with_metadata(self, path: str, tensor: torch.Tensor, identifier: str):\n        \"\"\"Saves tensor to JSON file with metadata.\"\"\"\n        metadata = {\n            \"identifier\": identifier,\n            \"shape\": list(tensor.shape),\n            \"dtype\": str(tensor.dtype),\n            \"timestamp\": datetime.datetime.now().isoformat()\n        }\n        data = {\n            \"metadata\": metadata,\n            \"data\": tensor.cpu().numpy().tolist() # Convert tensor data to list\n        }\n        with open(path, 'w') as f:\n            json.dump(data, f, indent=4) # Save data+metadata to JSON\n</code></pre> <p><code>MyCustomClassWriter</code> class example:</p> <ul> <li>Inherits from <code>BaseWriter</code>.</li> <li><code>write_tensor_with_metadata</code>: Saves tensors to JSON with metadata (shape, dtype, timestamp).</li> <li>Registers writer function in <code>writers</code> property with key <code>\"tensor_with_metadata\"</code>.</li> <li>Overrides <code>write</code> method for filename generation and calling custom writer function.</li> </ul> <p>4. Use Custom Writer Class in <code>config.yaml</code>:</p> <p>Use custom writer class by specifying class module path and registered writer key in <code>config.yaml</code>:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.FileWriter\n      path: \"outputs/metadata_tensors\"\n      writer: my_project.writers.my_custom_writer_class.MyCustomClassWriter.tensor_with_metadata # Custom class writer\n</code></pre> <ul> <li><code>writer</code>: Path to custom writer class and registered writer key (<code>\"tensor_with_metadata\"</code>).</li> </ul>"},{"location":"how-to/writers/#using-tablewriter","title":"Using <code>TableWriter</code>","text":"<p><code>TableWriter</code> callback saves tabular data to CSV files, useful for logging metrics or aggregated predictions.</p> <p>Configuration:</p> <p>Configure <code>TableWriter</code> in <code>config.yaml</code> within <code>trainer.callbacks</code> section:</p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.TableWriter # Use the TableWriter callback\n      path: \"outputs/metrics.csv\"          # Path to save CSV file\n</code></pre> <ul> <li><code>_target_: lighter.callbacks.TableWriter</code>: Use <code>TableWriter</code> callback.</li> <li><code>path: \"outputs/metrics.csv\"</code>: CSV file path for saving tabular data.</li> </ul> <p>Usage:</p> <p>To use <code>TableWriter</code>, return a dictionary from <code>validation_step</code>, <code>test_step</code>, or <code>predict_step</code>. <code>TableWriter</code> saves key-value pairs from dict as CSV rows.</p> <p>Example: Logging Metrics to CSV using <code>TableWriter</code></p> config.yaml<pre><code>trainer:\n  callbacks:\n    - _target_: lighter.callbacks.TableWriter\n      path: \"outputs/metrics.csv\" # Save metrics to CSV\n\nsystem:\n  metrics:\n    val:\n      - _target_: torchmetrics.Accuracy\n      - _target_: torchmetrics.DiceCoefficient\n\n  def validation_step(self, batch, batch_idx):\n    output = super().validation_step(batch, batch_idx) # Call base validation step\n    metrics = output[Data.METRICS] # Get computed metrics\n    self.log_dict(metrics)        # Log metrics for display\n    return metrics                # Return metrics dictionary for TableWriter\n</code></pre> <p>Example: <code>TableWriter</code> saves data to <code>outputs/metrics.csv</code>. In <code>validation_step</code>:</p> <ul> <li>Call base class <code>validation_step</code> to compute metrics.</li> <li>Extract metrics from <code>output</code> dict.</li> <li>Return <code>metrics</code> dict from <code>validation_step</code>.</li> </ul> <p><code>TableWriter</code> captures dict from <code>validation_step</code>/<code>test_step</code>/<code>predict_step</code>, saves as CSV rows. Dict keys become CSV column headers.</p>"},{"location":"how-to/writers/#custom-writer-example","title":"Custom Writer Example","text":"<pre><code># my_project/writers/visualization_writer.py\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nclass VisualizationWriter:\n    \"\"\"Save comparison plots of input, target, and prediction.\"\"\"\n    def __init__(self, path):\n        self.path = Path(path)\n        self.path.mkdir(exist_ok=True)\n\n    def write_comparison(self, input_img, target, prediction, identifier):\n        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n        axes[0].imshow(input_img.cpu().numpy().transpose(1, 2, 0))\n        axes[0].set_title(\"Input\")\n\n        axes[1].imshow(target.cpu().numpy(), cmap='tab20')\n        axes[1].set_title(\"Ground Truth\")\n\n        axes[2].imshow(prediction.argmax(0).cpu().numpy(), cmap='tab20')\n        axes[2].set_title(\"Prediction\")\n\n        for ax in axes:\n            ax.axis('off')\n\n        plt.tight_layout()\n        plt.savefig(self.path / f\"{identifier}_comparison.png\")\n        plt.close()\n</code></pre>"},{"location":"how-to/writers/#quick-reference","title":"Quick Reference \ud83d\udcc4","text":""},{"location":"how-to/writers/#filewriter-formats","title":"FileWriter Formats","text":"<pre><code># Medical imaging\nwriter: \"itk_nifti\"     # .nii.gz files\nwriter: \"itk_nrrd\"      # .nrrd files\nwriter: \"itk_seg_nrrd\"  # Segmentation masks\n\n# Standard formats\nwriter: \"tensor\"        # NumPy .npy files\nwriter: \"image\"         # PNG (2D) or MP4 (3D)\nwriter: \"video\"         # MP4 for time series\n\n# Custom\nwriter: my_project.writers.custom_writer\n</code></pre>"},{"location":"how-to/writers/#tablewriter-patterns","title":"TableWriter Patterns","text":"<pre><code># Return dict from step methods for TableWriter\ndef validation_step(self, batch, batch_idx):\n    # ... compute metrics ...\n    return {\n        \"patient_id\": batch[\"id\"],\n        \"dice_score\": dice,\n        \"loss\": loss.item(),\n        \"prediction_confidence\": pred.max()\n    }\n</code></pre>"},{"location":"how-to/writers/#common-issues-solutions","title":"Common Issues &amp; Solutions","text":"Issue Solution Permission denied Create output directory: <code>Path(\"outputs\").mkdir(exist_ok=True)</code> Out of disk space Use compression or write less frequently Slow writing Reduce precision to FP16 or use async writing"},{"location":"how-to/writers/#recap-and-next-steps","title":"Recap and Next Steps","text":"<p>\u2705 You've Learned: - Use FileWriter for predictions and tensors - Use TableWriter for metrics and results - Create custom writers for special needs - Optimize writing for performance</p> <p>\ud83c\udfaf Best Practices: - Organize outputs hierarchically - Use compression for large outputs - Consider async writing for speed - Save metadata with predictions</p> <p>\ud83d\udca1 Pro Tip: Always save enough information to reproduce your results!</p>"},{"location":"how-to/writers/#related-guides","title":"Related Guides","text":"<ul> <li>Adapters - Transform before writing</li> <li>Inferers - Write inference results</li> </ul>"},{"location":"migration/from-pytorch-lightning/","title":"Migrating from PyTorch Lightning","text":"<p>Quick guide for PyTorch Lightning users transitioning to Lighter.</p>"},{"location":"migration/from-pytorch-lightning/#key-difference-configuration-over-code","title":"Key Difference: Configuration Over Code","text":"<p>Lighter uses YAML configs (powered by Sparkwheel) instead of Python classes for experiment definition.</p>"},{"location":"migration/from-pytorch-lightning/#conceptual-mapping","title":"Conceptual Mapping","text":"PyTorch Lightning Lighter <code>LightningModule</code> <code>System</code> + YAML config <code>Trainer</code> <code>Trainer</code> (same, from PL) <code>training_step()</code> Handled by <code>System</code> <code>validation_step()</code> Handled by <code>System</code> <code>configure_optimizers()</code> Optimizer in YAML Custom callbacks Same (PL callbacks work) Loggers Same (PL loggers work)"},{"location":"migration/from-pytorch-lightning/#simple-example","title":"Simple Example","text":""},{"location":"migration/from-pytorch-lightning/#before-pytorch-lightning","title":"Before (PyTorch Lightning)","text":"<pre><code>class LitModel(LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.model = resnet18(num_classes=10)\n        self.criterion = CrossEntropyLoss()\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y)\n        return loss\n\n    def configure_optimizers(self):\n        return Adam(self.parameters(), lr=0.001)\n\ntrainer = Trainer(max_epochs=10)\ntrainer.fit(model, train_loader)\n</code></pre>"},{"location":"migration/from-pytorch-lightning/#after-lighter","title":"After (Lighter)","text":"<pre><code>trainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 10\n\nsystem:\n  _target_: lighter.System\n\n  model:\n    _target_: torchvision.models.resnet18\n    num_classes: 10\n\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n\n  dataloaders:\n    train: ...  # DataLoader config\n</code></pre> <pre><code>lighter fit config.yaml\n</code></pre> <p>Key insight: Same Trainer, same training logic, different interface.</p>"},{"location":"migration/from-pytorch-lightning/#what-you-need-to-learn","title":"What You Need to Learn","text":"<p>Only 3 things are Lighter-specific:</p> <ol> <li>Sparkwheel Configuration Syntax - Configuration Guide | Sparkwheel docs</li> <li>Adapters (Lighter's key feature) - Adapters Guide</li> <li>Project Module (optional) - Project Module Guide</li> </ol>"},{"location":"migration/from-pytorch-lightning/#what-stays-the-same","title":"What Stays the Same","text":"<p>Everything else is PyTorch Lightning:</p> <ul> <li>Trainer arguments - PL Trainer docs</li> <li>Callbacks - PL Callback docs</li> <li>Loggers - PL Logger docs</li> <li>Distributed training - PL distributed docs</li> <li>Profiling - PL profiler docs</li> </ul>"},{"location":"migration/from-pytorch-lightning/#common-migration-patterns","title":"Common Migration Patterns","text":""},{"location":"migration/from-pytorch-lightning/#custom-model","title":"Custom Model","text":"<p>Your <code>nn.Module</code> works as-is: <pre><code>system:\n  model:\n    _target_: my_project.models.MyCustomModel\n    arg1: value1\n</code></pre></p>"},{"location":"migration/from-pytorch-lightning/#custom-dataset","title":"Custom Dataset","text":"<p>Your PyTorch <code>Dataset</code> works directly: <pre><code>system:\n  dataloaders:\n    train:\n      _target_: torch.utils.data.DataLoader\n      dataset:\n        _target_: my_project.datasets.MyDataset\n        data_path: /path/to/data\n</code></pre></p>"},{"location":"migration/from-pytorch-lightning/#custom-callbacks","title":"Custom Callbacks","text":"<p>PL callbacks work without modification: <pre><code>trainer:\n  callbacks:\n    - _target_: pytorch_lightning.callbacks.EarlyStopping\n      monitor: val_loss\n      patience: 5\n    - _target_: my_project.callbacks.MyCustomCallback\n      arg: value\n</code></pre></p>"},{"location":"migration/from-pytorch-lightning/#learning-rate-schedulers","title":"Learning Rate Schedulers","text":"<pre><code>system:\n  scheduler:\n    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau\n    optimizer: \"@system::optimizer\"\n    factor: 0.5\n    patience: 10\n</code></pre>"},{"location":"migration/from-pytorch-lightning/#when-not-to-migrate","title":"When NOT to Migrate","text":"<p>Lighter might not fit if:</p> <ul> <li>You need highly custom training loops (stick with PL or PyTorch)</li> <li>You prefer writing code over configuration</li> <li>Your project doesn't run many experimental variations</li> </ul>"},{"location":"migration/from-pytorch-lightning/#next-steps","title":"Next Steps","text":"<ol> <li>Start with the Zero to Hero tutorial</li> <li>Try the Image Classification Tutorial</li> <li>Understand Design Philosophy</li> <li>Learn about Adapters (Lighter's superpower)</li> </ol>"},{"location":"reference/","title":"lighter","text":"<p>Lighter is a framework for streamlining deep learning experiments with configuration files.</p> <ul> <li>utils</li> <li>engine</li> <li>adapters</li> <li>callbacks</li> <li>system</li> </ul>"},{"location":"reference/#lighter.Runner","title":"<code>Runner</code>","text":"<p>Executes training stages using validated and resolved configurations.</p> <p>The Runner loads configurations using Sparkwheel, applies CLI overrides, validates against the schema, prunes unused components for the stage, and executes the appropriate PyTorch Lightning trainer method.</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>class Runner:\n    \"\"\"\n    Executes training stages using validated and resolved configurations.\n\n    The Runner loads configurations using Sparkwheel, applies CLI overrides,\n    validates against the schema, prunes unused components for the stage,\n    and executes the appropriate PyTorch Lightning trainer method.\n    \"\"\"\n\n    STAGE_MODES = {\n        Stage.FIT: [Mode.TRAIN, Mode.VAL],\n        Stage.VALIDATE: [Mode.VAL],\n        Stage.TEST: [Mode.TEST],\n        Stage.PREDICT: [Mode.PREDICT],\n    }\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the runner with empty state.\"\"\"\n        self.config: Config | None = None\n        self.system: System | None = None\n        self.trainer: Trainer | None = None\n\n    def run(\n        self,\n        stage: Stage,\n        config: str | list[str] | dict,\n        overrides: list[str] | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Run a training stage with configuration and overrides.\n\n        Args:\n            stage: Stage to run (fit, validate, test, predict)\n            config: Config file path(s) or dict. If string, supports comma-separated paths.\n            overrides: List of CLI override strings in format \"key::path=value\"\n\n        Raises:\n            ValueError: If config validation fails or required components are missing\n            TypeError: If system or trainer are not the correct type\n        \"\"\"\n        seed_everything()\n\n        # Handle comma-separated config files\n        if isinstance(config, str) and \",\" in config:\n            config = config.split(\",\")\n\n        # Load config with CLI overrides and validation (all in one step!)\n        try:\n            self.config = Config.from_cli(\n                config,\n                overrides or [],\n                schema=LighterConfig,\n            )\n        except ValidationError as e:\n            raise ValueError(f\"Configuration validation failed:\\n{e}\") from e\n\n        # Prune unused components for this stage\n        self._prune_for_stage(stage)\n\n        # Setup and run\n        self._setup(stage)\n        self._execute(stage)\n\n    def _prune_for_stage(self, stage: Stage) -&gt; None:\n        \"\"\"\n        Remove unused components using Sparkwheel's delete directive (~).\n\n        Args:\n            stage: Current stage being executed\n        \"\"\"\n        if self.config is None:\n            raise ValueError(\"Config must be loaded before pruning\")\n\n        required = set(self.STAGE_MODES[stage])\n        all_modes = {Mode.TRAIN, Mode.VAL, Mode.TEST, Mode.PREDICT}\n\n        # Build delete directives for unused modes\n        deletes = {}\n        for mode in all_modes - required:\n            deletes[f\"~system::dataloaders::{mode}\"] = None\n            deletes[f\"~system::metrics::{mode}\"] = None\n\n        # Remove optimizer/scheduler/criterion for non-training stages\n        if stage != Stage.FIT:\n            deletes[\"~system::optimizer\"] = None\n            deletes[\"~system::scheduler\"] = None\n            if stage != Stage.VALIDATE:\n                deletes[\"~system::criterion\"] = None\n\n        # Keep only args for this stage\n        for s in [Stage.FIT, Stage.VALIDATE, Stage.TEST, Stage.PREDICT]:\n            if s != stage:\n                deletes[f\"~args::{s}\"] = None\n\n        # Apply deletions\n        self.config.update(deletes)\n\n    def _setup(self, stage: Stage) -&gt; None:\n        \"\"\"\n        Setup system and trainer from configuration.\n\n        Args:\n            stage: Current stage being executed\n\n        Raises:\n            TypeError: If system or trainer are not the correct type\n        \"\"\"\n        if self.config is None:\n            raise ValueError(\"Config must be loaded before setup\")\n\n        # Import project module if specified\n        project = self.config.get(\"project\")\n        if project:\n            import_module_from_path(\"project\", project)\n\n        # Resolve system\n        self.system = self.config.resolve(\"system\")\n        if not isinstance(self.system, System):\n            raise TypeError(f\"system must be System, got {type(self.system)}\")\n\n        # Resolve trainer\n        self.trainer = self.config.resolve(\"trainer\")\n        if not isinstance(self.trainer, Trainer):\n            raise TypeError(f\"trainer must be Trainer, got {type(self.trainer)}\")\n\n        # Save config to system checkpoint and trainer logger\n        if self.system:\n            self.system.save_hyperparameters(self.config.get())\n        if self.trainer and self.trainer.logger:\n            self.trainer.logger.log_hyperparams(self.config.get())\n\n    def _execute(self, stage: Stage) -&gt; None:\n        \"\"\"\n        Execute the training stage.\n\n        Args:\n            stage: Stage to execute\n\n        Raises:\n            AttributeError: If trainer doesn't have the stage method\n        \"\"\"\n        if self.config is None or self.trainer is None or self.system is None:\n            raise ValueError(\"Config, trainer, and system must be set up before execution\")\n\n        # Get stage-specific arguments\n        args = self.config.resolve(f\"args::{stage}\", default={})\n\n        # Execute the stage method\n        stage_method = getattr(self.trainer, str(stage))\n        stage_method(self.system, **args)\n</code></pre>"},{"location":"reference/#lighter.Runner.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the runner with empty state.</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the runner with empty state.\"\"\"\n    self.config: Config | None = None\n    self.system: System | None = None\n    self.trainer: Trainer | None = None\n</code></pre>"},{"location":"reference/#lighter.Runner._execute","title":"<code>_execute(stage)</code>","text":"<p>Execute the training stage.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Stage to execute</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If trainer doesn't have the stage method</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def _execute(self, stage: Stage) -&gt; None:\n    \"\"\"\n    Execute the training stage.\n\n    Args:\n        stage: Stage to execute\n\n    Raises:\n        AttributeError: If trainer doesn't have the stage method\n    \"\"\"\n    if self.config is None or self.trainer is None or self.system is None:\n        raise ValueError(\"Config, trainer, and system must be set up before execution\")\n\n    # Get stage-specific arguments\n    args = self.config.resolve(f\"args::{stage}\", default={})\n\n    # Execute the stage method\n    stage_method = getattr(self.trainer, str(stage))\n    stage_method(self.system, **args)\n</code></pre>"},{"location":"reference/#lighter.Runner._prune_for_stage","title":"<code>_prune_for_stage(stage)</code>","text":"<p>Remove unused components using Sparkwheel's delete directive (~).</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Current stage being executed</p> required Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def _prune_for_stage(self, stage: Stage) -&gt; None:\n    \"\"\"\n    Remove unused components using Sparkwheel's delete directive (~).\n\n    Args:\n        stage: Current stage being executed\n    \"\"\"\n    if self.config is None:\n        raise ValueError(\"Config must be loaded before pruning\")\n\n    required = set(self.STAGE_MODES[stage])\n    all_modes = {Mode.TRAIN, Mode.VAL, Mode.TEST, Mode.PREDICT}\n\n    # Build delete directives for unused modes\n    deletes = {}\n    for mode in all_modes - required:\n        deletes[f\"~system::dataloaders::{mode}\"] = None\n        deletes[f\"~system::metrics::{mode}\"] = None\n\n    # Remove optimizer/scheduler/criterion for non-training stages\n    if stage != Stage.FIT:\n        deletes[\"~system::optimizer\"] = None\n        deletes[\"~system::scheduler\"] = None\n        if stage != Stage.VALIDATE:\n            deletes[\"~system::criterion\"] = None\n\n    # Keep only args for this stage\n    for s in [Stage.FIT, Stage.VALIDATE, Stage.TEST, Stage.PREDICT]:\n        if s != stage:\n            deletes[f\"~args::{s}\"] = None\n\n    # Apply deletions\n    self.config.update(deletes)\n</code></pre>"},{"location":"reference/#lighter.Runner._setup","title":"<code>_setup(stage)</code>","text":"<p>Setup system and trainer from configuration.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Current stage being executed</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If system or trainer are not the correct type</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def _setup(self, stage: Stage) -&gt; None:\n    \"\"\"\n    Setup system and trainer from configuration.\n\n    Args:\n        stage: Current stage being executed\n\n    Raises:\n        TypeError: If system or trainer are not the correct type\n    \"\"\"\n    if self.config is None:\n        raise ValueError(\"Config must be loaded before setup\")\n\n    # Import project module if specified\n    project = self.config.get(\"project\")\n    if project:\n        import_module_from_path(\"project\", project)\n\n    # Resolve system\n    self.system = self.config.resolve(\"system\")\n    if not isinstance(self.system, System):\n        raise TypeError(f\"system must be System, got {type(self.system)}\")\n\n    # Resolve trainer\n    self.trainer = self.config.resolve(\"trainer\")\n    if not isinstance(self.trainer, Trainer):\n        raise TypeError(f\"trainer must be Trainer, got {type(self.trainer)}\")\n\n    # Save config to system checkpoint and trainer logger\n    if self.system:\n        self.system.save_hyperparameters(self.config.get())\n    if self.trainer and self.trainer.logger:\n        self.trainer.logger.log_hyperparams(self.config.get())\n</code></pre>"},{"location":"reference/#lighter.Runner.run","title":"<code>run(stage, config, overrides=None)</code>","text":"<p>Run a training stage with configuration and overrides.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Stage to run (fit, validate, test, predict)</p> required <code>config</code> <code>str | list[str] | dict</code> <p>Config file path(s) or dict. If string, supports comma-separated paths.</p> required <code>overrides</code> <code>list[str] | None</code> <p>List of CLI override strings in format \"key::path=value\"</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If config validation fails or required components are missing</p> <code>TypeError</code> <p>If system or trainer are not the correct type</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def run(\n    self,\n    stage: Stage,\n    config: str | list[str] | dict,\n    overrides: list[str] | None = None,\n) -&gt; None:\n    \"\"\"\n    Run a training stage with configuration and overrides.\n\n    Args:\n        stage: Stage to run (fit, validate, test, predict)\n        config: Config file path(s) or dict. If string, supports comma-separated paths.\n        overrides: List of CLI override strings in format \"key::path=value\"\n\n    Raises:\n        ValueError: If config validation fails or required components are missing\n        TypeError: If system or trainer are not the correct type\n    \"\"\"\n    seed_everything()\n\n    # Handle comma-separated config files\n    if isinstance(config, str) and \",\" in config:\n        config = config.split(\",\")\n\n    # Load config with CLI overrides and validation (all in one step!)\n    try:\n        self.config = Config.from_cli(\n            config,\n            overrides or [],\n            schema=LighterConfig,\n        )\n    except ValidationError as e:\n        raise ValueError(f\"Configuration validation failed:\\n{e}\") from e\n\n    # Prune unused components for this stage\n    self._prune_for_stage(stage)\n\n    # Setup and run\n    self._setup(stage)\n    self._execute(stage)\n</code></pre>"},{"location":"reference/#lighter.System","title":"<code>System</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>System encapsulates the components of a deep learning system, extending PyTorch Lightning's LightningModule.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>Model.</p> required <code>optimizer</code> <code>Optimizer | None</code> <p>Optimizer.</p> <code>None</code> <code>scheduler</code> <code>LRScheduler | None</code> <p>Learning rate scheduler.</p> <code>None</code> <code>criterion</code> <code>Callable | None</code> <p>Criterion (loss) function.</p> <code>None</code> <code>metrics</code> <code>dict[str, Metric | list[Metric] | dict[str, Metric]] | None</code> <p>Metrics for train, val, and test. Supports a single/list/dict of <code>torchmetrics</code> metrics.</p> <code>None</code> <code>dataloaders</code> <code>dict[str, DataLoader]</code> <p>Dataloaders for train, val, test, and predict.</p> required <code>adapters</code> <code>dict[str, Callable] | None</code> <p>Adapters for batch preparation, criterion argument adaptation, metrics argument adaptation, and logging data adaptation.</p> <code>None</code> <code>inferer</code> <code>Callable | None</code> <p>Inferer to use in val/test/predict modes. Custom inferers can be defined to handle inference logic.</p> <code>None</code> Source code in <code>src/lighter/system.py</code> <pre><code>class System(pl.LightningModule):\n    \"\"\"\n    System encapsulates the components of a deep learning system, extending PyTorch Lightning's LightningModule.\n\n    Args:\n        model: Model.\n        optimizer: Optimizer.\n        scheduler: Learning rate scheduler.\n        criterion: Criterion (loss) function.\n        metrics: Metrics for train, val, and test. Supports a single/list/dict of `torchmetrics` metrics.\n        dataloaders: Dataloaders for train, val, test, and predict.\n        adapters: Adapters for batch preparation, criterion argument adaptation, metrics argument adaptation, and logging data adaptation.\n        inferer: Inferer to use in val/test/predict modes. Custom inferers can be defined to handle inference logic.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Module,\n        dataloaders: dict[str, DataLoader],\n        optimizer: Optimizer | None = None,\n        scheduler: LRScheduler | None = None,\n        criterion: Callable | None = None,\n        metrics: dict[str, Metric | list[Metric] | dict[str, Metric]] | None = None,\n        adapters: dict[str, Callable] | None = None,\n        inferer: Callable | None = None,\n    ) -&gt; None:\n        super().__init__()\n\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.criterion = criterion\n        self.inferer = inferer\n\n        #  Containers\n        self.dataloaders = DataLoaders(**(dataloaders or {}))\n        self.metrics = Metrics(**(metrics or {}))\n        self.adapters = Adapters(**(adapters or {}))\n\n        # Turn metrics container into a ModuleDict to register them properly.\n        self.metrics = PatchedModuleDict(asdict(self.metrics))\n\n        self.mode = None\n        self._setup_mode_hooks()\n\n    def _step(self, batch: dict, batch_idx: int) -&gt; dict[str, Any] | Any:\n        \"\"\"\n        Performs a step in the specified mode, processing the batch and calculating loss and metrics.\n\n        Args:\n            batch: The batch of data.\n            batch_idx: The index of the batch.\n        Returns:\n            dict or Any: For predict step, returns prediction only. For other steps,\n            returns dict with loss, metrics, input, target, pred, and identifier. Loss is None\n            for test step, metrics is None if unspecified.\n        \"\"\"\n        input, target, identifier = self._prepare_batch(batch)\n        pred = self.forward(input)\n\n        loss = self._calculate_loss(input, target, pred)\n        metrics = self._calculate_metrics(input, target, pred)\n\n        self._log_stats(loss, metrics, batch_idx)\n        output = self._prepare_output(identifier, input, target, pred, loss, metrics)\n        return output\n\n    def _prepare_batch(self, batch: dict) -&gt; tuple[Any, Any, Any]:\n        \"\"\"\n        Prepares the batch data.\n\n        Args:\n            batch: The input batch dictionary.\n\n        Returns:\n            tuple: A tuple containing (input, target, identifier).\n        \"\"\"\n        adapters = getattr(self.adapters, self.mode)\n        input, target, identifier = adapters.batch(batch)\n        return input, target, identifier\n\n    def forward(self, input: Any) -&gt; Any:\n        \"\"\"\n        Forward pass through the model.\n\n        Args:\n            input: The input data.\n\n        Returns:\n            Any: The model's output.\n        \"\"\"\n\n        # Pass `epoch` and/or `step` argument to forward if it accepts them\n        kwargs = {}\n        if hasarg(self.model.forward, Data.EPOCH):\n            kwargs[Data.EPOCH] = self.current_epoch\n        if hasarg(self.model.forward, Data.STEP):\n            kwargs[Data.STEP] = self.global_step\n\n        # Predict. Use inferer if available in val, test, and predict modes.\n        if self.inferer and self.mode in [Mode.VAL, Mode.TEST, Mode.PREDICT]:\n            return self.inferer(input, self.model, **kwargs)\n        return self.model(input, **kwargs)\n\n    def _calculate_loss(self, input: Any, target: Any, pred: Any) -&gt; Tensor | dict[str, Tensor] | None:\n        \"\"\"\n        Calculates the loss using the criterion if in train or validation mode.\n\n        Args:\n            input: The input data.\n            target: The target data.\n            pred: The model predictions.\n\n        Returns:\n            The calculated loss or None if not in train/val mode.\n\n        Raises:\n            ValueError: If criterion is not specified in train/val mode or if loss dict is missing 'total' key.\n        \"\"\"\n        loss = None\n        if self.mode in [Mode.TRAIN, Mode.VAL]:\n            if self.criterion is None:\n                raise ValueError(\"Please specify 'system.criterion' in the config.\")\n\n            adapters = getattr(self.adapters, self.mode)\n            loss = adapters.criterion(self.criterion, input, target, pred)\n\n            if isinstance(loss, dict) and \"total\" not in loss:\n                raise ValueError(\n                    \"The loss dictionary must include a 'total' key that combines all sublosses. \"\n                    \"Example: {'total': combined_loss, 'subloss1': loss1, ...}\"\n                )\n        return loss\n\n    def _calculate_metrics(self, input: Any, target: Any, pred: Any) -&gt; Any | None:\n        \"\"\"\n        Calculates the metrics if not in predict mode.\n\n        Args:\n            input: The input data.\n            target: The target data.\n            pred: The model predictions.\n\n        Returns:\n            The calculated metrics or None if in predict mode or no metrics specified.\n        \"\"\"\n        if self.mode == Mode.PREDICT or self.metrics[self.mode] is None:\n            return None\n\n        adapters = getattr(self.adapters, self.mode)\n        metrics = adapters.metrics(self.metrics[self.mode], input, target, pred)\n        return metrics\n\n    def _log_stats(self, loss: Tensor | dict[str, Tensor], metrics: MetricCollection, batch_idx: int) -&gt; None:\n        \"\"\"\n        Logs the loss, metrics, and optimizer statistics.\n\n        Args:\n            loss: The calculated loss.\n            metrics: The calculated metrics.\n            batch_idx: The index of the batch.\n        \"\"\"\n        if self.trainer.logger is None:\n            return\n\n        # Loss\n        if loss is not None:\n            if not isinstance(loss, dict):\n                self._log(f\"{self.mode}/{Data.LOSS}/{Data.STEP}\", loss, on_step=True)\n                self._log(f\"{self.mode}/{Data.LOSS}/{Data.EPOCH}\", loss, on_epoch=True)\n            else:\n                for name, subloss in loss.items():\n                    self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.STEP}\", subloss, on_step=True)\n                    self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.EPOCH}\", subloss, on_epoch=True)\n\n        # Metrics\n        if metrics is not None:\n            for name, metric in metrics.items():\n                self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.STEP}\", metric, on_step=True)\n                self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.EPOCH}\", metric, on_epoch=True)\n\n        # Optimizer's lr, momentum, beta. Logged in train mode and once per epoch.\n        if self.mode == Mode.TRAIN and batch_idx == 0:\n            for name, optimizer_stat in get_optimizer_stats(self.optimizer).items():\n                self._log(f\"{self.mode}/{name}\", optimizer_stat, on_epoch=True)\n\n    def _log(self, name: str, value: Any, on_step: bool = False, on_epoch: bool = False) -&gt; None:\n        \"\"\"Log a key, value pair. Syncs across distributed nodes if `on_epoch` is True.\n\n        Args:\n            name (str): key to log.\n            value (Any): value to log.\n            on_step (bool, optional): if True, logs on step.\n            on_epoch (bool, optional): if True, logs on epoch with sync_dist=True.\n        \"\"\"\n        batch_size = getattr(self.dataloaders, self.mode).batch_size\n        self.log(name, value, logger=True, batch_size=batch_size, on_step=on_step, on_epoch=on_epoch, sync_dist=on_epoch)\n\n    def _prepare_output(\n        self,\n        identifier: Any,\n        input: Any,\n        target: Any,\n        pred: Any,\n        loss: Tensor | dict[str, Tensor] | None,\n        metrics: Any | None,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Prepares the data to be returned by the step function to callbacks.\n\n        Args:\n            identifier: The batch identifier.\n            input: The input data.\n            target: The target data.\n            pred: The model predictions.\n            loss: The calculated loss.\n            metrics: The calculated metrics.\n\n        Returns:\n            dict: A dictionary containing all the step information.\n        \"\"\"\n        adapters = getattr(self.adapters, self.mode)\n        input, target, pred = adapters.logging(input, target, pred)\n        return {\n            Data.IDENTIFIER: identifier,\n            Data.INPUT: input,\n            Data.TARGET: target,\n            Data.PRED: pred,\n            Data.LOSS: loss,\n            Data.METRICS: metrics,\n            Data.STEP: self.global_step,\n            Data.EPOCH: self.current_epoch,\n        }\n\n    def configure_optimizers(self) -&gt; dict[str, Optimizer | LRScheduler] | None:\n        \"\"\"\n        Configures the optimizers and learning rate schedulers.\n\n        Returns:\n            dict: A dictionary containing the optimizer and scheduler.\n\n        Raises:\n            ValueError: If optimizer is not specified.\n        \"\"\"\n        if self.optimizer is None:\n            raise ValueError(\"Please specify 'system.optimizer' in the config.\")\n        if self.scheduler is None:\n            return {\"optimizer\": self.optimizer}\n        else:\n            return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler}\n\n    def _setup_mode_hooks(self):\n        \"\"\"\n        Sets up the training, validation, testing, and prediction hooks based on defined dataloaders.\n        \"\"\"\n        if self.dataloaders.train is not None:\n            self.training_step = self._step\n            self.train_dataloader = lambda: self.dataloaders.train\n            self.on_train_start = lambda: self._on_mode_start(Mode.TRAIN)\n            self.on_train_end = self._on_mode_end\n        if self.dataloaders.val is not None:\n            self.validation_step = self._step\n            self.val_dataloader = lambda: self.dataloaders.val\n            self.on_validation_start = lambda: self._on_mode_start(Mode.VAL)\n            self.on_validation_end = self._on_mode_end\n        if self.dataloaders.test is not None:\n            self.test_step = self._step\n            self.test_dataloader = lambda: self.dataloaders.test\n            self.on_test_start = lambda: self._on_mode_start(Mode.TEST)\n            self.on_test_end = self._on_mode_end\n        if self.dataloaders.predict is not None:\n            self.predict_step = self._step\n            self.predict_dataloader = lambda: self.dataloaders.predict\n            self.on_predict_start = lambda: self._on_mode_start(Mode.PREDICT)\n            self.on_predict_end = self._on_mode_end\n\n    def _on_mode_start(self, mode: str | None) -&gt; None:\n        \"\"\"\n        Sets the current mode at the start of a phase.\n\n        Args:\n            mode: The mode to set (train, val, test, or predict).\n        \"\"\"\n        self.mode = mode\n\n    def _on_mode_end(self) -&gt; None:\n        \"\"\"\n        Resets the mode at the end of a phase.\n        \"\"\"\n        self.mode = None\n\n    @property\n    def learning_rate(self) -&gt; float:\n        \"\"\"\n        Gets the learning rate of the optimizer.\n\n        Returns:\n            float: The learning rate.\n\n        Raises:\n            ValueError: If there are multiple optimizer parameter groups.\n        \"\"\"\n        if len(self.optimizer.param_groups) &gt; 1:\n            raise ValueError(\"The learning rate is not available when there are multiple optimizer parameter groups.\")\n        return self.optimizer.param_groups[0][\"lr\"]\n\n    @learning_rate.setter\n    def learning_rate(self, value: float) -&gt; None:\n        \"\"\"\n        Sets the learning rate of the optimizer.\n\n        Args:\n            value: The new learning rate.\n\n        Raises:\n            ValueError: If there are multiple optimizer parameter groups.\n        \"\"\"\n        if len(self.optimizer.param_groups) &gt; 1:\n            raise ValueError(\"The learning rate is not available when there are multiple optimizer parameter groups.\")\n        self.optimizer.param_groups[0][\"lr\"] = value\n</code></pre>"},{"location":"reference/#lighter.System.learning_rate","title":"<code>learning_rate</code>  <code>property</code> <code>writable</code>","text":"<p>Gets the learning rate of the optimizer.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The learning rate.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are multiple optimizer parameter groups.</p>"},{"location":"reference/#lighter.System._calculate_loss","title":"<code>_calculate_loss(input, target, pred)</code>","text":"<p>Calculates the loss using the criterion if in train or validation mode.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The model predictions.</p> required <p>Returns:</p> Type Description <code>Tensor | dict[str, Tensor] | None</code> <p>The calculated loss or None if not in train/val mode.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If criterion is not specified in train/val mode or if loss dict is missing 'total' key.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _calculate_loss(self, input: Any, target: Any, pred: Any) -&gt; Tensor | dict[str, Tensor] | None:\n    \"\"\"\n    Calculates the loss using the criterion if in train or validation mode.\n\n    Args:\n        input: The input data.\n        target: The target data.\n        pred: The model predictions.\n\n    Returns:\n        The calculated loss or None if not in train/val mode.\n\n    Raises:\n        ValueError: If criterion is not specified in train/val mode or if loss dict is missing 'total' key.\n    \"\"\"\n    loss = None\n    if self.mode in [Mode.TRAIN, Mode.VAL]:\n        if self.criterion is None:\n            raise ValueError(\"Please specify 'system.criterion' in the config.\")\n\n        adapters = getattr(self.adapters, self.mode)\n        loss = adapters.criterion(self.criterion, input, target, pred)\n\n        if isinstance(loss, dict) and \"total\" not in loss:\n            raise ValueError(\n                \"The loss dictionary must include a 'total' key that combines all sublosses. \"\n                \"Example: {'total': combined_loss, 'subloss1': loss1, ...}\"\n            )\n    return loss\n</code></pre>"},{"location":"reference/#lighter.System._calculate_metrics","title":"<code>_calculate_metrics(input, target, pred)</code>","text":"<p>Calculates the metrics if not in predict mode.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The model predictions.</p> required <p>Returns:</p> Type Description <code>Any | None</code> <p>The calculated metrics or None if in predict mode or no metrics specified.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _calculate_metrics(self, input: Any, target: Any, pred: Any) -&gt; Any | None:\n    \"\"\"\n    Calculates the metrics if not in predict mode.\n\n    Args:\n        input: The input data.\n        target: The target data.\n        pred: The model predictions.\n\n    Returns:\n        The calculated metrics or None if in predict mode or no metrics specified.\n    \"\"\"\n    if self.mode == Mode.PREDICT or self.metrics[self.mode] is None:\n        return None\n\n    adapters = getattr(self.adapters, self.mode)\n    metrics = adapters.metrics(self.metrics[self.mode], input, target, pred)\n    return metrics\n</code></pre>"},{"location":"reference/#lighter.System._log","title":"<code>_log(name, value, on_step=False, on_epoch=False)</code>","text":"<p>Log a key, value pair. Syncs across distributed nodes if <code>on_epoch</code> is True.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>key to log.</p> required <code>value</code> <code>Any</code> <p>value to log.</p> required <code>on_step</code> <code>bool</code> <p>if True, logs on step.</p> <code>False</code> <code>on_epoch</code> <code>bool</code> <p>if True, logs on epoch with sync_dist=True.</p> <code>False</code> Source code in <code>src/lighter/system.py</code> <pre><code>def _log(self, name: str, value: Any, on_step: bool = False, on_epoch: bool = False) -&gt; None:\n    \"\"\"Log a key, value pair. Syncs across distributed nodes if `on_epoch` is True.\n\n    Args:\n        name (str): key to log.\n        value (Any): value to log.\n        on_step (bool, optional): if True, logs on step.\n        on_epoch (bool, optional): if True, logs on epoch with sync_dist=True.\n    \"\"\"\n    batch_size = getattr(self.dataloaders, self.mode).batch_size\n    self.log(name, value, logger=True, batch_size=batch_size, on_step=on_step, on_epoch=on_epoch, sync_dist=on_epoch)\n</code></pre>"},{"location":"reference/#lighter.System._log_stats","title":"<code>_log_stats(loss, metrics, batch_idx)</code>","text":"<p>Logs the loss, metrics, and optimizer statistics.</p> <p>Parameters:</p> Name Type Description Default <code>loss</code> <code>Tensor | dict[str, Tensor]</code> <p>The calculated loss.</p> required <code>metrics</code> <code>MetricCollection</code> <p>The calculated metrics.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the batch.</p> required Source code in <code>src/lighter/system.py</code> <pre><code>def _log_stats(self, loss: Tensor | dict[str, Tensor], metrics: MetricCollection, batch_idx: int) -&gt; None:\n    \"\"\"\n    Logs the loss, metrics, and optimizer statistics.\n\n    Args:\n        loss: The calculated loss.\n        metrics: The calculated metrics.\n        batch_idx: The index of the batch.\n    \"\"\"\n    if self.trainer.logger is None:\n        return\n\n    # Loss\n    if loss is not None:\n        if not isinstance(loss, dict):\n            self._log(f\"{self.mode}/{Data.LOSS}/{Data.STEP}\", loss, on_step=True)\n            self._log(f\"{self.mode}/{Data.LOSS}/{Data.EPOCH}\", loss, on_epoch=True)\n        else:\n            for name, subloss in loss.items():\n                self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.STEP}\", subloss, on_step=True)\n                self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.EPOCH}\", subloss, on_epoch=True)\n\n    # Metrics\n    if metrics is not None:\n        for name, metric in metrics.items():\n            self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.STEP}\", metric, on_step=True)\n            self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.EPOCH}\", metric, on_epoch=True)\n\n    # Optimizer's lr, momentum, beta. Logged in train mode and once per epoch.\n    if self.mode == Mode.TRAIN and batch_idx == 0:\n        for name, optimizer_stat in get_optimizer_stats(self.optimizer).items():\n            self._log(f\"{self.mode}/{name}\", optimizer_stat, on_epoch=True)\n</code></pre>"},{"location":"reference/#lighter.System._on_mode_end","title":"<code>_on_mode_end()</code>","text":"<p>Resets the mode at the end of a phase.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _on_mode_end(self) -&gt; None:\n    \"\"\"\n    Resets the mode at the end of a phase.\n    \"\"\"\n    self.mode = None\n</code></pre>"},{"location":"reference/#lighter.System._on_mode_start","title":"<code>_on_mode_start(mode)</code>","text":"<p>Sets the current mode at the start of a phase.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str | None</code> <p>The mode to set (train, val, test, or predict).</p> required Source code in <code>src/lighter/system.py</code> <pre><code>def _on_mode_start(self, mode: str | None) -&gt; None:\n    \"\"\"\n    Sets the current mode at the start of a phase.\n\n    Args:\n        mode: The mode to set (train, val, test, or predict).\n    \"\"\"\n    self.mode = mode\n</code></pre>"},{"location":"reference/#lighter.System._prepare_batch","title":"<code>_prepare_batch(batch)</code>","text":"<p>Prepares the batch data.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>dict</code> <p>The input batch dictionary.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[Any, Any, Any]</code> <p>A tuple containing (input, target, identifier).</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _prepare_batch(self, batch: dict) -&gt; tuple[Any, Any, Any]:\n    \"\"\"\n    Prepares the batch data.\n\n    Args:\n        batch: The input batch dictionary.\n\n    Returns:\n        tuple: A tuple containing (input, target, identifier).\n    \"\"\"\n    adapters = getattr(self.adapters, self.mode)\n    input, target, identifier = adapters.batch(batch)\n    return input, target, identifier\n</code></pre>"},{"location":"reference/#lighter.System._prepare_output","title":"<code>_prepare_output(identifier, input, target, pred, loss, metrics)</code>","text":"<p>Prepares the data to be returned by the step function to callbacks.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Any</code> <p>The batch identifier.</p> required <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The model predictions.</p> required <code>loss</code> <code>Tensor | dict[str, Tensor] | None</code> <p>The calculated loss.</p> required <code>metrics</code> <code>Any | None</code> <p>The calculated metrics.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>A dictionary containing all the step information.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _prepare_output(\n    self,\n    identifier: Any,\n    input: Any,\n    target: Any,\n    pred: Any,\n    loss: Tensor | dict[str, Tensor] | None,\n    metrics: Any | None,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Prepares the data to be returned by the step function to callbacks.\n\n    Args:\n        identifier: The batch identifier.\n        input: The input data.\n        target: The target data.\n        pred: The model predictions.\n        loss: The calculated loss.\n        metrics: The calculated metrics.\n\n    Returns:\n        dict: A dictionary containing all the step information.\n    \"\"\"\n    adapters = getattr(self.adapters, self.mode)\n    input, target, pred = adapters.logging(input, target, pred)\n    return {\n        Data.IDENTIFIER: identifier,\n        Data.INPUT: input,\n        Data.TARGET: target,\n        Data.PRED: pred,\n        Data.LOSS: loss,\n        Data.METRICS: metrics,\n        Data.STEP: self.global_step,\n        Data.EPOCH: self.current_epoch,\n    }\n</code></pre>"},{"location":"reference/#lighter.System._setup_mode_hooks","title":"<code>_setup_mode_hooks()</code>","text":"<p>Sets up the training, validation, testing, and prediction hooks based on defined dataloaders.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _setup_mode_hooks(self):\n    \"\"\"\n    Sets up the training, validation, testing, and prediction hooks based on defined dataloaders.\n    \"\"\"\n    if self.dataloaders.train is not None:\n        self.training_step = self._step\n        self.train_dataloader = lambda: self.dataloaders.train\n        self.on_train_start = lambda: self._on_mode_start(Mode.TRAIN)\n        self.on_train_end = self._on_mode_end\n    if self.dataloaders.val is not None:\n        self.validation_step = self._step\n        self.val_dataloader = lambda: self.dataloaders.val\n        self.on_validation_start = lambda: self._on_mode_start(Mode.VAL)\n        self.on_validation_end = self._on_mode_end\n    if self.dataloaders.test is not None:\n        self.test_step = self._step\n        self.test_dataloader = lambda: self.dataloaders.test\n        self.on_test_start = lambda: self._on_mode_start(Mode.TEST)\n        self.on_test_end = self._on_mode_end\n    if self.dataloaders.predict is not None:\n        self.predict_step = self._step\n        self.predict_dataloader = lambda: self.dataloaders.predict\n        self.on_predict_start = lambda: self._on_mode_start(Mode.PREDICT)\n        self.on_predict_end = self._on_mode_end\n</code></pre>"},{"location":"reference/#lighter.System._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Performs a step in the specified mode, processing the batch and calculating loss and metrics.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>dict</code> <p>The batch of data.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the batch.</p> required <p>Returns:     dict or Any: For predict step, returns prediction only. For other steps,     returns dict with loss, metrics, input, target, pred, and identifier. Loss is None     for test step, metrics is None if unspecified.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _step(self, batch: dict, batch_idx: int) -&gt; dict[str, Any] | Any:\n    \"\"\"\n    Performs a step in the specified mode, processing the batch and calculating loss and metrics.\n\n    Args:\n        batch: The batch of data.\n        batch_idx: The index of the batch.\n    Returns:\n        dict or Any: For predict step, returns prediction only. For other steps,\n        returns dict with loss, metrics, input, target, pred, and identifier. Loss is None\n        for test step, metrics is None if unspecified.\n    \"\"\"\n    input, target, identifier = self._prepare_batch(batch)\n    pred = self.forward(input)\n\n    loss = self._calculate_loss(input, target, pred)\n    metrics = self._calculate_metrics(input, target, pred)\n\n    self._log_stats(loss, metrics, batch_idx)\n    output = self._prepare_output(identifier, input, target, pred, loss, metrics)\n    return output\n</code></pre>"},{"location":"reference/#lighter.System.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configures the optimizers and learning rate schedulers.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Optimizer | LRScheduler] | None</code> <p>A dictionary containing the optimizer and scheduler.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If optimizer is not specified.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def configure_optimizers(self) -&gt; dict[str, Optimizer | LRScheduler] | None:\n    \"\"\"\n    Configures the optimizers and learning rate schedulers.\n\n    Returns:\n        dict: A dictionary containing the optimizer and scheduler.\n\n    Raises:\n        ValueError: If optimizer is not specified.\n    \"\"\"\n    if self.optimizer is None:\n        raise ValueError(\"Please specify 'system.optimizer' in the config.\")\n    if self.scheduler is None:\n        return {\"optimizer\": self.optimizer}\n    else:\n        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler}\n</code></pre>"},{"location":"reference/#lighter.System.forward","title":"<code>forward(input)</code>","text":"<p>Forward pass through the model.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The model's output.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def forward(self, input: Any) -&gt; Any:\n    \"\"\"\n    Forward pass through the model.\n\n    Args:\n        input: The input data.\n\n    Returns:\n        Any: The model's output.\n    \"\"\"\n\n    # Pass `epoch` and/or `step` argument to forward if it accepts them\n    kwargs = {}\n    if hasarg(self.model.forward, Data.EPOCH):\n        kwargs[Data.EPOCH] = self.current_epoch\n    if hasarg(self.model.forward, Data.STEP):\n        kwargs[Data.STEP] = self.global_step\n\n    # Predict. Use inferer if available in val, test, and predict modes.\n    if self.inferer and self.mode in [Mode.VAL, Mode.TEST, Mode.PREDICT]:\n        return self.inferer(input, self.model, **kwargs)\n    return self.model(input, **kwargs)\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>lighter<ul> <li>adapters</li> <li>callbacks<ul> <li>freezer</li> <li>utils</li> <li>writer<ul> <li>base</li> <li>file</li> <li>table</li> </ul> </li> </ul> </li> <li>engine<ul> <li>runner</li> <li>schema</li> </ul> </li> <li>system</li> <li>utils<ul> <li>data</li> <li>dynamic_imports</li> <li>logging</li> <li>misc</li> <li>model</li> <li>patches</li> <li>types<ul> <li>containers</li> <li>enums</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/adapters/","title":"adapters","text":""},{"location":"reference/adapters/#lighter.adapters.BatchAdapter","title":"<code>BatchAdapter</code>","text":"Source code in <code>src/lighter/adapters.py</code> <pre><code>class BatchAdapter:\n    def __init__(\n        self,\n        input_accessor: int | str | Callable,\n        target_accessor: int | str | Callable | None = None,\n        identifier_accessor: int | str | Callable | None = None,\n    ):\n        \"\"\"\n        Initializes BatchAdapter with accessors for input, target, and identifier.\n\n        Args:\n            input_accessor: Accessor for the identifier data. Can be an index (lists/tuples), a key (dictionaries),\n                a callable (custom batch processing).\n            target_accessor: Accessor for the target data. Can be an index (for lists/tuples),\n                             a key (for dictionaries), or a callable (for custom batch processing).\n            identifier_accessor: Accessor for the identifier data. Can be an index (lists/tuples), a key (dictionaries),\n                a callable (custom batch processing), or None if no identifier is present.\n        \"\"\"\n        self.input_accessor = input_accessor\n        self.target_accessor = target_accessor\n        self.identifier_accessor = identifier_accessor\n\n    def __call__(self, batch: Any) -&gt; tuple[Any, Any, Any]:\n        \"\"\"\n        Accesses the identifier, input, and target data from the batch.\n\n        Args:\n            batch: The batch data from which to extract information.\n\n        Returns:\n            A tuple containing (identifier, input, target).\n\n        Raises:\n            ValueError: If accessors are invalid for the provided batch structure.\n        \"\"\"\n        input = self._access_value(batch, self.input_accessor)\n        target = self._access_value(batch, self.target_accessor)\n        identifier = self._access_value(batch, self.identifier_accessor)\n        return input, target, identifier\n\n    def _access_value(self, data: Any, accessor: int | str | Callable) -&gt; Any:\n        \"\"\"\n        Accesses a value from the data using the provided accessor.\n\n        Args:\n            data: The data to access the value from.\n            accessor: The accessor to use. Can be an index (for lists/tuples),\n                      a key (for dictionaries), or a callable.\n\n        Returns:\n            The accessed value.\n\n        Raises:\n            ValueError: If the accessor type or data structure is invalid.\n        \"\"\"\n        if accessor is None:\n            return None\n        elif isinstance(accessor, int) and isinstance(data, (tuple, list)):\n            return data[accessor]\n        elif isinstance(accessor, str) and isinstance(data, dict):\n            return data[accessor]\n        elif callable(accessor):\n            return accessor(data)\n        else:\n            raise ValueError(f\"Invalid accessor {accessor} of type {type(accessor)} for data type {type(data)}.\")\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.BatchAdapter.__call__","title":"<code>__call__(batch)</code>","text":"<p>Accesses the identifier, input, and target data from the batch.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Any</code> <p>The batch data from which to extract information.</p> required <p>Returns:</p> Type Description <code>tuple[Any, Any, Any]</code> <p>A tuple containing (identifier, input, target).</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If accessors are invalid for the provided batch structure.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __call__(self, batch: Any) -&gt; tuple[Any, Any, Any]:\n    \"\"\"\n    Accesses the identifier, input, and target data from the batch.\n\n    Args:\n        batch: The batch data from which to extract information.\n\n    Returns:\n        A tuple containing (identifier, input, target).\n\n    Raises:\n        ValueError: If accessors are invalid for the provided batch structure.\n    \"\"\"\n    input = self._access_value(batch, self.input_accessor)\n    target = self._access_value(batch, self.target_accessor)\n    identifier = self._access_value(batch, self.identifier_accessor)\n    return input, target, identifier\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.BatchAdapter.__init__","title":"<code>__init__(input_accessor, target_accessor=None, identifier_accessor=None)</code>","text":"<p>Initializes BatchAdapter with accessors for input, target, and identifier.</p> <p>Parameters:</p> Name Type Description Default <code>input_accessor</code> <code>int | str | Callable</code> <p>Accessor for the identifier data. Can be an index (lists/tuples), a key (dictionaries), a callable (custom batch processing).</p> required <code>target_accessor</code> <code>int | str | Callable | None</code> <p>Accessor for the target data. Can be an index (for lists/tuples),              a key (for dictionaries), or a callable (for custom batch processing).</p> <code>None</code> <code>identifier_accessor</code> <code>int | str | Callable | None</code> <p>Accessor for the identifier data. Can be an index (lists/tuples), a key (dictionaries), a callable (custom batch processing), or None if no identifier is present.</p> <code>None</code> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __init__(\n    self,\n    input_accessor: int | str | Callable,\n    target_accessor: int | str | Callable | None = None,\n    identifier_accessor: int | str | Callable | None = None,\n):\n    \"\"\"\n    Initializes BatchAdapter with accessors for input, target, and identifier.\n\n    Args:\n        input_accessor: Accessor for the identifier data. Can be an index (lists/tuples), a key (dictionaries),\n            a callable (custom batch processing).\n        target_accessor: Accessor for the target data. Can be an index (for lists/tuples),\n                         a key (for dictionaries), or a callable (for custom batch processing).\n        identifier_accessor: Accessor for the identifier data. Can be an index (lists/tuples), a key (dictionaries),\n            a callable (custom batch processing), or None if no identifier is present.\n    \"\"\"\n    self.input_accessor = input_accessor\n    self.target_accessor = target_accessor\n    self.identifier_accessor = identifier_accessor\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.BatchAdapter._access_value","title":"<code>_access_value(data, accessor)</code>","text":"<p>Accesses a value from the data using the provided accessor.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to access the value from.</p> required <code>accessor</code> <code>int | str | Callable</code> <p>The accessor to use. Can be an index (for lists/tuples),       a key (for dictionaries), or a callable.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The accessed value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the accessor type or data structure is invalid.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def _access_value(self, data: Any, accessor: int | str | Callable) -&gt; Any:\n    \"\"\"\n    Accesses a value from the data using the provided accessor.\n\n    Args:\n        data: The data to access the value from.\n        accessor: The accessor to use. Can be an index (for lists/tuples),\n                  a key (for dictionaries), or a callable.\n\n    Returns:\n        The accessed value.\n\n    Raises:\n        ValueError: If the accessor type or data structure is invalid.\n    \"\"\"\n    if accessor is None:\n        return None\n    elif isinstance(accessor, int) and isinstance(data, (tuple, list)):\n        return data[accessor]\n    elif isinstance(accessor, str) and isinstance(data, dict):\n        return data[accessor]\n    elif callable(accessor):\n        return accessor(data)\n    else:\n        raise ValueError(f\"Invalid accessor {accessor} of type {type(accessor)} for data type {type(data)}.\")\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.CriterionAdapter","title":"<code>CriterionAdapter</code>","text":"<p>               Bases: <code>_ArgumentsAndTransformsAdapter</code></p> <p>This adapter processes and transforms the input, target, and prediction data, if specified, and forwards them to the specified arguments of a criterion (loss function).</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>class CriterionAdapter(_ArgumentsAndTransformsAdapter):\n    \"\"\"\n    This adapter processes and transforms the input, target, and prediction data, if specified,\n    and forwards them to the specified arguments of a criterion (loss function).\n    \"\"\"\n\n    def __call__(self, criterion: Callable, input: Any, target: Any, pred: Any) -&gt; Any:\n        \"\"\"\n        Applies transforms and adapts arguments before calling the provided metric function.\n\n        Args:\n            criterion: The criterion (loss function).\n            input: The input data to transform with `input_transforms` if specified and pass to the metric with\n                the position or argument name specified by `input_argument`.\n            target: The target data to transform with `target_transforms` if specified and pass to the metric with\n                the position or argument name specified by `target_argument`.\n            pred: The prediction data to transform with `pred_transforms` if specified and pass to the metric with\n                the position or argument name specified by `pred_argument`.\n\n        Returns:\n            The result of the metric function call.\n        \"\"\"\n        return super().__call__(criterion, input, target, pred)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.CriterionAdapter.__call__","title":"<code>__call__(criterion, input, target, pred)</code>","text":"<p>Applies transforms and adapts arguments before calling the provided metric function.</p> <p>Parameters:</p> Name Type Description Default <code>criterion</code> <code>Callable</code> <p>The criterion (loss function).</p> required <code>input</code> <code>Any</code> <p>The input data to transform with <code>input_transforms</code> if specified and pass to the metric with the position or argument name specified by <code>input_argument</code>.</p> required <code>target</code> <code>Any</code> <p>The target data to transform with <code>target_transforms</code> if specified and pass to the metric with the position or argument name specified by <code>target_argument</code>.</p> required <code>pred</code> <code>Any</code> <p>The prediction data to transform with <code>pred_transforms</code> if specified and pass to the metric with the position or argument name specified by <code>pred_argument</code>.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The result of the metric function call.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __call__(self, criterion: Callable, input: Any, target: Any, pred: Any) -&gt; Any:\n    \"\"\"\n    Applies transforms and adapts arguments before calling the provided metric function.\n\n    Args:\n        criterion: The criterion (loss function).\n        input: The input data to transform with `input_transforms` if specified and pass to the metric with\n            the position or argument name specified by `input_argument`.\n        target: The target data to transform with `target_transforms` if specified and pass to the metric with\n            the position or argument name specified by `target_argument`.\n        pred: The prediction data to transform with `pred_transforms` if specified and pass to the metric with\n            the position or argument name specified by `pred_argument`.\n\n    Returns:\n        The result of the metric function call.\n    \"\"\"\n    return super().__call__(criterion, input, target, pred)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.LoggingAdapter","title":"<code>LoggingAdapter</code>","text":"<p>               Bases: <code>_TransformsAdapter</code></p> <p>Adapter for applying logging transformations to data.</p> <p>This adapter handles the transformation of input, target, and prediction data specifically for logging purposes. It can preprocess or format the data before logging, ensuring consistency and readability in logs.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>class LoggingAdapter(_TransformsAdapter):\n    \"\"\"\n    Adapter for applying logging transformations to data.\n\n    This adapter handles the transformation of input, target, and prediction data\n    specifically for logging purposes. It can preprocess or format the data before\n    logging, ensuring consistency and readability in logs.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        input_transforms: list[Callable] | None = None,\n        target_transforms: list[Callable] | None = None,\n        pred_transforms: list[Callable] | None = None,\n    ):\n        super().__init__(input_transforms, target_transforms, pred_transforms)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.MetricsAdapter","title":"<code>MetricsAdapter</code>","text":"<p>               Bases: <code>_ArgumentsAndTransformsAdapter</code></p> <p>This adapter processes and transforms the input, target, and prediction data, if specified, and forwards them to the specified arguments of a metric.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>class MetricsAdapter(_ArgumentsAndTransformsAdapter):\n    \"\"\"\n    This adapter processes and transforms the input, target, and prediction data, if specified,\n    and forwards them to the specified arguments of a metric.\n    \"\"\"\n\n    def __call__(self, metric: Callable, input: Any, target: Any, pred: Any) -&gt; Any:\n        \"\"\"\n        Applies transforms and adapts arguments before calling the provided metric function.\n\n        Args:\n            metric: The metric.\n            input: The input data to transform with `input_transforms` if specified and pass to the metric with\n                the position or argument name specified by `input_argument`.\n            target: The target data to transform with `target_transforms` if specified and pass to the metric with\n                the position or argument name specified by `target_argument`.\n            pred: The prediction data to transform with `pred_transforms` if specified and pass to the metric with\n                the position or argument name specified by `pred_argument`.\n\n        Returns:\n            The result of the metric function call.\n        \"\"\"\n        return super().__call__(metric, input, target, pred)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters.MetricsAdapter.__call__","title":"<code>__call__(metric, input, target, pred)</code>","text":"<p>Applies transforms and adapts arguments before calling the provided metric function.</p> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>Callable</code> <p>The metric.</p> required <code>input</code> <code>Any</code> <p>The input data to transform with <code>input_transforms</code> if specified and pass to the metric with the position or argument name specified by <code>input_argument</code>.</p> required <code>target</code> <code>Any</code> <p>The target data to transform with <code>target_transforms</code> if specified and pass to the metric with the position or argument name specified by <code>target_argument</code>.</p> required <code>pred</code> <code>Any</code> <p>The prediction data to transform with <code>pred_transforms</code> if specified and pass to the metric with the position or argument name specified by <code>pred_argument</code>.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The result of the metric function call.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __call__(self, metric: Callable, input: Any, target: Any, pred: Any) -&gt; Any:\n    \"\"\"\n    Applies transforms and adapts arguments before calling the provided metric function.\n\n    Args:\n        metric: The metric.\n        input: The input data to transform with `input_transforms` if specified and pass to the metric with\n            the position or argument name specified by `input_argument`.\n        target: The target data to transform with `target_transforms` if specified and pass to the metric with\n            the position or argument name specified by `target_argument`.\n        pred: The prediction data to transform with `pred_transforms` if specified and pass to the metric with\n            the position or argument name specified by `pred_argument`.\n\n    Returns:\n        The result of the metric function call.\n    \"\"\"\n    return super().__call__(metric, input, target, pred)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._ArgumentsAdapter","title":"<code>_ArgumentsAdapter</code>","text":"<p>Base adapter for adapting arguments to a function based on specified argument names or positions.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>class _ArgumentsAdapter:\n    \"\"\"\n    Base adapter for adapting arguments to a function based on specified argument names or positions.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_argument: int | str | None = None,\n        target_argument: int | str | None = None,\n        pred_argument: int | str | None = None,\n    ):\n        # Ensure that the positionals are consecutive integers.\n        # There cannot be positional 0 and 2, without 1. Same with a positional 1 without 0.\n        positionals = sorted(arg for arg in (input_argument, target_argument, pred_argument) if isinstance(arg, int))\n        if positionals != list(range(len(positionals))):\n            raise ValueError(\"Positional arguments must be consecutive integers starting from 0.\")\n\n        self.input_argument = input_argument\n        self.target_argument = target_argument\n        self.pred_argument = pred_argument\n\n    def __call__(self, input: Any, target: Any, pred: Any) -&gt; tuple[list[Any], dict[str, Any]]:\n        \"\"\"\n        Adapts the input, target, and prediction data to the specified argument positions or names.\n\n        Args:\n            input: The input data to be adapted.\n            target: The target data to be adapted.\n            pred: The prediction data to be adapted.\n\n        Returns:\n            A tuple containing a list of positional arguments and a dictionary of keyword arguments.\n        \"\"\"\n        args = []  # List to store positional arguments\n        kwargs = {}  # Dictionary to store keyword arguments\n\n        # Mapping of argument names to their respective values\n        argument_map = {\"input_argument\": input, \"target_argument\": target, \"pred_argument\": pred}\n\n        # Iterate over the argument map to adapt arguments\n        for arg_name, value in argument_map.items():\n            # Get the position or name of the argument from the instance attributes\n            arg_position = getattr(self, arg_name)\n            if arg_position is not None:\n                if isinstance(arg_position, int):\n                    # Insert the value into the args list at the specified position\n                    args.insert(arg_position, value)\n                elif isinstance(arg_position, str):\n                    # Add the value to the kwargs dictionary with the specified name\n                    kwargs[arg_position] = value\n                else:\n                    # Raise an error if the argument type is invalid\n                    raise ValueError(f\"Invalid {arg_name} type: {type(arg_position)}\")\n\n        # Return the adapted positional and keyword arguments\n        return args, kwargs\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._ArgumentsAdapter.__call__","title":"<code>__call__(input, target, pred)</code>","text":"<p>Adapts the input, target, and prediction data to the specified argument positions or names.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data to be adapted.</p> required <code>target</code> <code>Any</code> <p>The target data to be adapted.</p> required <code>pred</code> <code>Any</code> <p>The prediction data to be adapted.</p> required <p>Returns:</p> Type Description <code>tuple[list[Any], dict[str, Any]]</code> <p>A tuple containing a list of positional arguments and a dictionary of keyword arguments.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __call__(self, input: Any, target: Any, pred: Any) -&gt; tuple[list[Any], dict[str, Any]]:\n    \"\"\"\n    Adapts the input, target, and prediction data to the specified argument positions or names.\n\n    Args:\n        input: The input data to be adapted.\n        target: The target data to be adapted.\n        pred: The prediction data to be adapted.\n\n    Returns:\n        A tuple containing a list of positional arguments and a dictionary of keyword arguments.\n    \"\"\"\n    args = []  # List to store positional arguments\n    kwargs = {}  # Dictionary to store keyword arguments\n\n    # Mapping of argument names to their respective values\n    argument_map = {\"input_argument\": input, \"target_argument\": target, \"pred_argument\": pred}\n\n    # Iterate over the argument map to adapt arguments\n    for arg_name, value in argument_map.items():\n        # Get the position or name of the argument from the instance attributes\n        arg_position = getattr(self, arg_name)\n        if arg_position is not None:\n            if isinstance(arg_position, int):\n                # Insert the value into the args list at the specified position\n                args.insert(arg_position, value)\n            elif isinstance(arg_position, str):\n                # Add the value to the kwargs dictionary with the specified name\n                kwargs[arg_position] = value\n            else:\n                # Raise an error if the argument type is invalid\n                raise ValueError(f\"Invalid {arg_name} type: {type(arg_position)}\")\n\n    # Return the adapted positional and keyword arguments\n    return args, kwargs\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._ArgumentsAndTransformsAdapter","title":"<code>_ArgumentsAndTransformsAdapter</code>","text":"<p>               Bases: <code>_ArgumentsAdapter</code>, <code>_TransformsAdapter</code></p> <p>A generic adapter for applying functions (criterion or metrics) to data.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>class _ArgumentsAndTransformsAdapter(_ArgumentsAdapter, _TransformsAdapter):\n    \"\"\"\n    A generic adapter for applying functions (criterion or metrics) to data.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_argument: int | str | None = None,\n        target_argument: int | str | None = None,\n        pred_argument: int | str | None = None,\n        input_transforms: list[Callable] | None = None,\n        target_transforms: list[Callable] | None = None,\n        pred_transforms: list[Callable] | None = None,\n    ):\n        \"\"\"\n        Initializes the Arguments and Transforms Adapter.\n\n        Args:\n            input_argument: Position or name for the input data.\n            target_argument: Position or name for the target data.\n            pred_argument: Position or name for the prediction data.\n            input_transforms: Transforms to apply to the input data.\n            target_transforms: Transforms to apply to the target data.\n            pred_transforms: Transforms to apply to the prediction data.\n\n        Raises:\n            ValueError: If transforms are provided without corresponding argument specifications.\n        \"\"\"\n        # Validate transform arguments\n        if input_argument is None and input_transforms is not None:\n            raise ValueError(\"Input transforms provided but input_argument is None\")\n        if target_argument is None and target_transforms is not None:\n            raise ValueError(\"Target transforms provided but target_argument is None\")\n        if pred_argument is None and pred_transforms is not None:\n            raise ValueError(\"Pred transforms provided but pred_argument is None\")\n\n        _ArgumentsAdapter.__init__(self, input_argument, target_argument, pred_argument)\n        _TransformsAdapter.__init__(self, input_transforms, target_transforms, pred_transforms)\n\n    def __call__(self, fn: Callable, input: Any, target: Any, pred: Any) -&gt; Any:\n        \"\"\"\n        Applies transforms and adapts arguments before calling the provided function.\n\n        Args:\n            fn: The function/method to be called (e.g., a loss function or metric).\n            input: The input data.\n            target: The target data.\n            pred: The prediction data.\n\n        Returns:\n            The result of the function call.\n        \"\"\"\n        # Apply the transforms to the input, target, and prediction data\n        input, target, pred = _TransformsAdapter.__call__(self, input, target, pred)\n        # Map the input, target, and prediction data to the function arguments\n        args, kwargs = _ArgumentsAdapter.__call__(self, input, target, pred)\n        # Call the provided function with the adapted arguments\n        return fn(*args, **kwargs)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._ArgumentsAndTransformsAdapter.__call__","title":"<code>__call__(fn, input, target, pred)</code>","text":"<p>Applies transforms and adapts arguments before calling the provided function.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>The function/method to be called (e.g., a loss function or metric).</p> required <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The prediction data.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The result of the function call.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __call__(self, fn: Callable, input: Any, target: Any, pred: Any) -&gt; Any:\n    \"\"\"\n    Applies transforms and adapts arguments before calling the provided function.\n\n    Args:\n        fn: The function/method to be called (e.g., a loss function or metric).\n        input: The input data.\n        target: The target data.\n        pred: The prediction data.\n\n    Returns:\n        The result of the function call.\n    \"\"\"\n    # Apply the transforms to the input, target, and prediction data\n    input, target, pred = _TransformsAdapter.__call__(self, input, target, pred)\n    # Map the input, target, and prediction data to the function arguments\n    args, kwargs = _ArgumentsAdapter.__call__(self, input, target, pred)\n    # Call the provided function with the adapted arguments\n    return fn(*args, **kwargs)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._ArgumentsAndTransformsAdapter.__init__","title":"<code>__init__(input_argument=None, target_argument=None, pred_argument=None, input_transforms=None, target_transforms=None, pred_transforms=None)</code>","text":"<p>Initializes the Arguments and Transforms Adapter.</p> <p>Parameters:</p> Name Type Description Default <code>input_argument</code> <code>int | str | None</code> <p>Position or name for the input data.</p> <code>None</code> <code>target_argument</code> <code>int | str | None</code> <p>Position or name for the target data.</p> <code>None</code> <code>pred_argument</code> <code>int | str | None</code> <p>Position or name for the prediction data.</p> <code>None</code> <code>input_transforms</code> <code>list[Callable] | None</code> <p>Transforms to apply to the input data.</p> <code>None</code> <code>target_transforms</code> <code>list[Callable] | None</code> <p>Transforms to apply to the target data.</p> <code>None</code> <code>pred_transforms</code> <code>list[Callable] | None</code> <p>Transforms to apply to the prediction data.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If transforms are provided without corresponding argument specifications.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __init__(\n    self,\n    input_argument: int | str | None = None,\n    target_argument: int | str | None = None,\n    pred_argument: int | str | None = None,\n    input_transforms: list[Callable] | None = None,\n    target_transforms: list[Callable] | None = None,\n    pred_transforms: list[Callable] | None = None,\n):\n    \"\"\"\n    Initializes the Arguments and Transforms Adapter.\n\n    Args:\n        input_argument: Position or name for the input data.\n        target_argument: Position or name for the target data.\n        pred_argument: Position or name for the prediction data.\n        input_transforms: Transforms to apply to the input data.\n        target_transforms: Transforms to apply to the target data.\n        pred_transforms: Transforms to apply to the prediction data.\n\n    Raises:\n        ValueError: If transforms are provided without corresponding argument specifications.\n    \"\"\"\n    # Validate transform arguments\n    if input_argument is None and input_transforms is not None:\n        raise ValueError(\"Input transforms provided but input_argument is None\")\n    if target_argument is None and target_transforms is not None:\n        raise ValueError(\"Target transforms provided but target_argument is None\")\n    if pred_argument is None and pred_transforms is not None:\n        raise ValueError(\"Pred transforms provided but pred_argument is None\")\n\n    _ArgumentsAdapter.__init__(self, input_argument, target_argument, pred_argument)\n    _TransformsAdapter.__init__(self, input_transforms, target_transforms, pred_transforms)\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._TransformsAdapter","title":"<code>_TransformsAdapter</code>","text":"<p>Adapter for applying transformations to data.</p> <p>Parameters:</p> Name Type Description Default <code>input_transforms</code> <code>Callable | list[Callable] | None</code> <p>A single or a list of transforms to apply to the input data.</p> <code>None</code> <code>target_transforms</code> <code>Callable | list[Callable] | None</code> <p>A single or a list of transforms to apply to the target data.</p> <code>None</code> <code>pred_transforms</code> <code>Callable | list[Callable] | None</code> <p>A single or a list of transforms to apply to the prediction data.</p> <code>None</code> Source code in <code>src/lighter/adapters.py</code> <pre><code>class _TransformsAdapter:\n    \"\"\"\n    Adapter for applying transformations to data.\n\n    Args:\n        input_transforms: A single or a list of transforms to apply to the input data.\n        target_transforms: A single or a list of transforms to apply to the target data.\n        pred_transforms: A single or a list of transforms to apply to the prediction data.\n    \"\"\"\n\n    def __init__(\n        self,\n        input_transforms: Callable | list[Callable] | None = None,\n        target_transforms: Callable | list[Callable] | None = None,\n        pred_transforms: Callable | list[Callable] | None = None,\n    ):\n        self.input_transforms = input_transforms\n        self.target_transforms = target_transforms\n        self.pred_transforms = pred_transforms\n\n    def __call__(self, input: Any, target: Any, pred: Any) -&gt; tuple[Any, Any, Any]:\n        \"\"\"\n        Applies the specified transforms to the input, target, and prediction data.\n\n        Args:\n            input: The input data.\n            target: The target data.\n            pred: The prediction data.\n\n        Returns:\n            The transformed (input, target, prediction) data.\n        \"\"\"\n        input = self._transform(input, self.input_transforms)\n        target = self._transform(target, self.target_transforms)\n        pred = self._transform(pred, self.pred_transforms)\n        return input, target, pred\n\n    def _transform(self, data: Any, transforms: Callable | list[Callable]) -&gt; Any:\n        \"\"\"\n        Applies a list of transform functions to the data.\n\n        Args:\n            data: The data to be transformed.\n            transforms: A single transform function or a list of functions.\n\n        Returns:\n            The transformed data.\n\n        Raises:\n            ValueError: If any transform is not callable.\n        \"\"\"\n        for transform in ensure_list(transforms):\n            if callable(transform):\n                data = transform(data)\n            else:\n                raise ValueError(f\"Invalid transform type for transform: {transform}\")\n        return data\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._TransformsAdapter.__call__","title":"<code>__call__(input, target, pred)</code>","text":"<p>Applies the specified transforms to the input, target, and prediction data.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The prediction data.</p> required <p>Returns:</p> Type Description <code>tuple[Any, Any, Any]</code> <p>The transformed (input, target, prediction) data.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def __call__(self, input: Any, target: Any, pred: Any) -&gt; tuple[Any, Any, Any]:\n    \"\"\"\n    Applies the specified transforms to the input, target, and prediction data.\n\n    Args:\n        input: The input data.\n        target: The target data.\n        pred: The prediction data.\n\n    Returns:\n        The transformed (input, target, prediction) data.\n    \"\"\"\n    input = self._transform(input, self.input_transforms)\n    target = self._transform(target, self.target_transforms)\n    pred = self._transform(pred, self.pred_transforms)\n    return input, target, pred\n</code></pre>"},{"location":"reference/adapters/#lighter.adapters._TransformsAdapter._transform","title":"<code>_transform(data, transforms)</code>","text":"<p>Applies a list of transform functions to the data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Any</code> <p>The data to be transformed.</p> required <code>transforms</code> <code>Callable | list[Callable]</code> <p>A single transform function or a list of functions.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The transformed data.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any transform is not callable.</p> Source code in <code>src/lighter/adapters.py</code> <pre><code>def _transform(self, data: Any, transforms: Callable | list[Callable]) -&gt; Any:\n    \"\"\"\n    Applies a list of transform functions to the data.\n\n    Args:\n        data: The data to be transformed.\n        transforms: A single transform function or a list of functions.\n\n    Returns:\n        The transformed data.\n\n    Raises:\n        ValueError: If any transform is not callable.\n    \"\"\"\n    for transform in ensure_list(transforms):\n        if callable(transform):\n            data = transform(data)\n        else:\n            raise ValueError(f\"Invalid transform type for transform: {transform}\")\n    return data\n</code></pre>"},{"location":"reference/system/","title":"system","text":"<p>This module defines the System class, which encapsulates the components of a deep learning system, including the model, optimizer, datasets, and more. It extends PyTorch Lightning's LightningModule.</p>"},{"location":"reference/system/#lighter.system.System","title":"<code>System</code>","text":"<p>               Bases: <code>LightningModule</code></p> <p>System encapsulates the components of a deep learning system, extending PyTorch Lightning's LightningModule.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>Model.</p> required <code>optimizer</code> <code>Optimizer | None</code> <p>Optimizer.</p> <code>None</code> <code>scheduler</code> <code>LRScheduler | None</code> <p>Learning rate scheduler.</p> <code>None</code> <code>criterion</code> <code>Callable | None</code> <p>Criterion (loss) function.</p> <code>None</code> <code>metrics</code> <code>dict[str, Metric | list[Metric] | dict[str, Metric]] | None</code> <p>Metrics for train, val, and test. Supports a single/list/dict of <code>torchmetrics</code> metrics.</p> <code>None</code> <code>dataloaders</code> <code>dict[str, DataLoader]</code> <p>Dataloaders for train, val, test, and predict.</p> required <code>adapters</code> <code>dict[str, Callable] | None</code> <p>Adapters for batch preparation, criterion argument adaptation, metrics argument adaptation, and logging data adaptation.</p> <code>None</code> <code>inferer</code> <code>Callable | None</code> <p>Inferer to use in val/test/predict modes. Custom inferers can be defined to handle inference logic.</p> <code>None</code> Source code in <code>src/lighter/system.py</code> <pre><code>class System(pl.LightningModule):\n    \"\"\"\n    System encapsulates the components of a deep learning system, extending PyTorch Lightning's LightningModule.\n\n    Args:\n        model: Model.\n        optimizer: Optimizer.\n        scheduler: Learning rate scheduler.\n        criterion: Criterion (loss) function.\n        metrics: Metrics for train, val, and test. Supports a single/list/dict of `torchmetrics` metrics.\n        dataloaders: Dataloaders for train, val, test, and predict.\n        adapters: Adapters for batch preparation, criterion argument adaptation, metrics argument adaptation, and logging data adaptation.\n        inferer: Inferer to use in val/test/predict modes. Custom inferers can be defined to handle inference logic.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        model: Module,\n        dataloaders: dict[str, DataLoader],\n        optimizer: Optimizer | None = None,\n        scheduler: LRScheduler | None = None,\n        criterion: Callable | None = None,\n        metrics: dict[str, Metric | list[Metric] | dict[str, Metric]] | None = None,\n        adapters: dict[str, Callable] | None = None,\n        inferer: Callable | None = None,\n    ) -&gt; None:\n        super().__init__()\n\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.criterion = criterion\n        self.inferer = inferer\n\n        #  Containers\n        self.dataloaders = DataLoaders(**(dataloaders or {}))\n        self.metrics = Metrics(**(metrics or {}))\n        self.adapters = Adapters(**(adapters or {}))\n\n        # Turn metrics container into a ModuleDict to register them properly.\n        self.metrics = PatchedModuleDict(asdict(self.metrics))\n\n        self.mode = None\n        self._setup_mode_hooks()\n\n    def _step(self, batch: dict, batch_idx: int) -&gt; dict[str, Any] | Any:\n        \"\"\"\n        Performs a step in the specified mode, processing the batch and calculating loss and metrics.\n\n        Args:\n            batch: The batch of data.\n            batch_idx: The index of the batch.\n        Returns:\n            dict or Any: For predict step, returns prediction only. For other steps,\n            returns dict with loss, metrics, input, target, pred, and identifier. Loss is None\n            for test step, metrics is None if unspecified.\n        \"\"\"\n        input, target, identifier = self._prepare_batch(batch)\n        pred = self.forward(input)\n\n        loss = self._calculate_loss(input, target, pred)\n        metrics = self._calculate_metrics(input, target, pred)\n\n        self._log_stats(loss, metrics, batch_idx)\n        output = self._prepare_output(identifier, input, target, pred, loss, metrics)\n        return output\n\n    def _prepare_batch(self, batch: dict) -&gt; tuple[Any, Any, Any]:\n        \"\"\"\n        Prepares the batch data.\n\n        Args:\n            batch: The input batch dictionary.\n\n        Returns:\n            tuple: A tuple containing (input, target, identifier).\n        \"\"\"\n        adapters = getattr(self.adapters, self.mode)\n        input, target, identifier = adapters.batch(batch)\n        return input, target, identifier\n\n    def forward(self, input: Any) -&gt; Any:\n        \"\"\"\n        Forward pass through the model.\n\n        Args:\n            input: The input data.\n\n        Returns:\n            Any: The model's output.\n        \"\"\"\n\n        # Pass `epoch` and/or `step` argument to forward if it accepts them\n        kwargs = {}\n        if hasarg(self.model.forward, Data.EPOCH):\n            kwargs[Data.EPOCH] = self.current_epoch\n        if hasarg(self.model.forward, Data.STEP):\n            kwargs[Data.STEP] = self.global_step\n\n        # Predict. Use inferer if available in val, test, and predict modes.\n        if self.inferer and self.mode in [Mode.VAL, Mode.TEST, Mode.PREDICT]:\n            return self.inferer(input, self.model, **kwargs)\n        return self.model(input, **kwargs)\n\n    def _calculate_loss(self, input: Any, target: Any, pred: Any) -&gt; Tensor | dict[str, Tensor] | None:\n        \"\"\"\n        Calculates the loss using the criterion if in train or validation mode.\n\n        Args:\n            input: The input data.\n            target: The target data.\n            pred: The model predictions.\n\n        Returns:\n            The calculated loss or None if not in train/val mode.\n\n        Raises:\n            ValueError: If criterion is not specified in train/val mode or if loss dict is missing 'total' key.\n        \"\"\"\n        loss = None\n        if self.mode in [Mode.TRAIN, Mode.VAL]:\n            if self.criterion is None:\n                raise ValueError(\"Please specify 'system.criterion' in the config.\")\n\n            adapters = getattr(self.adapters, self.mode)\n            loss = adapters.criterion(self.criterion, input, target, pred)\n\n            if isinstance(loss, dict) and \"total\" not in loss:\n                raise ValueError(\n                    \"The loss dictionary must include a 'total' key that combines all sublosses. \"\n                    \"Example: {'total': combined_loss, 'subloss1': loss1, ...}\"\n                )\n        return loss\n\n    def _calculate_metrics(self, input: Any, target: Any, pred: Any) -&gt; Any | None:\n        \"\"\"\n        Calculates the metrics if not in predict mode.\n\n        Args:\n            input: The input data.\n            target: The target data.\n            pred: The model predictions.\n\n        Returns:\n            The calculated metrics or None if in predict mode or no metrics specified.\n        \"\"\"\n        if self.mode == Mode.PREDICT or self.metrics[self.mode] is None:\n            return None\n\n        adapters = getattr(self.adapters, self.mode)\n        metrics = adapters.metrics(self.metrics[self.mode], input, target, pred)\n        return metrics\n\n    def _log_stats(self, loss: Tensor | dict[str, Tensor], metrics: MetricCollection, batch_idx: int) -&gt; None:\n        \"\"\"\n        Logs the loss, metrics, and optimizer statistics.\n\n        Args:\n            loss: The calculated loss.\n            metrics: The calculated metrics.\n            batch_idx: The index of the batch.\n        \"\"\"\n        if self.trainer.logger is None:\n            return\n\n        # Loss\n        if loss is not None:\n            if not isinstance(loss, dict):\n                self._log(f\"{self.mode}/{Data.LOSS}/{Data.STEP}\", loss, on_step=True)\n                self._log(f\"{self.mode}/{Data.LOSS}/{Data.EPOCH}\", loss, on_epoch=True)\n            else:\n                for name, subloss in loss.items():\n                    self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.STEP}\", subloss, on_step=True)\n                    self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.EPOCH}\", subloss, on_epoch=True)\n\n        # Metrics\n        if metrics is not None:\n            for name, metric in metrics.items():\n                self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.STEP}\", metric, on_step=True)\n                self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.EPOCH}\", metric, on_epoch=True)\n\n        # Optimizer's lr, momentum, beta. Logged in train mode and once per epoch.\n        if self.mode == Mode.TRAIN and batch_idx == 0:\n            for name, optimizer_stat in get_optimizer_stats(self.optimizer).items():\n                self._log(f\"{self.mode}/{name}\", optimizer_stat, on_epoch=True)\n\n    def _log(self, name: str, value: Any, on_step: bool = False, on_epoch: bool = False) -&gt; None:\n        \"\"\"Log a key, value pair. Syncs across distributed nodes if `on_epoch` is True.\n\n        Args:\n            name (str): key to log.\n            value (Any): value to log.\n            on_step (bool, optional): if True, logs on step.\n            on_epoch (bool, optional): if True, logs on epoch with sync_dist=True.\n        \"\"\"\n        batch_size = getattr(self.dataloaders, self.mode).batch_size\n        self.log(name, value, logger=True, batch_size=batch_size, on_step=on_step, on_epoch=on_epoch, sync_dist=on_epoch)\n\n    def _prepare_output(\n        self,\n        identifier: Any,\n        input: Any,\n        target: Any,\n        pred: Any,\n        loss: Tensor | dict[str, Tensor] | None,\n        metrics: Any | None,\n    ) -&gt; dict[str, Any]:\n        \"\"\"\n        Prepares the data to be returned by the step function to callbacks.\n\n        Args:\n            identifier: The batch identifier.\n            input: The input data.\n            target: The target data.\n            pred: The model predictions.\n            loss: The calculated loss.\n            metrics: The calculated metrics.\n\n        Returns:\n            dict: A dictionary containing all the step information.\n        \"\"\"\n        adapters = getattr(self.adapters, self.mode)\n        input, target, pred = adapters.logging(input, target, pred)\n        return {\n            Data.IDENTIFIER: identifier,\n            Data.INPUT: input,\n            Data.TARGET: target,\n            Data.PRED: pred,\n            Data.LOSS: loss,\n            Data.METRICS: metrics,\n            Data.STEP: self.global_step,\n            Data.EPOCH: self.current_epoch,\n        }\n\n    def configure_optimizers(self) -&gt; dict[str, Optimizer | LRScheduler] | None:\n        \"\"\"\n        Configures the optimizers and learning rate schedulers.\n\n        Returns:\n            dict: A dictionary containing the optimizer and scheduler.\n\n        Raises:\n            ValueError: If optimizer is not specified.\n        \"\"\"\n        if self.optimizer is None:\n            raise ValueError(\"Please specify 'system.optimizer' in the config.\")\n        if self.scheduler is None:\n            return {\"optimizer\": self.optimizer}\n        else:\n            return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler}\n\n    def _setup_mode_hooks(self):\n        \"\"\"\n        Sets up the training, validation, testing, and prediction hooks based on defined dataloaders.\n        \"\"\"\n        if self.dataloaders.train is not None:\n            self.training_step = self._step\n            self.train_dataloader = lambda: self.dataloaders.train\n            self.on_train_start = lambda: self._on_mode_start(Mode.TRAIN)\n            self.on_train_end = self._on_mode_end\n        if self.dataloaders.val is not None:\n            self.validation_step = self._step\n            self.val_dataloader = lambda: self.dataloaders.val\n            self.on_validation_start = lambda: self._on_mode_start(Mode.VAL)\n            self.on_validation_end = self._on_mode_end\n        if self.dataloaders.test is not None:\n            self.test_step = self._step\n            self.test_dataloader = lambda: self.dataloaders.test\n            self.on_test_start = lambda: self._on_mode_start(Mode.TEST)\n            self.on_test_end = self._on_mode_end\n        if self.dataloaders.predict is not None:\n            self.predict_step = self._step\n            self.predict_dataloader = lambda: self.dataloaders.predict\n            self.on_predict_start = lambda: self._on_mode_start(Mode.PREDICT)\n            self.on_predict_end = self._on_mode_end\n\n    def _on_mode_start(self, mode: str | None) -&gt; None:\n        \"\"\"\n        Sets the current mode at the start of a phase.\n\n        Args:\n            mode: The mode to set (train, val, test, or predict).\n        \"\"\"\n        self.mode = mode\n\n    def _on_mode_end(self) -&gt; None:\n        \"\"\"\n        Resets the mode at the end of a phase.\n        \"\"\"\n        self.mode = None\n\n    @property\n    def learning_rate(self) -&gt; float:\n        \"\"\"\n        Gets the learning rate of the optimizer.\n\n        Returns:\n            float: The learning rate.\n\n        Raises:\n            ValueError: If there are multiple optimizer parameter groups.\n        \"\"\"\n        if len(self.optimizer.param_groups) &gt; 1:\n            raise ValueError(\"The learning rate is not available when there are multiple optimizer parameter groups.\")\n        return self.optimizer.param_groups[0][\"lr\"]\n\n    @learning_rate.setter\n    def learning_rate(self, value: float) -&gt; None:\n        \"\"\"\n        Sets the learning rate of the optimizer.\n\n        Args:\n            value: The new learning rate.\n\n        Raises:\n            ValueError: If there are multiple optimizer parameter groups.\n        \"\"\"\n        if len(self.optimizer.param_groups) &gt; 1:\n            raise ValueError(\"The learning rate is not available when there are multiple optimizer parameter groups.\")\n        self.optimizer.param_groups[0][\"lr\"] = value\n</code></pre>"},{"location":"reference/system/#lighter.system.System.learning_rate","title":"<code>learning_rate</code>  <code>property</code> <code>writable</code>","text":"<p>Gets the learning rate of the optimizer.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The learning rate.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are multiple optimizer parameter groups.</p>"},{"location":"reference/system/#lighter.system.System._calculate_loss","title":"<code>_calculate_loss(input, target, pred)</code>","text":"<p>Calculates the loss using the criterion if in train or validation mode.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The model predictions.</p> required <p>Returns:</p> Type Description <code>Tensor | dict[str, Tensor] | None</code> <p>The calculated loss or None if not in train/val mode.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If criterion is not specified in train/val mode or if loss dict is missing 'total' key.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _calculate_loss(self, input: Any, target: Any, pred: Any) -&gt; Tensor | dict[str, Tensor] | None:\n    \"\"\"\n    Calculates the loss using the criterion if in train or validation mode.\n\n    Args:\n        input: The input data.\n        target: The target data.\n        pred: The model predictions.\n\n    Returns:\n        The calculated loss or None if not in train/val mode.\n\n    Raises:\n        ValueError: If criterion is not specified in train/val mode or if loss dict is missing 'total' key.\n    \"\"\"\n    loss = None\n    if self.mode in [Mode.TRAIN, Mode.VAL]:\n        if self.criterion is None:\n            raise ValueError(\"Please specify 'system.criterion' in the config.\")\n\n        adapters = getattr(self.adapters, self.mode)\n        loss = adapters.criterion(self.criterion, input, target, pred)\n\n        if isinstance(loss, dict) and \"total\" not in loss:\n            raise ValueError(\n                \"The loss dictionary must include a 'total' key that combines all sublosses. \"\n                \"Example: {'total': combined_loss, 'subloss1': loss1, ...}\"\n            )\n    return loss\n</code></pre>"},{"location":"reference/system/#lighter.system.System._calculate_metrics","title":"<code>_calculate_metrics(input, target, pred)</code>","text":"<p>Calculates the metrics if not in predict mode.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The model predictions.</p> required <p>Returns:</p> Type Description <code>Any | None</code> <p>The calculated metrics or None if in predict mode or no metrics specified.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _calculate_metrics(self, input: Any, target: Any, pred: Any) -&gt; Any | None:\n    \"\"\"\n    Calculates the metrics if not in predict mode.\n\n    Args:\n        input: The input data.\n        target: The target data.\n        pred: The model predictions.\n\n    Returns:\n        The calculated metrics or None if in predict mode or no metrics specified.\n    \"\"\"\n    if self.mode == Mode.PREDICT or self.metrics[self.mode] is None:\n        return None\n\n    adapters = getattr(self.adapters, self.mode)\n    metrics = adapters.metrics(self.metrics[self.mode], input, target, pred)\n    return metrics\n</code></pre>"},{"location":"reference/system/#lighter.system.System._log","title":"<code>_log(name, value, on_step=False, on_epoch=False)</code>","text":"<p>Log a key, value pair. Syncs across distributed nodes if <code>on_epoch</code> is True.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>key to log.</p> required <code>value</code> <code>Any</code> <p>value to log.</p> required <code>on_step</code> <code>bool</code> <p>if True, logs on step.</p> <code>False</code> <code>on_epoch</code> <code>bool</code> <p>if True, logs on epoch with sync_dist=True.</p> <code>False</code> Source code in <code>src/lighter/system.py</code> <pre><code>def _log(self, name: str, value: Any, on_step: bool = False, on_epoch: bool = False) -&gt; None:\n    \"\"\"Log a key, value pair. Syncs across distributed nodes if `on_epoch` is True.\n\n    Args:\n        name (str): key to log.\n        value (Any): value to log.\n        on_step (bool, optional): if True, logs on step.\n        on_epoch (bool, optional): if True, logs on epoch with sync_dist=True.\n    \"\"\"\n    batch_size = getattr(self.dataloaders, self.mode).batch_size\n    self.log(name, value, logger=True, batch_size=batch_size, on_step=on_step, on_epoch=on_epoch, sync_dist=on_epoch)\n</code></pre>"},{"location":"reference/system/#lighter.system.System._log_stats","title":"<code>_log_stats(loss, metrics, batch_idx)</code>","text":"<p>Logs the loss, metrics, and optimizer statistics.</p> <p>Parameters:</p> Name Type Description Default <code>loss</code> <code>Tensor | dict[str, Tensor]</code> <p>The calculated loss.</p> required <code>metrics</code> <code>MetricCollection</code> <p>The calculated metrics.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the batch.</p> required Source code in <code>src/lighter/system.py</code> <pre><code>def _log_stats(self, loss: Tensor | dict[str, Tensor], metrics: MetricCollection, batch_idx: int) -&gt; None:\n    \"\"\"\n    Logs the loss, metrics, and optimizer statistics.\n\n    Args:\n        loss: The calculated loss.\n        metrics: The calculated metrics.\n        batch_idx: The index of the batch.\n    \"\"\"\n    if self.trainer.logger is None:\n        return\n\n    # Loss\n    if loss is not None:\n        if not isinstance(loss, dict):\n            self._log(f\"{self.mode}/{Data.LOSS}/{Data.STEP}\", loss, on_step=True)\n            self._log(f\"{self.mode}/{Data.LOSS}/{Data.EPOCH}\", loss, on_epoch=True)\n        else:\n            for name, subloss in loss.items():\n                self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.STEP}\", subloss, on_step=True)\n                self._log(f\"{self.mode}/{Data.LOSS}/{name}/{Data.EPOCH}\", subloss, on_epoch=True)\n\n    # Metrics\n    if metrics is not None:\n        for name, metric in metrics.items():\n            self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.STEP}\", metric, on_step=True)\n            self._log(f\"{self.mode}/{Data.METRICS}/{name}/{Data.EPOCH}\", metric, on_epoch=True)\n\n    # Optimizer's lr, momentum, beta. Logged in train mode and once per epoch.\n    if self.mode == Mode.TRAIN and batch_idx == 0:\n        for name, optimizer_stat in get_optimizer_stats(self.optimizer).items():\n            self._log(f\"{self.mode}/{name}\", optimizer_stat, on_epoch=True)\n</code></pre>"},{"location":"reference/system/#lighter.system.System._on_mode_end","title":"<code>_on_mode_end()</code>","text":"<p>Resets the mode at the end of a phase.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _on_mode_end(self) -&gt; None:\n    \"\"\"\n    Resets the mode at the end of a phase.\n    \"\"\"\n    self.mode = None\n</code></pre>"},{"location":"reference/system/#lighter.system.System._on_mode_start","title":"<code>_on_mode_start(mode)</code>","text":"<p>Sets the current mode at the start of a phase.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str | None</code> <p>The mode to set (train, val, test, or predict).</p> required Source code in <code>src/lighter/system.py</code> <pre><code>def _on_mode_start(self, mode: str | None) -&gt; None:\n    \"\"\"\n    Sets the current mode at the start of a phase.\n\n    Args:\n        mode: The mode to set (train, val, test, or predict).\n    \"\"\"\n    self.mode = mode\n</code></pre>"},{"location":"reference/system/#lighter.system.System._prepare_batch","title":"<code>_prepare_batch(batch)</code>","text":"<p>Prepares the batch data.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>dict</code> <p>The input batch dictionary.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[Any, Any, Any]</code> <p>A tuple containing (input, target, identifier).</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _prepare_batch(self, batch: dict) -&gt; tuple[Any, Any, Any]:\n    \"\"\"\n    Prepares the batch data.\n\n    Args:\n        batch: The input batch dictionary.\n\n    Returns:\n        tuple: A tuple containing (input, target, identifier).\n    \"\"\"\n    adapters = getattr(self.adapters, self.mode)\n    input, target, identifier = adapters.batch(batch)\n    return input, target, identifier\n</code></pre>"},{"location":"reference/system/#lighter.system.System._prepare_output","title":"<code>_prepare_output(identifier, input, target, pred, loss, metrics)</code>","text":"<p>Prepares the data to be returned by the step function to callbacks.</p> <p>Parameters:</p> Name Type Description Default <code>identifier</code> <code>Any</code> <p>The batch identifier.</p> required <code>input</code> <code>Any</code> <p>The input data.</p> required <code>target</code> <code>Any</code> <p>The target data.</p> required <code>pred</code> <code>Any</code> <p>The model predictions.</p> required <code>loss</code> <code>Tensor | dict[str, Tensor] | None</code> <p>The calculated loss.</p> required <code>metrics</code> <code>Any | None</code> <p>The calculated metrics.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Any]</code> <p>A dictionary containing all the step information.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _prepare_output(\n    self,\n    identifier: Any,\n    input: Any,\n    target: Any,\n    pred: Any,\n    loss: Tensor | dict[str, Tensor] | None,\n    metrics: Any | None,\n) -&gt; dict[str, Any]:\n    \"\"\"\n    Prepares the data to be returned by the step function to callbacks.\n\n    Args:\n        identifier: The batch identifier.\n        input: The input data.\n        target: The target data.\n        pred: The model predictions.\n        loss: The calculated loss.\n        metrics: The calculated metrics.\n\n    Returns:\n        dict: A dictionary containing all the step information.\n    \"\"\"\n    adapters = getattr(self.adapters, self.mode)\n    input, target, pred = adapters.logging(input, target, pred)\n    return {\n        Data.IDENTIFIER: identifier,\n        Data.INPUT: input,\n        Data.TARGET: target,\n        Data.PRED: pred,\n        Data.LOSS: loss,\n        Data.METRICS: metrics,\n        Data.STEP: self.global_step,\n        Data.EPOCH: self.current_epoch,\n    }\n</code></pre>"},{"location":"reference/system/#lighter.system.System._setup_mode_hooks","title":"<code>_setup_mode_hooks()</code>","text":"<p>Sets up the training, validation, testing, and prediction hooks based on defined dataloaders.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _setup_mode_hooks(self):\n    \"\"\"\n    Sets up the training, validation, testing, and prediction hooks based on defined dataloaders.\n    \"\"\"\n    if self.dataloaders.train is not None:\n        self.training_step = self._step\n        self.train_dataloader = lambda: self.dataloaders.train\n        self.on_train_start = lambda: self._on_mode_start(Mode.TRAIN)\n        self.on_train_end = self._on_mode_end\n    if self.dataloaders.val is not None:\n        self.validation_step = self._step\n        self.val_dataloader = lambda: self.dataloaders.val\n        self.on_validation_start = lambda: self._on_mode_start(Mode.VAL)\n        self.on_validation_end = self._on_mode_end\n    if self.dataloaders.test is not None:\n        self.test_step = self._step\n        self.test_dataloader = lambda: self.dataloaders.test\n        self.on_test_start = lambda: self._on_mode_start(Mode.TEST)\n        self.on_test_end = self._on_mode_end\n    if self.dataloaders.predict is not None:\n        self.predict_step = self._step\n        self.predict_dataloader = lambda: self.dataloaders.predict\n        self.on_predict_start = lambda: self._on_mode_start(Mode.PREDICT)\n        self.on_predict_end = self._on_mode_end\n</code></pre>"},{"location":"reference/system/#lighter.system.System._step","title":"<code>_step(batch, batch_idx)</code>","text":"<p>Performs a step in the specified mode, processing the batch and calculating loss and metrics.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>dict</code> <p>The batch of data.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the batch.</p> required <p>Returns:     dict or Any: For predict step, returns prediction only. For other steps,     returns dict with loss, metrics, input, target, pred, and identifier. Loss is None     for test step, metrics is None if unspecified.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def _step(self, batch: dict, batch_idx: int) -&gt; dict[str, Any] | Any:\n    \"\"\"\n    Performs a step in the specified mode, processing the batch and calculating loss and metrics.\n\n    Args:\n        batch: The batch of data.\n        batch_idx: The index of the batch.\n    Returns:\n        dict or Any: For predict step, returns prediction only. For other steps,\n        returns dict with loss, metrics, input, target, pred, and identifier. Loss is None\n        for test step, metrics is None if unspecified.\n    \"\"\"\n    input, target, identifier = self._prepare_batch(batch)\n    pred = self.forward(input)\n\n    loss = self._calculate_loss(input, target, pred)\n    metrics = self._calculate_metrics(input, target, pred)\n\n    self._log_stats(loss, metrics, batch_idx)\n    output = self._prepare_output(identifier, input, target, pred, loss, metrics)\n    return output\n</code></pre>"},{"location":"reference/system/#lighter.system.System.configure_optimizers","title":"<code>configure_optimizers()</code>","text":"<p>Configures the optimizers and learning rate schedulers.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, Optimizer | LRScheduler] | None</code> <p>A dictionary containing the optimizer and scheduler.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If optimizer is not specified.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def configure_optimizers(self) -&gt; dict[str, Optimizer | LRScheduler] | None:\n    \"\"\"\n    Configures the optimizers and learning rate schedulers.\n\n    Returns:\n        dict: A dictionary containing the optimizer and scheduler.\n\n    Raises:\n        ValueError: If optimizer is not specified.\n    \"\"\"\n    if self.optimizer is None:\n        raise ValueError(\"Please specify 'system.optimizer' in the config.\")\n    if self.scheduler is None:\n        return {\"optimizer\": self.optimizer}\n    else:\n        return {\"optimizer\": self.optimizer, \"lr_scheduler\": self.scheduler}\n</code></pre>"},{"location":"reference/system/#lighter.system.System.forward","title":"<code>forward(input)</code>","text":"<p>Forward pass through the model.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input data.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The model's output.</p> Source code in <code>src/lighter/system.py</code> <pre><code>def forward(self, input: Any) -&gt; Any:\n    \"\"\"\n    Forward pass through the model.\n\n    Args:\n        input: The input data.\n\n    Returns:\n        Any: The model's output.\n    \"\"\"\n\n    # Pass `epoch` and/or `step` argument to forward if it accepts them\n    kwargs = {}\n    if hasarg(self.model.forward, Data.EPOCH):\n        kwargs[Data.EPOCH] = self.current_epoch\n    if hasarg(self.model.forward, Data.STEP):\n        kwargs[Data.STEP] = self.global_step\n\n    # Predict. Use inferer if available in val, test, and predict modes.\n    if self.inferer and self.mode in [Mode.VAL, Mode.TEST, Mode.PREDICT]:\n        return self.inferer(input, self.model, **kwargs)\n    return self.model(input, **kwargs)\n</code></pre>"},{"location":"reference/callbacks/","title":"callbacks","text":"<ul> <li>utils</li> <li>freezer</li> <li>writer</li> </ul>"},{"location":"reference/callbacks/#lighter.callbacks.FileWriter","title":"<code>FileWriter</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for saving predictions to files in various formats including tensors, images, and videos. Custom writer functions can be provided to extend supported formats. Args:     path: Directory path where output files will be saved.     writer: Either a string specifying a built-in writer or a custom writer function.         Built-in writers:             - \"tensor\": Saves raw tensor data (.pt)             - \"image\": Saves as image file (.png)             - \"video\": Saves as video file (.mp4)         Custom writers must:             - Accept (path, tensor) arguments             - Handle single tensor input (no batch dimension)             - Save output to the specified path</p> Source code in <code>src/lighter/callbacks/writer/file.py</code> <pre><code>class FileWriter(BaseWriter):\n    \"\"\"\n    Writer for saving predictions to files in various formats including tensors, images, and videos.\n    Custom writer functions can be provided to extend supported formats.\n    Args:\n        path: Directory path where output files will be saved.\n        writer: Either a string specifying a built-in writer or a custom writer function.\n            Built-in writers:\n                - \"tensor\": Saves raw tensor data (.pt)\n                - \"image\": Saves as image file (.png)\n                - \"video\": Saves as video file (.mp4)\n            Custom writers must:\n                - Accept (path, tensor) arguments\n                - Handle single tensor input (no batch dimension)\n                - Save output to the specified path\n    \"\"\"\n\n    @property\n    def writers(self) -&gt; dict[str, Callable]:\n        return {\n            \"tensor\": write_tensor,\n            \"image\": write_image,\n            \"video\": write_video,\n        }\n\n    def write(self, tensor: Tensor, identifier: int | str) -&gt; None:\n        \"\"\"\n        Writes the tensor to a file using the specified writer.\n\n        Args:\n            tensor: The tensor to write.\n            identifier: Identifier for naming the file.\n        \"\"\"\n        if not self.path.is_dir():\n            raise RuntimeError(f\"FileWriter expects a directory path, got {self.path}\")\n\n        # Determine the path for the file based on prediction count. The suffix must be added by the writer function.\n        path = self.path / str(identifier)\n        # Write the tensor to the file.\n        self.writer(path, tensor)\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.FileWriter.write","title":"<code>write(tensor, identifier)</code>","text":"<p>Writes the tensor to a file using the specified writer.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>The tensor to write.</p> required <code>identifier</code> <code>int | str</code> <p>Identifier for naming the file.</p> required Source code in <code>src/lighter/callbacks/writer/file.py</code> <pre><code>def write(self, tensor: Tensor, identifier: int | str) -&gt; None:\n    \"\"\"\n    Writes the tensor to a file using the specified writer.\n\n    Args:\n        tensor: The tensor to write.\n        identifier: Identifier for naming the file.\n    \"\"\"\n    if not self.path.is_dir():\n        raise RuntimeError(f\"FileWriter expects a directory path, got {self.path}\")\n\n    # Determine the path for the file based on prediction count. The suffix must be added by the writer function.\n    path = self.path / str(identifier)\n    # Write the tensor to the file.\n    self.writer(path, tensor)\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.Freezer","title":"<code>Freezer</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to freeze model parameters during training. Parameters can be frozen by exact name or prefix. Freezing can be applied indefinitely or until a specified step/epoch.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>str | list[str] | None</code> <p>Full names of parameters to freeze.</p> <code>None</code> <code>name_starts_with</code> <code>str | list[str] | None</code> <p>Prefixes of parameter names to freeze.</p> <code>None</code> <code>except_names</code> <code>str | list[str] | None</code> <p>Names of parameters to exclude from freezing.</p> <code>None</code> <code>except_name_starts_with</code> <code>str | list[str] | None</code> <p>Prefixes of parameter names to exclude from freezing.</p> <code>None</code> <code>until_step</code> <code>int | None</code> <p>Maximum step to freeze parameters until.</p> <code>None</code> <code>until_epoch</code> <code>int | None</code> <p>Maximum epoch to freeze parameters until.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>names</code> nor <code>name_starts_with</code> are specified.</p> <code>ValueError</code> <p>If both <code>until_step</code> and <code>until_epoch</code> are specified.</p> Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>class Freezer(Callback):\n    \"\"\"\n    Callback to freeze model parameters during training. Parameters can be frozen by exact name or prefix.\n    Freezing can be applied indefinitely or until a specified step/epoch.\n\n    Args:\n        names: Full names of parameters to freeze.\n        name_starts_with: Prefixes of parameter names to freeze.\n        except_names: Names of parameters to exclude from freezing.\n        except_name_starts_with: Prefixes of parameter names to exclude from freezing.\n        until_step: Maximum step to freeze parameters until.\n        until_epoch: Maximum epoch to freeze parameters until.\n\n    Raises:\n        ValueError: If neither `names` nor `name_starts_with` are specified.\n        ValueError: If both `until_step` and `until_epoch` are specified.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        names: str | list[str] | None = None,\n        name_starts_with: str | list[str] | None = None,\n        except_names: str | list[str] | None = None,\n        except_name_starts_with: str | list[str] | None = None,\n        until_step: int | None = None,\n        until_epoch: int | None = None,\n    ) -&gt; None:\n        super().__init__()\n\n        if names is None and name_starts_with is None:\n            raise ValueError(\"At least one of `names` or `name_starts_with` must be specified.\")\n\n        if until_step is not None and until_epoch is not None:\n            raise ValueError(\"Only one of `until_step` or `until_epoch` can be specified.\")\n\n        self.names = ensure_list(names)\n        self.name_starts_with = ensure_list(name_starts_with)\n        self.except_names = ensure_list(except_names)\n        self.except_name_starts_with = ensure_list(except_name_starts_with)\n        self.until_step = until_step\n        self.until_epoch = until_epoch\n\n        self._frozen_state = False\n\n    def on_train_batch_start(self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int) -&gt; None:\n        \"\"\"\n        Called at the start of each training batch to potentially freeze parameters.\n\n        Args:\n            trainer: The trainer instance.\n            pl_module: The System instance.\n            batch: The current batch.\n            batch_idx: The index of the batch.\n        \"\"\"\n        self._on_batch_start(trainer, pl_module)\n\n    def on_validation_batch_start(\n        self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int, dataloader_idx: int = 0\n    ) -&gt; None:\n        self._on_batch_start(trainer, pl_module)\n\n    def on_test_batch_start(\n        self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int, dataloader_idx: int = 0\n    ) -&gt; None:\n        self._on_batch_start(trainer, pl_module)\n\n    def on_predict_batch_start(\n        self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int, dataloader_idx: int = 0\n    ) -&gt; None:\n        self._on_batch_start(trainer, pl_module)\n\n    def _on_batch_start(self, trainer: Trainer, pl_module: System) -&gt; None:\n        \"\"\"\n        Freezes or unfreezes model parameters based on the current step or epoch.\n\n        Args:\n            trainer: The trainer instance.\n            pl_module: The System instance.\n        \"\"\"\n        current_step = trainer.global_step\n        current_epoch = trainer.current_epoch\n\n        if self.until_step is not None and current_step &gt;= self.until_step:\n            if self._frozen_state:\n                logger.info(f\"Reached step {self.until_step} - unfreezing the previously frozen layers.\")\n                self._set_model_requires_grad(pl_module, True)\n            return\n\n        if self.until_epoch is not None and current_epoch &gt;= self.until_epoch:\n            if self._frozen_state:\n                logger.info(f\"Reached epoch {self.until_epoch} - unfreezing the previously frozen layers.\")\n                self._set_model_requires_grad(pl_module, True)\n            return\n\n        if not self._frozen_state:\n            self._set_model_requires_grad(pl_module, False)\n\n    def _set_model_requires_grad(self, model: Module | System, requires_grad: bool) -&gt; None:\n        \"\"\"\n        Sets the requires_grad attribute for model parameters, effectively freezing or unfreezing them.\n\n        Args:\n            model: The model whose parameters to modify.\n            requires_grad: Whether to allow gradients (unfreeze) or not (freeze).\n        \"\"\"\n        # If the model is a `System`, get the underlying PyTorch model.\n        if isinstance(model, System):\n            model = model.model\n\n        frozen_layers = []\n        # Freeze the specified parameters.\n        for name, param in model.named_parameters():\n            # Leave the excluded-from-freezing parameters trainable.\n            if self.except_names and name in self.except_names:\n                param.requires_grad = True\n                continue\n            if self.except_name_starts_with and any(name.startswith(prefix) for prefix in self.except_name_starts_with):\n                param.requires_grad = True\n                continue\n\n            # Freeze/unfreeze the specified parameters, based on the `requires_grad` argument.\n            if self.names and name in self.names:\n                param.requires_grad = requires_grad\n                frozen_layers.append(name)\n                continue\n            if self.name_starts_with and any(name.startswith(prefix) for prefix in self.name_starts_with):\n                param.requires_grad = requires_grad\n                frozen_layers.append(name)\n                continue\n\n            # Otherwise, leave the parameter trainable.\n            param.requires_grad = True\n\n        self._frozen_state = not requires_grad\n        # Log only when freezing the parameters.\n        if self._frozen_state:\n            logger.info(\n                f\"Setting requires_grad={requires_grad} the following layers\"\n                + (f\" until step {self.until_step}\" if self.until_step is not None else \"\")\n                + (f\" until epoch {self.until_epoch}\" if self.until_epoch is not None else \"\")\n                + f\": {frozen_layers}\"\n            )\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.Freezer._on_batch_start","title":"<code>_on_batch_start(trainer, pl_module)</code>","text":"<p>Freezes or unfreezes model parameters based on the current step or epoch.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>def _on_batch_start(self, trainer: Trainer, pl_module: System) -&gt; None:\n    \"\"\"\n    Freezes or unfreezes model parameters based on the current step or epoch.\n\n    Args:\n        trainer: The trainer instance.\n        pl_module: The System instance.\n    \"\"\"\n    current_step = trainer.global_step\n    current_epoch = trainer.current_epoch\n\n    if self.until_step is not None and current_step &gt;= self.until_step:\n        if self._frozen_state:\n            logger.info(f\"Reached step {self.until_step} - unfreezing the previously frozen layers.\")\n            self._set_model_requires_grad(pl_module, True)\n        return\n\n    if self.until_epoch is not None and current_epoch &gt;= self.until_epoch:\n        if self._frozen_state:\n            logger.info(f\"Reached epoch {self.until_epoch} - unfreezing the previously frozen layers.\")\n            self._set_model_requires_grad(pl_module, True)\n        return\n\n    if not self._frozen_state:\n        self._set_model_requires_grad(pl_module, False)\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.Freezer._set_model_requires_grad","title":"<code>_set_model_requires_grad(model, requires_grad)</code>","text":"<p>Sets the requires_grad attribute for model parameters, effectively freezing or unfreezing them.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module | System</code> <p>The model whose parameters to modify.</p> required <code>requires_grad</code> <code>bool</code> <p>Whether to allow gradients (unfreeze) or not (freeze).</p> required Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>def _set_model_requires_grad(self, model: Module | System, requires_grad: bool) -&gt; None:\n    \"\"\"\n    Sets the requires_grad attribute for model parameters, effectively freezing or unfreezing them.\n\n    Args:\n        model: The model whose parameters to modify.\n        requires_grad: Whether to allow gradients (unfreeze) or not (freeze).\n    \"\"\"\n    # If the model is a `System`, get the underlying PyTorch model.\n    if isinstance(model, System):\n        model = model.model\n\n    frozen_layers = []\n    # Freeze the specified parameters.\n    for name, param in model.named_parameters():\n        # Leave the excluded-from-freezing parameters trainable.\n        if self.except_names and name in self.except_names:\n            param.requires_grad = True\n            continue\n        if self.except_name_starts_with and any(name.startswith(prefix) for prefix in self.except_name_starts_with):\n            param.requires_grad = True\n            continue\n\n        # Freeze/unfreeze the specified parameters, based on the `requires_grad` argument.\n        if self.names and name in self.names:\n            param.requires_grad = requires_grad\n            frozen_layers.append(name)\n            continue\n        if self.name_starts_with and any(name.startswith(prefix) for prefix in self.name_starts_with):\n            param.requires_grad = requires_grad\n            frozen_layers.append(name)\n            continue\n\n        # Otherwise, leave the parameter trainable.\n        param.requires_grad = True\n\n    self._frozen_state = not requires_grad\n    # Log only when freezing the parameters.\n    if self._frozen_state:\n        logger.info(\n            f\"Setting requires_grad={requires_grad} the following layers\"\n            + (f\" until step {self.until_step}\" if self.until_step is not None else \"\")\n            + (f\" until epoch {self.until_epoch}\" if self.until_epoch is not None else \"\")\n            + f\": {frozen_layers}\"\n        )\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.Freezer.on_train_batch_start","title":"<code>on_train_batch_start(trainer, pl_module, batch, batch_idx)</code>","text":"<p>Called at the start of each training batch to potentially freeze parameters.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required <code>batch</code> <code>Any</code> <p>The current batch.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the batch.</p> required Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>def on_train_batch_start(self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int) -&gt; None:\n    \"\"\"\n    Called at the start of each training batch to potentially freeze parameters.\n\n    Args:\n        trainer: The trainer instance.\n        pl_module: The System instance.\n        batch: The current batch.\n        batch_idx: The index of the batch.\n    \"\"\"\n    self._on_batch_start(trainer, pl_module)\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.TableWriter","title":"<code>TableWriter</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for saving predictions in a table format, such as CSV.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>CSV filepath.</p> required <code>writer</code> <code>str | Callable</code> <p>Writer function or name of a registered writer.</p> required Source code in <code>src/lighter/callbacks/writer/table.py</code> <pre><code>class TableWriter(BaseWriter):\n    \"\"\"\n    Writer for saving predictions in a table format, such as CSV.\n\n    Args:\n        path: CSV filepath.\n        writer: Writer function or name of a registered writer.\n    \"\"\"\n\n    def __init__(self, path: str | Path, writer: str | Callable) -&gt; None:\n        super().__init__(path, writer)\n        self.csv_records = []\n\n    @property\n    def writers(self) -&gt; dict[str, Callable]:\n        return {\n            \"tensor\": lambda tensor: tensor.item() if tensor.numel() == 1 else tensor.tolist(),\n        }\n\n    def write(self, tensor: Any, identifier: int | str) -&gt; None:\n        \"\"\"\n        Writes the tensor as a table record using the specified writer.\n\n        Args:\n            tensor: The tensor to record. Should not have a batch dimension.\n            identifier: Identifier for the record.\n        \"\"\"\n        self.csv_records.append({\"identifier\": identifier, \"pred\": self.writer(tensor)})\n\n    def on_predict_epoch_end(self, trainer: Trainer, pl_module: System) -&gt; None:\n        \"\"\"\n        Called at the end of the prediction epoch to save predictions to a CSV file.\n\n        Args:\n            trainer: The trainer instance.\n            pl_module: The System instance.\n        \"\"\"\n        # If in distributed data parallel mode, gather records from all processes to rank 0.\n        if trainer.world_size &gt; 1:\n            gather_csv_records = [None] * trainer.world_size if trainer.is_global_zero else None\n            torch.distributed.gather_object(self.csv_records, gather_csv_records, dst=0)\n            if trainer.is_global_zero:\n                self.csv_records = list(itertools.chain(*gather_csv_records))\n\n        # Save the records to a CSV file\n        if trainer.is_global_zero:\n            df = pd.DataFrame(self.csv_records)\n            try:\n                df = df.sort_values(\"identifier\")\n            except TypeError:\n                pass\n            df = df.set_index(\"identifier\")\n            df.to_csv(self.path)\n\n        # Clear the records after saving\n        self.csv_records = []\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.TableWriter.on_predict_epoch_end","title":"<code>on_predict_epoch_end(trainer, pl_module)</code>","text":"<p>Called at the end of the prediction epoch to save predictions to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required Source code in <code>src/lighter/callbacks/writer/table.py</code> <pre><code>def on_predict_epoch_end(self, trainer: Trainer, pl_module: System) -&gt; None:\n    \"\"\"\n    Called at the end of the prediction epoch to save predictions to a CSV file.\n\n    Args:\n        trainer: The trainer instance.\n        pl_module: The System instance.\n    \"\"\"\n    # If in distributed data parallel mode, gather records from all processes to rank 0.\n    if trainer.world_size &gt; 1:\n        gather_csv_records = [None] * trainer.world_size if trainer.is_global_zero else None\n        torch.distributed.gather_object(self.csv_records, gather_csv_records, dst=0)\n        if trainer.is_global_zero:\n            self.csv_records = list(itertools.chain(*gather_csv_records))\n\n    # Save the records to a CSV file\n    if trainer.is_global_zero:\n        df = pd.DataFrame(self.csv_records)\n        try:\n            df = df.sort_values(\"identifier\")\n        except TypeError:\n            pass\n        df = df.set_index(\"identifier\")\n        df.to_csv(self.path)\n\n    # Clear the records after saving\n    self.csv_records = []\n</code></pre>"},{"location":"reference/callbacks/#lighter.callbacks.TableWriter.write","title":"<code>write(tensor, identifier)</code>","text":"<p>Writes the tensor as a table record using the specified writer.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Any</code> <p>The tensor to record. Should not have a batch dimension.</p> required <code>identifier</code> <code>int | str</code> <p>Identifier for the record.</p> required Source code in <code>src/lighter/callbacks/writer/table.py</code> <pre><code>def write(self, tensor: Any, identifier: int | str) -&gt; None:\n    \"\"\"\n    Writes the tensor as a table record using the specified writer.\n\n    Args:\n        tensor: The tensor to record. Should not have a batch dimension.\n        identifier: Identifier for the record.\n    \"\"\"\n    self.csv_records.append({\"identifier\": identifier, \"pred\": self.writer(tensor)})\n</code></pre>"},{"location":"reference/callbacks/freezer/","title":"freezer","text":"<p>This module provides the Freezer callback, which allows freezing model parameters during training.</p>"},{"location":"reference/callbacks/freezer/#lighter.callbacks.freezer.Freezer","title":"<code>Freezer</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Callback to freeze model parameters during training. Parameters can be frozen by exact name or prefix. Freezing can be applied indefinitely or until a specified step/epoch.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>str | list[str] | None</code> <p>Full names of parameters to freeze.</p> <code>None</code> <code>name_starts_with</code> <code>str | list[str] | None</code> <p>Prefixes of parameter names to freeze.</p> <code>None</code> <code>except_names</code> <code>str | list[str] | None</code> <p>Names of parameters to exclude from freezing.</p> <code>None</code> <code>except_name_starts_with</code> <code>str | list[str] | None</code> <p>Prefixes of parameter names to exclude from freezing.</p> <code>None</code> <code>until_step</code> <code>int | None</code> <p>Maximum step to freeze parameters until.</p> <code>None</code> <code>until_epoch</code> <code>int | None</code> <p>Maximum epoch to freeze parameters until.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>names</code> nor <code>name_starts_with</code> are specified.</p> <code>ValueError</code> <p>If both <code>until_step</code> and <code>until_epoch</code> are specified.</p> Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>class Freezer(Callback):\n    \"\"\"\n    Callback to freeze model parameters during training. Parameters can be frozen by exact name or prefix.\n    Freezing can be applied indefinitely or until a specified step/epoch.\n\n    Args:\n        names: Full names of parameters to freeze.\n        name_starts_with: Prefixes of parameter names to freeze.\n        except_names: Names of parameters to exclude from freezing.\n        except_name_starts_with: Prefixes of parameter names to exclude from freezing.\n        until_step: Maximum step to freeze parameters until.\n        until_epoch: Maximum epoch to freeze parameters until.\n\n    Raises:\n        ValueError: If neither `names` nor `name_starts_with` are specified.\n        ValueError: If both `until_step` and `until_epoch` are specified.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        names: str | list[str] | None = None,\n        name_starts_with: str | list[str] | None = None,\n        except_names: str | list[str] | None = None,\n        except_name_starts_with: str | list[str] | None = None,\n        until_step: int | None = None,\n        until_epoch: int | None = None,\n    ) -&gt; None:\n        super().__init__()\n\n        if names is None and name_starts_with is None:\n            raise ValueError(\"At least one of `names` or `name_starts_with` must be specified.\")\n\n        if until_step is not None and until_epoch is not None:\n            raise ValueError(\"Only one of `until_step` or `until_epoch` can be specified.\")\n\n        self.names = ensure_list(names)\n        self.name_starts_with = ensure_list(name_starts_with)\n        self.except_names = ensure_list(except_names)\n        self.except_name_starts_with = ensure_list(except_name_starts_with)\n        self.until_step = until_step\n        self.until_epoch = until_epoch\n\n        self._frozen_state = False\n\n    def on_train_batch_start(self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int) -&gt; None:\n        \"\"\"\n        Called at the start of each training batch to potentially freeze parameters.\n\n        Args:\n            trainer: The trainer instance.\n            pl_module: The System instance.\n            batch: The current batch.\n            batch_idx: The index of the batch.\n        \"\"\"\n        self._on_batch_start(trainer, pl_module)\n\n    def on_validation_batch_start(\n        self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int, dataloader_idx: int = 0\n    ) -&gt; None:\n        self._on_batch_start(trainer, pl_module)\n\n    def on_test_batch_start(\n        self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int, dataloader_idx: int = 0\n    ) -&gt; None:\n        self._on_batch_start(trainer, pl_module)\n\n    def on_predict_batch_start(\n        self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int, dataloader_idx: int = 0\n    ) -&gt; None:\n        self._on_batch_start(trainer, pl_module)\n\n    def _on_batch_start(self, trainer: Trainer, pl_module: System) -&gt; None:\n        \"\"\"\n        Freezes or unfreezes model parameters based on the current step or epoch.\n\n        Args:\n            trainer: The trainer instance.\n            pl_module: The System instance.\n        \"\"\"\n        current_step = trainer.global_step\n        current_epoch = trainer.current_epoch\n\n        if self.until_step is not None and current_step &gt;= self.until_step:\n            if self._frozen_state:\n                logger.info(f\"Reached step {self.until_step} - unfreezing the previously frozen layers.\")\n                self._set_model_requires_grad(pl_module, True)\n            return\n\n        if self.until_epoch is not None and current_epoch &gt;= self.until_epoch:\n            if self._frozen_state:\n                logger.info(f\"Reached epoch {self.until_epoch} - unfreezing the previously frozen layers.\")\n                self._set_model_requires_grad(pl_module, True)\n            return\n\n        if not self._frozen_state:\n            self._set_model_requires_grad(pl_module, False)\n\n    def _set_model_requires_grad(self, model: Module | System, requires_grad: bool) -&gt; None:\n        \"\"\"\n        Sets the requires_grad attribute for model parameters, effectively freezing or unfreezing them.\n\n        Args:\n            model: The model whose parameters to modify.\n            requires_grad: Whether to allow gradients (unfreeze) or not (freeze).\n        \"\"\"\n        # If the model is a `System`, get the underlying PyTorch model.\n        if isinstance(model, System):\n            model = model.model\n\n        frozen_layers = []\n        # Freeze the specified parameters.\n        for name, param in model.named_parameters():\n            # Leave the excluded-from-freezing parameters trainable.\n            if self.except_names and name in self.except_names:\n                param.requires_grad = True\n                continue\n            if self.except_name_starts_with and any(name.startswith(prefix) for prefix in self.except_name_starts_with):\n                param.requires_grad = True\n                continue\n\n            # Freeze/unfreeze the specified parameters, based on the `requires_grad` argument.\n            if self.names and name in self.names:\n                param.requires_grad = requires_grad\n                frozen_layers.append(name)\n                continue\n            if self.name_starts_with and any(name.startswith(prefix) for prefix in self.name_starts_with):\n                param.requires_grad = requires_grad\n                frozen_layers.append(name)\n                continue\n\n            # Otherwise, leave the parameter trainable.\n            param.requires_grad = True\n\n        self._frozen_state = not requires_grad\n        # Log only when freezing the parameters.\n        if self._frozen_state:\n            logger.info(\n                f\"Setting requires_grad={requires_grad} the following layers\"\n                + (f\" until step {self.until_step}\" if self.until_step is not None else \"\")\n                + (f\" until epoch {self.until_epoch}\" if self.until_epoch is not None else \"\")\n                + f\": {frozen_layers}\"\n            )\n</code></pre>"},{"location":"reference/callbacks/freezer/#lighter.callbacks.freezer.Freezer._on_batch_start","title":"<code>_on_batch_start(trainer, pl_module)</code>","text":"<p>Freezes or unfreezes model parameters based on the current step or epoch.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>def _on_batch_start(self, trainer: Trainer, pl_module: System) -&gt; None:\n    \"\"\"\n    Freezes or unfreezes model parameters based on the current step or epoch.\n\n    Args:\n        trainer: The trainer instance.\n        pl_module: The System instance.\n    \"\"\"\n    current_step = trainer.global_step\n    current_epoch = trainer.current_epoch\n\n    if self.until_step is not None and current_step &gt;= self.until_step:\n        if self._frozen_state:\n            logger.info(f\"Reached step {self.until_step} - unfreezing the previously frozen layers.\")\n            self._set_model_requires_grad(pl_module, True)\n        return\n\n    if self.until_epoch is not None and current_epoch &gt;= self.until_epoch:\n        if self._frozen_state:\n            logger.info(f\"Reached epoch {self.until_epoch} - unfreezing the previously frozen layers.\")\n            self._set_model_requires_grad(pl_module, True)\n        return\n\n    if not self._frozen_state:\n        self._set_model_requires_grad(pl_module, False)\n</code></pre>"},{"location":"reference/callbacks/freezer/#lighter.callbacks.freezer.Freezer._set_model_requires_grad","title":"<code>_set_model_requires_grad(model, requires_grad)</code>","text":"<p>Sets the requires_grad attribute for model parameters, effectively freezing or unfreezing them.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module | System</code> <p>The model whose parameters to modify.</p> required <code>requires_grad</code> <code>bool</code> <p>Whether to allow gradients (unfreeze) or not (freeze).</p> required Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>def _set_model_requires_grad(self, model: Module | System, requires_grad: bool) -&gt; None:\n    \"\"\"\n    Sets the requires_grad attribute for model parameters, effectively freezing or unfreezing them.\n\n    Args:\n        model: The model whose parameters to modify.\n        requires_grad: Whether to allow gradients (unfreeze) or not (freeze).\n    \"\"\"\n    # If the model is a `System`, get the underlying PyTorch model.\n    if isinstance(model, System):\n        model = model.model\n\n    frozen_layers = []\n    # Freeze the specified parameters.\n    for name, param in model.named_parameters():\n        # Leave the excluded-from-freezing parameters trainable.\n        if self.except_names and name in self.except_names:\n            param.requires_grad = True\n            continue\n        if self.except_name_starts_with and any(name.startswith(prefix) for prefix in self.except_name_starts_with):\n            param.requires_grad = True\n            continue\n\n        # Freeze/unfreeze the specified parameters, based on the `requires_grad` argument.\n        if self.names and name in self.names:\n            param.requires_grad = requires_grad\n            frozen_layers.append(name)\n            continue\n        if self.name_starts_with and any(name.startswith(prefix) for prefix in self.name_starts_with):\n            param.requires_grad = requires_grad\n            frozen_layers.append(name)\n            continue\n\n        # Otherwise, leave the parameter trainable.\n        param.requires_grad = True\n\n    self._frozen_state = not requires_grad\n    # Log only when freezing the parameters.\n    if self._frozen_state:\n        logger.info(\n            f\"Setting requires_grad={requires_grad} the following layers\"\n            + (f\" until step {self.until_step}\" if self.until_step is not None else \"\")\n            + (f\" until epoch {self.until_epoch}\" if self.until_epoch is not None else \"\")\n            + f\": {frozen_layers}\"\n        )\n</code></pre>"},{"location":"reference/callbacks/freezer/#lighter.callbacks.freezer.Freezer.on_train_batch_start","title":"<code>on_train_batch_start(trainer, pl_module, batch, batch_idx)</code>","text":"<p>Called at the start of each training batch to potentially freeze parameters.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required <code>batch</code> <code>Any</code> <p>The current batch.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the batch.</p> required Source code in <code>src/lighter/callbacks/freezer.py</code> <pre><code>def on_train_batch_start(self, trainer: Trainer, pl_module: System, batch: Any, batch_idx: int) -&gt; None:\n    \"\"\"\n    Called at the start of each training batch to potentially freeze parameters.\n\n    Args:\n        trainer: The trainer instance.\n        pl_module: The System instance.\n        batch: The current batch.\n        batch_idx: The index of the batch.\n    \"\"\"\n    self._on_batch_start(trainer, pl_module)\n</code></pre>"},{"location":"reference/callbacks/utils/","title":"utils","text":"<p>This module provides utility functions for callbacks, including mode conversion and image preprocessing.</p>"},{"location":"reference/callbacks/utils/#lighter.callbacks.utils.preprocess_image","title":"<code>preprocess_image(image)</code>","text":"<p>Preprocess image for logging. For multiple 2D images, creates a grid. For 3D images, stacks slices vertically. For multiple 3D images, creates a grid with each column showing a different 3D image stacked vertically.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Tensor</code> <p>A 2D or 3D image tensor.</p> required <p>Returns:</p> Name Type Description <code>Tensor</code> <code>Tensor</code> <p>The preprocessed image ready for logging.</p> Source code in <code>src/lighter/callbacks/utils.py</code> <pre><code>def preprocess_image(image: Tensor) -&gt; Tensor:\n    \"\"\"\n    Preprocess image for logging. For multiple 2D images, creates a grid.\n    For 3D images, stacks slices vertically. For multiple 3D images, creates a grid\n    with each column showing a different 3D image stacked vertically.\n\n    Args:\n        image: A 2D or 3D image tensor.\n\n    Returns:\n        Tensor: The preprocessed image ready for logging.\n    \"\"\"\n    # If 3D (BCDHW), concat the images vertically and horizontally.\n    if image.ndim == 5:\n        shape = image.shape\n        # BCDHW -&gt; BC(D*H)W. Combine slices of a 3D images vertically into a single 2D image.\n        image = image.view(shape[0], shape[1], shape[2] * shape[3], shape[4])\n        # BCDHW -&gt; 1CDH(B*W). Concat images in the batch horizontally, and unsqueeze to add back the B dim.\n        image = torch.cat([*image], dim=-1).unsqueeze(0)\n    # If only one image in the batch, select it and return it. Same happens when the images are 3D as they\n    # are combined into a single image. `make_grid` is called when a batch of multiple 2D image is provided.\n    return image[0] if image.shape[0] == 1 else torchvision.utils.make_grid(image, nrow=8)\n</code></pre>"},{"location":"reference/callbacks/writer/","title":"writer","text":"<ul> <li>file</li> <li>table</li> <li>base</li> </ul>"},{"location":"reference/callbacks/writer/base/","title":"base","text":"<p>This module provides the base class for defining custom writers in Lighter, allowing predictions to be saved in various formats.</p>"},{"location":"reference/callbacks/writer/base/#lighter.callbacks.writer.base.BaseWriter","title":"<code>BaseWriter</code>","text":"<p>               Bases: <code>ABC</code>, <code>Callback</code></p> <p>Base class for defining custom Writer. It provides the structure to save predictions in various formats.</p> Subclasses should implement <p>1) <code>self.writers</code> attribute to specify the supported formats and their corresponding writer functions. 2) <code>self.write()</code> method to specify the saving strategy for a prediction.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Path for saving predictions.</p> required <code>writer</code> <code>str | Callable</code> <p>Writer function or name of a registered writer.</p> required Source code in <code>src/lighter/callbacks/writer/base.py</code> <pre><code>class BaseWriter(ABC, Callback):\n    \"\"\"\n    Base class for defining custom Writer. It provides the structure to save predictions in various formats.\n\n    Subclasses should implement:\n        1) `self.writers` attribute to specify the supported formats and their corresponding writer functions.\n        2) `self.write()` method to specify the saving strategy for a prediction.\n\n    Args:\n        path (str | Path): Path for saving predictions.\n        writer (str | Callable): Writer function or name of a registered writer.\n    \"\"\"\n\n    def __init__(self, path: str | Path, writer: str | Callable) -&gt; None:\n        self.path = Path(path)\n\n        # Check if the writer is a string and if it exists in the writers dictionary\n        if isinstance(writer, str):\n            if writer not in self.writers:\n                raise ValueError(f\"Writer for format {writer} does not exist. Available writers: {self.writers.keys()}.\")\n            self.writer = self.writers[writer]\n        else:\n            # If the writer is not a string, it is assumed to be a callable function\n            self.writer = writer\n\n        # Prediction counter. Used when IDs are not provided. Initialized in `self.setup()` based on the DDP rank.\n        self._pred_counter = None\n\n    @property\n    @abstractmethod\n    def writers(self) -&gt; dict[str, Callable]:\n        \"\"\"\n        Property to define the default writer functions.\n        \"\"\"\n\n    @abstractmethod\n    def write(self, tensor: Tensor, identifier: int | str) -&gt; None:\n        \"\"\"\n        Method to define how a tensor should be saved. The input tensor will be a single tensor without\n        the batch dimension.\n\n        For each supported format, there should be a corresponding writer function registered in `self.writers`\n        A specific writer function can be retrieved using `self.get_writer(self.format)`.\n\n        Args:\n            tensor (Tensor): Tensor, without the batch dimension, to be saved.\n            identifier (int): Identifier for the tensor, can be used for naming files or adding table records.\n        \"\"\"\n\n    def setup(self, trainer: Trainer, pl_module: System, stage: str) -&gt; None:\n        \"\"\"\n        Sets up the writer, ensuring the path is ready for saving predictions.\n\n        Args:\n            trainer (Trainer): The trainer instance.\n            pl_module (System): The System instance.\n            stage (str): The current stage of training.\n        \"\"\"\n        if stage != Stage.PREDICT:\n            return\n\n        # Initialize the prediction count with the rank of the current process\n        self._pred_counter = torch.distributed.get_rank() if trainer.world_size &gt; 1 else 0\n\n        # Ensure all distributed nodes write to the same path\n        self.path = trainer.strategy.broadcast(self.path, src=0)\n        directory = self.path.parent if self.path.suffix else self.path\n\n        # Warn if the path already exists\n        if self.path.exists():\n            logger.warning(f\"{self.path} already exists, existing predictions will be overwritten.\")\n\n        if trainer.is_global_zero:\n            directory.mkdir(parents=True, exist_ok=True)\n\n        # Wait for rank 0 to create the directory\n        trainer.strategy.barrier()\n\n        # Ensure all distributed nodes have access to the path\n        if not directory.exists():\n            raise RuntimeError(\n                f\"Rank {trainer.global_rank} does not share storage with rank 0. Ensure nodes have common storage access.\"\n            )\n\n    def on_predict_batch_end(\n        self, trainer: Trainer, pl_module: System, outputs: Any, batch: Any, batch_idx: int, dataloader_idx: int = 0\n    ) -&gt; None:\n        \"\"\"\n        Callback method executed at the end of each prediction batch to write predictions with unique IDs.\n\n        Args:\n            trainer (Trainer): The trainer instance.\n            pl_module (System): The System instance.\n            outputs (Any): The outputs from the prediction step.\n            batch (Any): The current batch.\n            batch_idx (int): The index of the batch.\n            dataloader_idx (int): The index of the dataloader.\n        \"\"\"\n        # If the IDs are not provided, generate global unique IDs based on the prediction count. DDP supported.\n        if outputs[Data.IDENTIFIER] is None:\n            batch_size = len(outputs[Data.PRED])\n            world_size = trainer.world_size\n            outputs[Data.IDENTIFIER] = list(\n                range(\n                    self._pred_counter,  # Start: counted globally, initialized with the rank of the current process\n                    self._pred_counter + batch_size * world_size,  # Stop: count the total batch size across all processes\n                    world_size,  # Step: each process writes predictions for every Nth sample\n                )\n            )\n            self._pred_counter += batch_size * world_size\n\n        # Ensure equal number of predictions and identifiers\n        if len(outputs[Data.IDENTIFIER]) != len(outputs[Data.PRED]):\n            raise ValueError(\n                f\"The number of predictions ({len(outputs[Data.PRED])}) does not\"\n                f\"match the number of identifiers ({len(outputs[Data.IDENTIFIER])})\"\n            )\n\n        for pred, identifier in zip(outputs[Data.PRED], outputs[Data.IDENTIFIER], strict=True):\n            self.write(tensor=pred, identifier=identifier)\n\n        # Clear the predictions to save CPU memory. https://github.com/Lightning-AI/pytorch-lightning/issues/19398\n        trainer.predict_loop._predictions = [[] for _ in range(trainer.predict_loop.num_dataloaders)]\n        gc.collect()\n</code></pre>"},{"location":"reference/callbacks/writer/base/#lighter.callbacks.writer.base.BaseWriter.writers","title":"<code>writers</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Property to define the default writer functions.</p>"},{"location":"reference/callbacks/writer/base/#lighter.callbacks.writer.base.BaseWriter.on_predict_batch_end","title":"<code>on_predict_batch_end(trainer, pl_module, outputs, batch, batch_idx, dataloader_idx=0)</code>","text":"<p>Callback method executed at the end of each prediction batch to write predictions with unique IDs.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required <code>outputs</code> <code>Any</code> <p>The outputs from the prediction step.</p> required <code>batch</code> <code>Any</code> <p>The current batch.</p> required <code>batch_idx</code> <code>int</code> <p>The index of the batch.</p> required <code>dataloader_idx</code> <code>int</code> <p>The index of the dataloader.</p> <code>0</code> Source code in <code>src/lighter/callbacks/writer/base.py</code> <pre><code>def on_predict_batch_end(\n    self, trainer: Trainer, pl_module: System, outputs: Any, batch: Any, batch_idx: int, dataloader_idx: int = 0\n) -&gt; None:\n    \"\"\"\n    Callback method executed at the end of each prediction batch to write predictions with unique IDs.\n\n    Args:\n        trainer (Trainer): The trainer instance.\n        pl_module (System): The System instance.\n        outputs (Any): The outputs from the prediction step.\n        batch (Any): The current batch.\n        batch_idx (int): The index of the batch.\n        dataloader_idx (int): The index of the dataloader.\n    \"\"\"\n    # If the IDs are not provided, generate global unique IDs based on the prediction count. DDP supported.\n    if outputs[Data.IDENTIFIER] is None:\n        batch_size = len(outputs[Data.PRED])\n        world_size = trainer.world_size\n        outputs[Data.IDENTIFIER] = list(\n            range(\n                self._pred_counter,  # Start: counted globally, initialized with the rank of the current process\n                self._pred_counter + batch_size * world_size,  # Stop: count the total batch size across all processes\n                world_size,  # Step: each process writes predictions for every Nth sample\n            )\n        )\n        self._pred_counter += batch_size * world_size\n\n    # Ensure equal number of predictions and identifiers\n    if len(outputs[Data.IDENTIFIER]) != len(outputs[Data.PRED]):\n        raise ValueError(\n            f\"The number of predictions ({len(outputs[Data.PRED])}) does not\"\n            f\"match the number of identifiers ({len(outputs[Data.IDENTIFIER])})\"\n        )\n\n    for pred, identifier in zip(outputs[Data.PRED], outputs[Data.IDENTIFIER], strict=True):\n        self.write(tensor=pred, identifier=identifier)\n\n    # Clear the predictions to save CPU memory. https://github.com/Lightning-AI/pytorch-lightning/issues/19398\n    trainer.predict_loop._predictions = [[] for _ in range(trainer.predict_loop.num_dataloaders)]\n    gc.collect()\n</code></pre>"},{"location":"reference/callbacks/writer/base/#lighter.callbacks.writer.base.BaseWriter.setup","title":"<code>setup(trainer, pl_module, stage)</code>","text":"<p>Sets up the writer, ensuring the path is ready for saving predictions.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required <code>stage</code> <code>str</code> <p>The current stage of training.</p> required Source code in <code>src/lighter/callbacks/writer/base.py</code> <pre><code>def setup(self, trainer: Trainer, pl_module: System, stage: str) -&gt; None:\n    \"\"\"\n    Sets up the writer, ensuring the path is ready for saving predictions.\n\n    Args:\n        trainer (Trainer): The trainer instance.\n        pl_module (System): The System instance.\n        stage (str): The current stage of training.\n    \"\"\"\n    if stage != Stage.PREDICT:\n        return\n\n    # Initialize the prediction count with the rank of the current process\n    self._pred_counter = torch.distributed.get_rank() if trainer.world_size &gt; 1 else 0\n\n    # Ensure all distributed nodes write to the same path\n    self.path = trainer.strategy.broadcast(self.path, src=0)\n    directory = self.path.parent if self.path.suffix else self.path\n\n    # Warn if the path already exists\n    if self.path.exists():\n        logger.warning(f\"{self.path} already exists, existing predictions will be overwritten.\")\n\n    if trainer.is_global_zero:\n        directory.mkdir(parents=True, exist_ok=True)\n\n    # Wait for rank 0 to create the directory\n    trainer.strategy.barrier()\n\n    # Ensure all distributed nodes have access to the path\n    if not directory.exists():\n        raise RuntimeError(\n            f\"Rank {trainer.global_rank} does not share storage with rank 0. Ensure nodes have common storage access.\"\n        )\n</code></pre>"},{"location":"reference/callbacks/writer/base/#lighter.callbacks.writer.base.BaseWriter.write","title":"<code>write(tensor, identifier)</code>  <code>abstractmethod</code>","text":"<p>Method to define how a tensor should be saved. The input tensor will be a single tensor without the batch dimension.</p> <p>For each supported format, there should be a corresponding writer function registered in <code>self.writers</code> A specific writer function can be retrieved using <code>self.get_writer(self.format)</code>.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>Tensor, without the batch dimension, to be saved.</p> required <code>identifier</code> <code>int</code> <p>Identifier for the tensor, can be used for naming files or adding table records.</p> required Source code in <code>src/lighter/callbacks/writer/base.py</code> <pre><code>@abstractmethod\ndef write(self, tensor: Tensor, identifier: int | str) -&gt; None:\n    \"\"\"\n    Method to define how a tensor should be saved. The input tensor will be a single tensor without\n    the batch dimension.\n\n    For each supported format, there should be a corresponding writer function registered in `self.writers`\n    A specific writer function can be retrieved using `self.get_writer(self.format)`.\n\n    Args:\n        tensor (Tensor): Tensor, without the batch dimension, to be saved.\n        identifier (int): Identifier for the tensor, can be used for naming files or adding table records.\n    \"\"\"\n</code></pre>"},{"location":"reference/callbacks/writer/file/","title":"file","text":"<p>This module provides the FileWriter class, which writes predictions to files in various formats.</p>"},{"location":"reference/callbacks/writer/file/#lighter.callbacks.writer.file.FileWriter","title":"<code>FileWriter</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for saving predictions to files in various formats including tensors, images, and videos. Custom writer functions can be provided to extend supported formats. Args:     path: Directory path where output files will be saved.     writer: Either a string specifying a built-in writer or a custom writer function.         Built-in writers:             - \"tensor\": Saves raw tensor data (.pt)             - \"image\": Saves as image file (.png)             - \"video\": Saves as video file (.mp4)         Custom writers must:             - Accept (path, tensor) arguments             - Handle single tensor input (no batch dimension)             - Save output to the specified path</p> Source code in <code>src/lighter/callbacks/writer/file.py</code> <pre><code>class FileWriter(BaseWriter):\n    \"\"\"\n    Writer for saving predictions to files in various formats including tensors, images, and videos.\n    Custom writer functions can be provided to extend supported formats.\n    Args:\n        path: Directory path where output files will be saved.\n        writer: Either a string specifying a built-in writer or a custom writer function.\n            Built-in writers:\n                - \"tensor\": Saves raw tensor data (.pt)\n                - \"image\": Saves as image file (.png)\n                - \"video\": Saves as video file (.mp4)\n            Custom writers must:\n                - Accept (path, tensor) arguments\n                - Handle single tensor input (no batch dimension)\n                - Save output to the specified path\n    \"\"\"\n\n    @property\n    def writers(self) -&gt; dict[str, Callable]:\n        return {\n            \"tensor\": write_tensor,\n            \"image\": write_image,\n            \"video\": write_video,\n        }\n\n    def write(self, tensor: Tensor, identifier: int | str) -&gt; None:\n        \"\"\"\n        Writes the tensor to a file using the specified writer.\n\n        Args:\n            tensor: The tensor to write.\n            identifier: Identifier for naming the file.\n        \"\"\"\n        if not self.path.is_dir():\n            raise RuntimeError(f\"FileWriter expects a directory path, got {self.path}\")\n\n        # Determine the path for the file based on prediction count. The suffix must be added by the writer function.\n        path = self.path / str(identifier)\n        # Write the tensor to the file.\n        self.writer(path, tensor)\n</code></pre>"},{"location":"reference/callbacks/writer/file/#lighter.callbacks.writer.file.FileWriter.write","title":"<code>write(tensor, identifier)</code>","text":"<p>Writes the tensor to a file using the specified writer.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Tensor</code> <p>The tensor to write.</p> required <code>identifier</code> <code>int | str</code> <p>Identifier for naming the file.</p> required Source code in <code>src/lighter/callbacks/writer/file.py</code> <pre><code>def write(self, tensor: Tensor, identifier: int | str) -&gt; None:\n    \"\"\"\n    Writes the tensor to a file using the specified writer.\n\n    Args:\n        tensor: The tensor to write.\n        identifier: Identifier for naming the file.\n    \"\"\"\n    if not self.path.is_dir():\n        raise RuntimeError(f\"FileWriter expects a directory path, got {self.path}\")\n\n    # Determine the path for the file based on prediction count. The suffix must be added by the writer function.\n    path = self.path / str(identifier)\n    # Write the tensor to the file.\n    self.writer(path, tensor)\n</code></pre>"},{"location":"reference/callbacks/writer/file/#lighter.callbacks.writer.file.write_image","title":"<code>write_image(path, tensor)</code>","text":"<p>Writes a tensor as an image file in .png format.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>The path to save the image.</p> required <code>tensor</code> <p>The tensor representing the image.</p> required Source code in <code>src/lighter/callbacks/writer/file.py</code> <pre><code>def write_image(path, tensor):\n    \"\"\"\n    Writes a tensor as an image file in .png format.\n\n    Args:\n        path: The path to save the image.\n        tensor: The tensor representing the image.\n    \"\"\"\n    path = path.with_suffix(\".png\")\n    tensor = preprocess_image(tensor)\n    torchvision.io.write_png(tensor, str(path))\n</code></pre>"},{"location":"reference/callbacks/writer/file/#lighter.callbacks.writer.file.write_tensor","title":"<code>write_tensor(path, tensor)</code>","text":"<p>Writes a tensor to a file in .pt format.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>The path to save the tensor.</p> required <code>tensor</code> <p>The tensor to save.</p> required Source code in <code>src/lighter/callbacks/writer/file.py</code> <pre><code>def write_tensor(path, tensor):\n    \"\"\"\n    Writes a tensor to a file in .pt format.\n\n    Args:\n        path: The path to save the tensor.\n        tensor: The tensor to save.\n    \"\"\"\n    torch.save(tensor, path.with_suffix(\".pt\"))  # nosec B614\n</code></pre>"},{"location":"reference/callbacks/writer/file/#lighter.callbacks.writer.file.write_video","title":"<code>write_video(path, tensor)</code>","text":"<p>Writes a tensor as a video file in .mp4 format.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <p>The path to save the video.</p> required <code>tensor</code> <p>The tensor representing the video in CTHW format.</p> required Source code in <code>src/lighter/callbacks/writer/file.py</code> <pre><code>def write_video(path, tensor):\n    \"\"\"\n    Writes a tensor as a video file in .mp4 format.\n\n    Args:\n        path: The path to save the video.\n        tensor: The tensor representing the video in CTHW format.\n    \"\"\"\n    path = path.with_suffix(\".mp4\")\n    # Video tensor must be divisible by 2. Pad the height and width if needed.\n    _, _, h, w = tensor.shape\n    pad_h = (2 - h % 2) % 2\n    pad_w = (2 - w % 2) % 2\n    if pad_h &gt; 0 or pad_w &gt; 0:\n        tensor = torch.nn.functional.pad(tensor, (0, pad_w, 0, pad_h))\n    # Video tensor must be THWC. Permute CTHW -&gt; THWC.\n    tensor = tensor.permute(1, 2, 3, 0)\n    # Video tensor must have 3 channels (RGB). Repeat the channel dim to convert grayscale to RGB.\n    if tensor.shape[-1] == 1:\n        tensor = tensor.repeat(1, 1, 1, 3)\n    # Video tensor must be in the range [0, 1]. Scale to [0, 255].\n    tensor = (tensor * 255).to(torch.uint8)\n    torchvision.io.write_video(str(path), tensor, fps=24)\n</code></pre>"},{"location":"reference/callbacks/writer/table/","title":"table","text":"<p>This module provides the TableWriter class, which saves predictions in a table format, such as CSV.</p>"},{"location":"reference/callbacks/writer/table/#lighter.callbacks.writer.table.TableWriter","title":"<code>TableWriter</code>","text":"<p>               Bases: <code>BaseWriter</code></p> <p>Writer for saving predictions in a table format, such as CSV.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>CSV filepath.</p> required <code>writer</code> <code>str | Callable</code> <p>Writer function or name of a registered writer.</p> required Source code in <code>src/lighter/callbacks/writer/table.py</code> <pre><code>class TableWriter(BaseWriter):\n    \"\"\"\n    Writer for saving predictions in a table format, such as CSV.\n\n    Args:\n        path: CSV filepath.\n        writer: Writer function or name of a registered writer.\n    \"\"\"\n\n    def __init__(self, path: str | Path, writer: str | Callable) -&gt; None:\n        super().__init__(path, writer)\n        self.csv_records = []\n\n    @property\n    def writers(self) -&gt; dict[str, Callable]:\n        return {\n            \"tensor\": lambda tensor: tensor.item() if tensor.numel() == 1 else tensor.tolist(),\n        }\n\n    def write(self, tensor: Any, identifier: int | str) -&gt; None:\n        \"\"\"\n        Writes the tensor as a table record using the specified writer.\n\n        Args:\n            tensor: The tensor to record. Should not have a batch dimension.\n            identifier: Identifier for the record.\n        \"\"\"\n        self.csv_records.append({\"identifier\": identifier, \"pred\": self.writer(tensor)})\n\n    def on_predict_epoch_end(self, trainer: Trainer, pl_module: System) -&gt; None:\n        \"\"\"\n        Called at the end of the prediction epoch to save predictions to a CSV file.\n\n        Args:\n            trainer: The trainer instance.\n            pl_module: The System instance.\n        \"\"\"\n        # If in distributed data parallel mode, gather records from all processes to rank 0.\n        if trainer.world_size &gt; 1:\n            gather_csv_records = [None] * trainer.world_size if trainer.is_global_zero else None\n            torch.distributed.gather_object(self.csv_records, gather_csv_records, dst=0)\n            if trainer.is_global_zero:\n                self.csv_records = list(itertools.chain(*gather_csv_records))\n\n        # Save the records to a CSV file\n        if trainer.is_global_zero:\n            df = pd.DataFrame(self.csv_records)\n            try:\n                df = df.sort_values(\"identifier\")\n            except TypeError:\n                pass\n            df = df.set_index(\"identifier\")\n            df.to_csv(self.path)\n\n        # Clear the records after saving\n        self.csv_records = []\n</code></pre>"},{"location":"reference/callbacks/writer/table/#lighter.callbacks.writer.table.TableWriter.on_predict_epoch_end","title":"<code>on_predict_epoch_end(trainer, pl_module)</code>","text":"<p>Called at the end of the prediction epoch to save predictions to a CSV file.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>The trainer instance.</p> required <code>pl_module</code> <code>System</code> <p>The System instance.</p> required Source code in <code>src/lighter/callbacks/writer/table.py</code> <pre><code>def on_predict_epoch_end(self, trainer: Trainer, pl_module: System) -&gt; None:\n    \"\"\"\n    Called at the end of the prediction epoch to save predictions to a CSV file.\n\n    Args:\n        trainer: The trainer instance.\n        pl_module: The System instance.\n    \"\"\"\n    # If in distributed data parallel mode, gather records from all processes to rank 0.\n    if trainer.world_size &gt; 1:\n        gather_csv_records = [None] * trainer.world_size if trainer.is_global_zero else None\n        torch.distributed.gather_object(self.csv_records, gather_csv_records, dst=0)\n        if trainer.is_global_zero:\n            self.csv_records = list(itertools.chain(*gather_csv_records))\n\n    # Save the records to a CSV file\n    if trainer.is_global_zero:\n        df = pd.DataFrame(self.csv_records)\n        try:\n            df = df.sort_values(\"identifier\")\n        except TypeError:\n            pass\n        df = df.set_index(\"identifier\")\n        df.to_csv(self.path)\n\n    # Clear the records after saving\n    self.csv_records = []\n</code></pre>"},{"location":"reference/callbacks/writer/table/#lighter.callbacks.writer.table.TableWriter.write","title":"<code>write(tensor, identifier)</code>","text":"<p>Writes the tensor as a table record using the specified writer.</p> <p>Parameters:</p> Name Type Description Default <code>tensor</code> <code>Any</code> <p>The tensor to record. Should not have a batch dimension.</p> required <code>identifier</code> <code>int | str</code> <p>Identifier for the record.</p> required Source code in <code>src/lighter/callbacks/writer/table.py</code> <pre><code>def write(self, tensor: Any, identifier: int | str) -&gt; None:\n    \"\"\"\n    Writes the tensor as a table record using the specified writer.\n\n    Args:\n        tensor: The tensor to record. Should not have a batch dimension.\n        identifier: Identifier for the record.\n    \"\"\"\n    self.csv_records.append({\"identifier\": identifier, \"pred\": self.writer(tensor)})\n</code></pre>"},{"location":"reference/engine/","title":"engine","text":"<ul> <li>runner</li> <li>schema</li> </ul>"},{"location":"reference/engine/runner/","title":"runner","text":"<p>Runner module for executing training stages with configuration management. Contains the Runner class and CLI entry point.</p>"},{"location":"reference/engine/runner/#lighter.engine.runner.Runner","title":"<code>Runner</code>","text":"<p>Executes training stages using validated and resolved configurations.</p> <p>The Runner loads configurations using Sparkwheel, applies CLI overrides, validates against the schema, prunes unused components for the stage, and executes the appropriate PyTorch Lightning trainer method.</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>class Runner:\n    \"\"\"\n    Executes training stages using validated and resolved configurations.\n\n    The Runner loads configurations using Sparkwheel, applies CLI overrides,\n    validates against the schema, prunes unused components for the stage,\n    and executes the appropriate PyTorch Lightning trainer method.\n    \"\"\"\n\n    STAGE_MODES = {\n        Stage.FIT: [Mode.TRAIN, Mode.VAL],\n        Stage.VALIDATE: [Mode.VAL],\n        Stage.TEST: [Mode.TEST],\n        Stage.PREDICT: [Mode.PREDICT],\n    }\n\n    def __init__(self) -&gt; None:\n        \"\"\"Initialize the runner with empty state.\"\"\"\n        self.config: Config | None = None\n        self.system: System | None = None\n        self.trainer: Trainer | None = None\n\n    def run(\n        self,\n        stage: Stage,\n        config: str | list[str] | dict,\n        overrides: list[str] | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Run a training stage with configuration and overrides.\n\n        Args:\n            stage: Stage to run (fit, validate, test, predict)\n            config: Config file path(s) or dict. If string, supports comma-separated paths.\n            overrides: List of CLI override strings in format \"key::path=value\"\n\n        Raises:\n            ValueError: If config validation fails or required components are missing\n            TypeError: If system or trainer are not the correct type\n        \"\"\"\n        seed_everything()\n\n        # Handle comma-separated config files\n        if isinstance(config, str) and \",\" in config:\n            config = config.split(\",\")\n\n        # Load config with CLI overrides and validation (all in one step!)\n        try:\n            self.config = Config.from_cli(\n                config,\n                overrides or [],\n                schema=LighterConfig,\n            )\n        except ValidationError as e:\n            raise ValueError(f\"Configuration validation failed:\\n{e}\") from e\n\n        # Prune unused components for this stage\n        self._prune_for_stage(stage)\n\n        # Setup and run\n        self._setup(stage)\n        self._execute(stage)\n\n    def _prune_for_stage(self, stage: Stage) -&gt; None:\n        \"\"\"\n        Remove unused components using Sparkwheel's delete directive (~).\n\n        Args:\n            stage: Current stage being executed\n        \"\"\"\n        if self.config is None:\n            raise ValueError(\"Config must be loaded before pruning\")\n\n        required = set(self.STAGE_MODES[stage])\n        all_modes = {Mode.TRAIN, Mode.VAL, Mode.TEST, Mode.PREDICT}\n\n        # Build delete directives for unused modes\n        deletes = {}\n        for mode in all_modes - required:\n            deletes[f\"~system::dataloaders::{mode}\"] = None\n            deletes[f\"~system::metrics::{mode}\"] = None\n\n        # Remove optimizer/scheduler/criterion for non-training stages\n        if stage != Stage.FIT:\n            deletes[\"~system::optimizer\"] = None\n            deletes[\"~system::scheduler\"] = None\n            if stage != Stage.VALIDATE:\n                deletes[\"~system::criterion\"] = None\n\n        # Keep only args for this stage\n        for s in [Stage.FIT, Stage.VALIDATE, Stage.TEST, Stage.PREDICT]:\n            if s != stage:\n                deletes[f\"~args::{s}\"] = None\n\n        # Apply deletions\n        self.config.update(deletes)\n\n    def _setup(self, stage: Stage) -&gt; None:\n        \"\"\"\n        Setup system and trainer from configuration.\n\n        Args:\n            stage: Current stage being executed\n\n        Raises:\n            TypeError: If system or trainer are not the correct type\n        \"\"\"\n        if self.config is None:\n            raise ValueError(\"Config must be loaded before setup\")\n\n        # Import project module if specified\n        project = self.config.get(\"project\")\n        if project:\n            import_module_from_path(\"project\", project)\n\n        # Resolve system\n        self.system = self.config.resolve(\"system\")\n        if not isinstance(self.system, System):\n            raise TypeError(f\"system must be System, got {type(self.system)}\")\n\n        # Resolve trainer\n        self.trainer = self.config.resolve(\"trainer\")\n        if not isinstance(self.trainer, Trainer):\n            raise TypeError(f\"trainer must be Trainer, got {type(self.trainer)}\")\n\n        # Save config to system checkpoint and trainer logger\n        if self.system:\n            self.system.save_hyperparameters(self.config.get())\n        if self.trainer and self.trainer.logger:\n            self.trainer.logger.log_hyperparams(self.config.get())\n\n    def _execute(self, stage: Stage) -&gt; None:\n        \"\"\"\n        Execute the training stage.\n\n        Args:\n            stage: Stage to execute\n\n        Raises:\n            AttributeError: If trainer doesn't have the stage method\n        \"\"\"\n        if self.config is None or self.trainer is None or self.system is None:\n            raise ValueError(\"Config, trainer, and system must be set up before execution\")\n\n        # Get stage-specific arguments\n        args = self.config.resolve(f\"args::{stage}\", default={})\n\n        # Execute the stage method\n        stage_method = getattr(self.trainer, str(stage))\n        stage_method(self.system, **args)\n</code></pre>"},{"location":"reference/engine/runner/#lighter.engine.runner.Runner.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the runner with empty state.</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def __init__(self) -&gt; None:\n    \"\"\"Initialize the runner with empty state.\"\"\"\n    self.config: Config | None = None\n    self.system: System | None = None\n    self.trainer: Trainer | None = None\n</code></pre>"},{"location":"reference/engine/runner/#lighter.engine.runner.Runner._execute","title":"<code>_execute(stage)</code>","text":"<p>Execute the training stage.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Stage to execute</p> required <p>Raises:</p> Type Description <code>AttributeError</code> <p>If trainer doesn't have the stage method</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def _execute(self, stage: Stage) -&gt; None:\n    \"\"\"\n    Execute the training stage.\n\n    Args:\n        stage: Stage to execute\n\n    Raises:\n        AttributeError: If trainer doesn't have the stage method\n    \"\"\"\n    if self.config is None or self.trainer is None or self.system is None:\n        raise ValueError(\"Config, trainer, and system must be set up before execution\")\n\n    # Get stage-specific arguments\n    args = self.config.resolve(f\"args::{stage}\", default={})\n\n    # Execute the stage method\n    stage_method = getattr(self.trainer, str(stage))\n    stage_method(self.system, **args)\n</code></pre>"},{"location":"reference/engine/runner/#lighter.engine.runner.Runner._prune_for_stage","title":"<code>_prune_for_stage(stage)</code>","text":"<p>Remove unused components using Sparkwheel's delete directive (~).</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Current stage being executed</p> required Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def _prune_for_stage(self, stage: Stage) -&gt; None:\n    \"\"\"\n    Remove unused components using Sparkwheel's delete directive (~).\n\n    Args:\n        stage: Current stage being executed\n    \"\"\"\n    if self.config is None:\n        raise ValueError(\"Config must be loaded before pruning\")\n\n    required = set(self.STAGE_MODES[stage])\n    all_modes = {Mode.TRAIN, Mode.VAL, Mode.TEST, Mode.PREDICT}\n\n    # Build delete directives for unused modes\n    deletes = {}\n    for mode in all_modes - required:\n        deletes[f\"~system::dataloaders::{mode}\"] = None\n        deletes[f\"~system::metrics::{mode}\"] = None\n\n    # Remove optimizer/scheduler/criterion for non-training stages\n    if stage != Stage.FIT:\n        deletes[\"~system::optimizer\"] = None\n        deletes[\"~system::scheduler\"] = None\n        if stage != Stage.VALIDATE:\n            deletes[\"~system::criterion\"] = None\n\n    # Keep only args for this stage\n    for s in [Stage.FIT, Stage.VALIDATE, Stage.TEST, Stage.PREDICT]:\n        if s != stage:\n            deletes[f\"~args::{s}\"] = None\n\n    # Apply deletions\n    self.config.update(deletes)\n</code></pre>"},{"location":"reference/engine/runner/#lighter.engine.runner.Runner._setup","title":"<code>_setup(stage)</code>","text":"<p>Setup system and trainer from configuration.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Current stage being executed</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If system or trainer are not the correct type</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def _setup(self, stage: Stage) -&gt; None:\n    \"\"\"\n    Setup system and trainer from configuration.\n\n    Args:\n        stage: Current stage being executed\n\n    Raises:\n        TypeError: If system or trainer are not the correct type\n    \"\"\"\n    if self.config is None:\n        raise ValueError(\"Config must be loaded before setup\")\n\n    # Import project module if specified\n    project = self.config.get(\"project\")\n    if project:\n        import_module_from_path(\"project\", project)\n\n    # Resolve system\n    self.system = self.config.resolve(\"system\")\n    if not isinstance(self.system, System):\n        raise TypeError(f\"system must be System, got {type(self.system)}\")\n\n    # Resolve trainer\n    self.trainer = self.config.resolve(\"trainer\")\n    if not isinstance(self.trainer, Trainer):\n        raise TypeError(f\"trainer must be Trainer, got {type(self.trainer)}\")\n\n    # Save config to system checkpoint and trainer logger\n    if self.system:\n        self.system.save_hyperparameters(self.config.get())\n    if self.trainer and self.trainer.logger:\n        self.trainer.logger.log_hyperparams(self.config.get())\n</code></pre>"},{"location":"reference/engine/runner/#lighter.engine.runner.Runner.run","title":"<code>run(stage, config, overrides=None)</code>","text":"<p>Run a training stage with configuration and overrides.</p> <p>Parameters:</p> Name Type Description Default <code>stage</code> <code>Stage</code> <p>Stage to run (fit, validate, test, predict)</p> required <code>config</code> <code>str | list[str] | dict</code> <p>Config file path(s) or dict. If string, supports comma-separated paths.</p> required <code>overrides</code> <code>list[str] | None</code> <p>List of CLI override strings in format \"key::path=value\"</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If config validation fails or required components are missing</p> <code>TypeError</code> <p>If system or trainer are not the correct type</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def run(\n    self,\n    stage: Stage,\n    config: str | list[str] | dict,\n    overrides: list[str] | None = None,\n) -&gt; None:\n    \"\"\"\n    Run a training stage with configuration and overrides.\n\n    Args:\n        stage: Stage to run (fit, validate, test, predict)\n        config: Config file path(s) or dict. If string, supports comma-separated paths.\n        overrides: List of CLI override strings in format \"key::path=value\"\n\n    Raises:\n        ValueError: If config validation fails or required components are missing\n        TypeError: If system or trainer are not the correct type\n    \"\"\"\n    seed_everything()\n\n    # Handle comma-separated config files\n    if isinstance(config, str) and \",\" in config:\n        config = config.split(\",\")\n\n    # Load config with CLI overrides and validation (all in one step!)\n    try:\n        self.config = Config.from_cli(\n            config,\n            overrides or [],\n            schema=LighterConfig,\n        )\n    except ValidationError as e:\n        raise ValueError(f\"Configuration validation failed:\\n{e}\") from e\n\n    # Prune unused components for this stage\n    self._prune_for_stage(stage)\n\n    # Setup and run\n    self._setup(stage)\n    self._execute(stage)\n</code></pre>"},{"location":"reference/engine/runner/#lighter.engine.runner.cli","title":"<code>cli()</code>","text":"<p>Entry point for the lighter CLI.</p> Source code in <code>src/lighter/engine/runner.py</code> <pre><code>def cli() -&gt; None:\n    \"\"\"Entry point for the lighter CLI.\"\"\"\n    parser = argparse.ArgumentParser(\n        prog=\"lighter\",\n        description=\"Lighter: YAML-based deep learning framework\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n\n    subparsers = parser.add_subparsers(\n        dest=\"command\",\n        required=True,\n        help=\"Available commands\",\n    )\n\n    # Fit subcommand\n    fit_parser = subparsers.add_parser(\n        \"fit\",\n        help=\"Train a model\",\n        description=\"Train a model using the specified configuration file.\",\n        epilog=\"Examples:\\n\"\n        \"  lighter fit config.yaml\\n\"\n        \"  lighter fit config.yaml system::optimizer::lr=0.001\\n\"\n        \"  lighter fit base.yaml,experiment.yaml trainer::max_epochs=100\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    fit_parser.add_argument(\n        \"config\",\n        help=\"Path to config file(s), comma-separated for multiple files\",\n    )\n    fit_parser.add_argument(\n        \"overrides\",\n        nargs=\"*\",\n        default=[],\n        help='Configuration overrides in format \"key::path=value\"',\n    )\n\n    # Validate subcommand\n    validate_parser = subparsers.add_parser(\n        \"validate\",\n        help=\"Validate a model\",\n        description=\"Validate a model using the specified configuration file.\",\n        epilog=\"Examples:\\n\"\n        \"  lighter validate config.yaml\\n\"\n        \"  lighter validate config.yaml system::model::weights=checkpoint.ckpt\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    validate_parser.add_argument(\n        \"config\",\n        help=\"Path to config file(s), comma-separated for multiple files\",\n    )\n    validate_parser.add_argument(\n        \"overrides\",\n        nargs=\"*\",\n        default=[],\n        help='Configuration overrides in format \"key::path=value\"',\n    )\n\n    # Test subcommand\n    test_parser = subparsers.add_parser(\n        \"test\",\n        help=\"Test a model\",\n        description=\"Test a model using the specified configuration file.\",\n        epilog=\"Examples:\\n  lighter test config.yaml\\n  lighter test config.yaml system::model::weights=checkpoint.ckpt\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    test_parser.add_argument(\n        \"config\",\n        help=\"Path to config file(s), comma-separated for multiple files\",\n    )\n    test_parser.add_argument(\n        \"overrides\",\n        nargs=\"*\",\n        default=[],\n        help='Configuration overrides in format \"key::path=value\"',\n    )\n\n    # Predict subcommand\n    predict_parser = subparsers.add_parser(\n        \"predict\",\n        help=\"Run predictions with a model\",\n        description=\"Run predictions using the specified configuration file.\",\n        epilog=\"Examples:\\n\"\n        \"  lighter predict config.yaml\\n\"\n        \"  lighter predict config.yaml system::model::weights=checkpoint.ckpt\",\n        formatter_class=argparse.RawDescriptionHelpFormatter,\n    )\n    predict_parser.add_argument(\n        \"config\",\n        help=\"Path to config file(s), comma-separated for multiple files\",\n    )\n    predict_parser.add_argument(\n        \"overrides\",\n        nargs=\"*\",\n        default=[],\n        help='Configuration overrides in format \"key::path=value\"',\n    )\n\n    # Parse arguments\n    args = parser.parse_args()\n\n    # Execute command\n    try:\n        Runner().run(args.command, args.config, args.overrides)\n    except Exception as e:\n        # Suppress exception chain to avoid duplicate tracebacks\n        raise e from None\n</code></pre>"},{"location":"reference/engine/schema/","title":"schema","text":"<p>Defines the schema for configuration validation using Sparkwheel's validation with dataclasses.</p>"},{"location":"reference/engine/schema/#lighter.engine.schema.AdapterConfig","title":"<code>AdapterConfig</code>  <code>dataclass</code>","text":"<p>Adapter configuration for a specific mode.</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass AdapterConfig:\n    \"\"\"Adapter configuration for a specific mode.\"\"\"\n\n    batch: Optional[dict] = None\n    criterion: Optional[dict] = None\n    metrics: Optional[dict] = None\n    logging: Optional[dict] = None\n</code></pre>"},{"location":"reference/engine/schema/#lighter.engine.schema.AdaptersConfig","title":"<code>AdaptersConfig</code>  <code>dataclass</code>","text":"<p>Adapters configuration for all modes.</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass AdaptersConfig:\n    \"\"\"Adapters configuration for all modes.\"\"\"\n\n    train: Optional[dict] = None  # Can be AdapterConfig but keep flexible\n    val: Optional[dict] = None\n    test: Optional[dict] = None\n    predict: Optional[dict] = None\n</code></pre>"},{"location":"reference/engine/schema/#lighter.engine.schema.ArgsConfig","title":"<code>ArgsConfig</code>  <code>dataclass</code>","text":"<p>Arguments to pass to Trainer stage methods.</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass ArgsConfig:\n    \"\"\"Arguments to pass to Trainer stage methods.\"\"\"\n\n    fit: Optional[dict] = None\n    validate: Optional[dict] = None\n    test: Optional[dict] = None\n    predict: Optional[dict] = None\n</code></pre>"},{"location":"reference/engine/schema/#lighter.engine.schema.DataloadersConfig","title":"<code>DataloadersConfig</code>  <code>dataclass</code>","text":"<p>Dataloaders configuration for different stages.</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass DataloadersConfig:\n    \"\"\"Dataloaders configuration for different stages.\"\"\"\n\n    train: Optional[dict] = None\n    val: Optional[dict] = None\n    test: Optional[dict] = None\n    predict: Optional[dict] = None\n</code></pre>"},{"location":"reference/engine/schema/#lighter.engine.schema.LighterConfig","title":"<code>LighterConfig</code>  <code>dataclass</code>","text":"<p>Main Lighter configuration schema.</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass LighterConfig:\n    \"\"\"Main Lighter configuration schema.\"\"\"\n\n    trainer: dict  # pytorch_lightning.Trainer\n    system: SystemConfig  # lighter.System\n    project: Optional[str] = None\n    vars: Optional[dict] = None\n    args: Optional[ArgsConfig] = None\n</code></pre>"},{"location":"reference/engine/schema/#lighter.engine.schema.MetricsConfig","title":"<code>MetricsConfig</code>  <code>dataclass</code>","text":"<p>Metrics configuration for different stages.</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass MetricsConfig:\n    \"\"\"Metrics configuration for different stages.\"\"\"\n\n    train: Optional[list | dict] = None\n    val: Optional[list | dict] = None\n    test: Optional[list | dict] = None\n</code></pre>"},{"location":"reference/engine/schema/#lighter.engine.schema.PredictAdapterConfig","title":"<code>PredictAdapterConfig</code>  <code>dataclass</code>","text":"<p>Adapter configuration for predict mode (no criterion).</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass PredictAdapterConfig:\n    \"\"\"Adapter configuration for predict mode (no criterion).\"\"\"\n\n    batch: Optional[dict] = None\n    logging: Optional[dict] = None\n</code></pre>"},{"location":"reference/engine/schema/#lighter.engine.schema.SystemConfig","title":"<code>SystemConfig</code>  <code>dataclass</code>","text":"<p>System configuration with model, optimizer, scheduler, etc.</p> Source code in <code>src/lighter/engine/schema.py</code> <pre><code>@dataclass\nclass SystemConfig:\n    \"\"\"System configuration with model, optimizer, scheduler, etc.\"\"\"\n\n    model: Optional[dict] = None\n    criterion: Optional[dict] = None\n    optimizer: Optional[dict] = None\n    scheduler: Optional[dict] = None\n    inferer: Optional[dict] = None\n    metrics: Optional[MetricsConfig] = None\n    dataloaders: Optional[DataloadersConfig] = None\n    adapters: Optional[AdaptersConfig] = None\n</code></pre>"},{"location":"reference/utils/","title":"utils","text":"<ul> <li>types</li> <li>dynamic_imports</li> <li>patches</li> <li>misc</li> <li>data</li> <li>logging</li> <li>model</li> </ul>"},{"location":"reference/utils/data/","title":"data","text":""},{"location":"reference/utils/data/#lighter.utils.data.collate_replace_corrupted","title":"<code>collate_replace_corrupted(batch, dataset, default_collate_fn=None)</code>","text":"<p>Collate function to handle corrupted examples in a batch by replacing them with valid ones.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>Any</code> <p>The batch of data from the DataLoader.</p> required <code>dataset</code> <code>Dataset</code> <p>The dataset being used, which should return <code>None</code> for corrupted examples.</p> required <code>default_collate_fn</code> <code>Callable | None</code> <p>The default collate function to use once the batch is clean.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>A batch with corrupted examples replaced by valid ones.</p> Source code in <code>src/lighter/utils/data.py</code> <pre><code>def collate_replace_corrupted(\n    batch: Any, dataset: torch.utils.data.Dataset, default_collate_fn: Callable | None = None\n) -&gt; Any:\n    \"\"\"\n    Collate function to handle corrupted examples in a batch by replacing them with valid ones.\n\n    Args:\n        batch: The batch of data from the DataLoader.\n        dataset: The dataset being used, which should return `None` for corrupted examples.\n        default_collate_fn: The default collate function to use once the batch is clean.\n\n    Returns:\n        A batch with corrupted examples replaced by valid ones.\n    \"\"\"\n    # Use `torch.utils.data.dataloader.default_collate` if no other default collate function is specified.\n    default_collate_fn = default_collate_fn if default_collate_fn is not None else default_collate\n    # Idea from https://stackoverflow.com/a/57882783\n    original_batch_len = len(batch)\n    # Filter out all the Nones (corrupted examples).\n    batch = list(filter(lambda x: x is not None, batch))\n    filtered_batch_len = len(batch)\n    # Num of corrupted examples.\n    num_corrupted = original_batch_len - filtered_batch_len\n    if num_corrupted &gt; 0:\n        # Replace a corrupted example with another randomly selected example.\n        batch.extend([dataset[random.randint(0, len(dataset) - 1)] for _ in range(num_corrupted)])\n        # Recursive call to replace the replacements if they are corrupted.\n        return collate_replace_corrupted(batch, dataset)\n    # Finally, when the whole batch is fine, apply the default collate function.\n    return default_collate_fn(batch)\n</code></pre>"},{"location":"reference/utils/dynamic_imports/","title":"dynamic_imports","text":"<p>This module provides utilities for dynamic imports, allowing optional imports and importing modules from paths.</p>"},{"location":"reference/utils/dynamic_imports/#lighter.utils.dynamic_imports.OptionalImports","title":"<code>OptionalImports</code>  <code>dataclass</code>","text":"<p>Handles optional imports, allowing modules to be imported only if they are available.</p> <p>Attributes:</p> Name Type Description <code>imports</code> <code>dict[str, object]</code> <p>A dictionary to store the imported modules.</p> Example <pre><code>from lighter.utils.dynamic_imports import OPTIONAL_IMPORTS\nwriter = OPTIONAL_IMPORTS[\"tensorboard\"].SummaryWriter()\n</code></pre> Source code in <code>src/lighter/utils/dynamic_imports.py</code> <pre><code>@dataclass\nclass OptionalImports:\n    \"\"\"\n    Handles optional imports, allowing modules to be imported only if they are available.\n\n    Attributes:\n        imports: A dictionary to store the imported modules.\n\n    Example:\n        ```\n        from lighter.utils.dynamic_imports import OPTIONAL_IMPORTS\n        writer = OPTIONAL_IMPORTS[\"tensorboard\"].SummaryWriter()\n        ```\n    \"\"\"\n\n    imports: dict[str, object] = field(default_factory=dict)\n\n    def __getitem__(self, module_name: str) -&gt; object:\n        \"\"\"\n        Get the imported module by name, importing it if necessary.\n\n        Args:\n            module_name: Name of the module to import.\n\n        Raises:\n            ImportError: If the module is not available.\n\n        Returns:\n            object: The imported module.\n        \"\"\"\n        \"\"\"Get the imported module by name.\n\n        Args:\n            module_name: Name of the module to import.\n\n        Raises:\n            ImportError: If the module is not available.\n\n        Returns:\n            Imported module.\n        \"\"\"\n        if module_name not in self.imports:\n            self.imports[module_name], module_available = optional_import(module_name)\n            if not module_available:\n                raise ImportError(f\"'{module_name}' is not available. Make sure that it is installed and spelled correctly.\")\n        return self.imports[module_name]\n</code></pre>"},{"location":"reference/utils/dynamic_imports/#lighter.utils.dynamic_imports.OptionalImports.__getitem__","title":"<code>__getitem__(module_name)</code>","text":"<p>Get the imported module by name, importing it if necessary.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>Name of the module to import.</p> required <p>Raises:</p> Type Description <code>ImportError</code> <p>If the module is not available.</p> <p>Returns:</p> Name Type Description <code>object</code> <code>object</code> <p>The imported module.</p> Source code in <code>src/lighter/utils/dynamic_imports.py</code> <pre><code>def __getitem__(self, module_name: str) -&gt; object:\n    \"\"\"\n    Get the imported module by name, importing it if necessary.\n\n    Args:\n        module_name: Name of the module to import.\n\n    Raises:\n        ImportError: If the module is not available.\n\n    Returns:\n        object: The imported module.\n    \"\"\"\n    \"\"\"Get the imported module by name.\n\n    Args:\n        module_name: Name of the module to import.\n\n    Raises:\n        ImportError: If the module is not available.\n\n    Returns:\n        Imported module.\n    \"\"\"\n    if module_name not in self.imports:\n        self.imports[module_name], module_available = optional_import(module_name)\n        if not module_available:\n            raise ImportError(f\"'{module_name}' is not available. Make sure that it is installed and spelled correctly.\")\n    return self.imports[module_name]\n</code></pre>"},{"location":"reference/utils/dynamic_imports/#lighter.utils.dynamic_imports.import_module_from_path","title":"<code>import_module_from_path(module_name, module_path)</code>","text":"<p>Import a module from a given path and assign it a specified name.</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>Name to assign to the imported module.</p> required <code>module_path</code> <code>Path</code> <p>Path to the module being imported.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the module has already been imported.</p> <code>FileNotFoundError</code> <p>If the <code>__init__.py</code> file is not found in the module path.</p> Source code in <code>src/lighter/utils/dynamic_imports.py</code> <pre><code>def import_module_from_path(module_name: str, module_path: Path) -&gt; None:\n    \"\"\"\n    Import a module from a given path and assign it a specified name.\n\n    Args:\n        module_name: Name to assign to the imported module.\n        module_path: Path to the module being imported.\n\n    Raises:\n        ValueError: If the module has already been imported.\n        FileNotFoundError: If the `__init__.py` file is not found in the module path.\n    \"\"\"\n    # Based on https://stackoverflow.com/a/41595552.\n\n    if module_name in sys.modules:\n        logger.warning(f\"{module_name} has already been imported as module.\")\n        return\n\n    module_path = Path(module_path).resolve() / \"__init__.py\"\n    if not module_path.is_file():\n        raise FileNotFoundError(f\"No `__init__.py` in `{module_path}`.\")\n    spec = importlib.util.spec_from_file_location(module_name, str(module_path))\n    if spec is None:\n        raise ModuleNotFoundError(f\"Could not find module '{module_name}' at '{module_path}'.\")\n    module = importlib.util.module_from_spec(spec)\n    spec.loader.exec_module(module)\n    sys.modules[module_name] = module\n    logger.info(f\"Imported {module_path.parent} as module '{module_name}'.\")\n</code></pre>"},{"location":"reference/utils/dynamic_imports/#lighter.utils.dynamic_imports.optional_import","title":"<code>optional_import(module_name)</code>","text":"<p>Import a module optionally, returning a tuple of (module, is_available).</p> <p>Parameters:</p> Name Type Description Default <code>module_name</code> <code>str</code> <p>Name of the module to import.</p> required <p>Returns:</p> Type Description <code>tuple[object, bool]</code> <p>Tuple of (module or None, bool indicating if import succeeded).</p> Source code in <code>src/lighter/utils/dynamic_imports.py</code> <pre><code>def optional_import(module_name: str) -&gt; tuple[object, bool]:\n    \"\"\"\n    Import a module optionally, returning a tuple of (module, is_available).\n\n    Args:\n        module_name: Name of the module to import.\n\n    Returns:\n        Tuple of (module or None, bool indicating if import succeeded).\n    \"\"\"\n    try:\n        module = importlib.import_module(module_name)\n        return module, True\n    except ImportError:\n        return None, False\n</code></pre>"},{"location":"reference/utils/logging/","title":"logging","text":"<p>Logging utilities for configuring and setting up custom logging using Loguru and Rich.</p> <p>This module provides functionality to set up visually appealing logs with custom formatting, traceback handling, and suppression of detailed logs from specified modules. It includes color mapping for different log levels and handlers to intercept and redirect logging to Loguru.</p>"},{"location":"reference/utils/logging/#lighter.utils.logging._setup_logging","title":"<code>_setup_logging()</code>","text":"<p>Configures custom logging using Loguru and Rich for visually appealing logs. Sets up traceback handling and suppression of specific modules. Must be run before importing anything else to set up the loggers correctly.</p> Source code in <code>src/lighter/utils/logging.py</code> <pre><code>def _setup_logging():\n    \"\"\"\n    Configures custom logging using Loguru and Rich for visually appealing logs.\n    Sets up traceback handling and suppression of specific modules.\n    Must be run before importing anything else to set up the loggers correctly.\n    \"\"\"\n    import inspect\n    import logging\n    import warnings\n\n    import rich.logging\n    import rich.traceback\n    from loguru import logger\n\n    def formatter(record: dict) -&gt; str:\n        \"\"\"Format log messages for better readability and clarity. Used to configure Loguru with a Rich handler.\"\"\"\n        lvl_name = record[\"level\"].name\n        lvl_color = LOGGING_COLOR_MAP.get(lvl_name, \"cyan\")\n        return (\n            \"[not bold green]{time:YYYY/MM/DD HH:mm:ss.SSS}[/not bold green]  |  {level.icon}  \"\n            f\"[{lvl_color}]{lvl_name:&lt;10}[/{lvl_color}]|  [{lvl_color}]{{message}}[/{lvl_color}]\"\n        )\n\n    class InterceptHandler(logging.Handler):\n        \"\"\"Handler to redirect other libraries' logging to Loguru. Taken from Loguru's documentation:\n        https://github.com/Delgan/loguru?tab=readme-ov-file#entirely-compatible-with-standard-logging\n        \"\"\"\n\n        def emit(self, record: logging.LogRecord) -&gt; None:\n            # Get corresponding Loguru level if it exists.\n            level: str | int\n            try:\n                level = logger.level(record.levelname).name\n            except ValueError:\n                level = record.levelno\n\n            # Find caller from where originated the logged message.\n            frame, depth = inspect.currentframe(), 0\n            while frame and (depth == 0 or frame.f_code.co_filename == logging.__file__):\n                frame = frame.f_back\n                depth += 1\n\n            logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())\n\n    # Intercept logging and redirect to Loguru. Must be called before importing other libraries to work.\n    logging.getLogger().handlers = [InterceptHandler()]\n\n    # Configure Rich traceback.\n    suppress = [importlib.import_module(name) for name in SUPPRESSED_MODULES]\n    rich.traceback.install(show_locals=False, width=127, suppress=suppress)\n    # Rich handler for Loguru. Time and level are handled by the formatter.\n    rich_handler = rich.logging.RichHandler(markup=True, show_time=False, show_level=False)\n    logger.configure(handlers=[{\"sink\": rich_handler, \"format\": formatter}])\n\n    # Capture the `warnings` standard module with Loguru\n    # https://loguru.readthedocs.io/en/stable/resources/recipes.html#capturing-standard-stdout-stderr-and-warnings\n    warnings.showwarning = lambda message, *args, **kwargs: logger.opt(depth=2).warning(message)\n</code></pre>"},{"location":"reference/utils/misc/","title":"misc","text":"<p>This module contains miscellaneous utility functions for handling lists, attributes, and function arguments.</p>"},{"location":"reference/utils/misc/#lighter.utils.misc.ensure_list","title":"<code>ensure_list(input)</code>","text":"<p>Ensures that the input is wrapped in a list. If the input is None, returns an empty list.</p> <p>Parameters:</p> Name Type Description Default <code>input</code> <code>Any</code> <p>The input to wrap in a list.</p> required <p>Returns:</p> Name Type Description <code>List</code> <code>list</code> <p>The input wrapped in a list, or an empty list if input is None.</p> Source code in <code>src/lighter/utils/misc.py</code> <pre><code>def ensure_list(input: Any) -&gt; list:\n    \"\"\"\n    Ensures that the input is wrapped in a list. If the input is None, returns an empty list.\n\n    Args:\n        input: The input to wrap in a list.\n\n    Returns:\n        List: The input wrapped in a list, or an empty list if input is None.\n    \"\"\"\n    if isinstance(input, list):\n        return input\n    if isinstance(input, tuple):\n        return list(input)\n    if input is None:\n        return []\n    return [input]\n</code></pre>"},{"location":"reference/utils/misc/#lighter.utils.misc.get_name","title":"<code>get_name(_callable, include_module_name=False)</code>","text":"<p>Retrieves the name of a callable, optionally including the module name.</p> <p>Parameters:</p> Name Type Description Default <code>_callable</code> <code>Callable</code> <p>The callable whose name to retrieve.</p> required <code>include_module_name</code> <code>bool</code> <p>Whether to include the module name in the result.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the callable, optionally prefixed with the module name.</p> Source code in <code>src/lighter/utils/misc.py</code> <pre><code>def get_name(_callable: Callable, include_module_name: bool = False) -&gt; str:\n    \"\"\"\n    Retrieves the name of a callable, optionally including the module name.\n\n    Args:\n        _callable: The callable whose name to retrieve.\n        include_module_name: Whether to include the module name in the result.\n\n    Returns:\n        str: The name of the callable, optionally prefixed with the module name.\n    \"\"\"\n    # Get the name directly from the callable's __name__ attribute\n    name = getattr(_callable, \"__name__\", type(_callable).__name__)\n\n    if include_module_name:\n        # Get the module name directly from the callable's __module__ attribute\n        module = getattr(_callable, \"__module__\", type(_callable).__module__)\n        name = f\"{module}.{name}\"\n\n    return name\n</code></pre>"},{"location":"reference/utils/misc/#lighter.utils.misc.get_optimizer_stats","title":"<code>get_optimizer_stats(optimizer)</code>","text":"<p>Extract learning rates and momentum values from a PyTorch optimizer.</p> <p>Collects learning rate and momentum/beta values from each parameter group in the optimizer and returns them in a dictionary. Keys are formatted to show the optimizer type and group number (if multiple groups exist).</p> <p>Parameters:</p> Name Type Description Default <code>optimizer</code> <code>Optimizer</code> <p>The PyTorch optimizer to extract values from.</p> required <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: dictionary containing: - Learning rates: \"optimizer/{name}/lr[/group{N}]\" - Momentum values: \"optimizer/{name}/momentum[/group{N}]\"</p> <p>Where [/group{N}] is only added for optimizers with multiple groups.</p> Source code in <code>src/lighter/utils/misc.py</code> <pre><code>def get_optimizer_stats(optimizer: Optimizer) -&gt; dict[str, float]:\n    \"\"\"\n    Extract learning rates and momentum values from a PyTorch optimizer.\n\n    Collects learning rate and momentum/beta values from each parameter group\n    in the optimizer and returns them in a dictionary. Keys are formatted to show\n    the optimizer type and group number (if multiple groups exist).\n\n    Args:\n        optimizer: The PyTorch optimizer to extract values from.\n\n    Returns:\n        dict[str, float]: dictionary containing:\n            - Learning rates: \"optimizer/{name}/lr[/group{N}]\"\n            - Momentum values: \"optimizer/{name}/momentum[/group{N}]\"\n\n            Where [/group{N}] is only added for optimizers with multiple groups.\n    \"\"\"\n    stats_dict = {}\n    for group_idx, group in enumerate(optimizer.param_groups):\n        lr_key = f\"optimizer/{optimizer.__class__.__name__}/lr\"\n        momentum_key = f\"optimizer/{optimizer.__class__.__name__}/momentum\"\n\n        # Add group index to the key if there are multiple parameter groups\n        if len(optimizer.param_groups) &gt; 1:\n            lr_key += f\"/group{group_idx + 1}\"\n            momentum_key += f\"/group{group_idx + 1}\"\n\n        # Extracting learning rate\n        stats_dict[lr_key] = group[\"lr\"]\n\n        # Extracting momentum or betas[0] if available\n        if \"momentum\" in group:\n            stats_dict[momentum_key] = group[\"momentum\"]\n        if \"betas\" in group:\n            stats_dict[momentum_key] = group[\"betas\"][0]\n\n    return stats_dict\n</code></pre>"},{"location":"reference/utils/misc/#lighter.utils.misc.hasarg","title":"<code>hasarg(fn, arg_name)</code>","text":"<p>Checks if a callable (function, method, or class) has a specific argument.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable</code> <p>The callable to inspect.</p> required <code>arg_name</code> <code>str</code> <p>The name of the argument to check for.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the argument exists, False otherwise.</p> Source code in <code>src/lighter/utils/misc.py</code> <pre><code>def hasarg(fn: Callable, arg_name: str) -&gt; bool:\n    \"\"\"\n    Checks if a callable (function, method, or class) has a specific argument.\n\n    Args:\n        fn: The callable to inspect.\n        arg_name: The name of the argument to check for.\n\n    Returns:\n        bool: True if the argument exists, False otherwise.\n    \"\"\"\n    args = inspect.signature(fn).parameters.keys()\n    return arg_name in args\n</code></pre>"},{"location":"reference/utils/misc/#lighter.utils.misc.setattr_dot_notation","title":"<code>setattr_dot_notation(obj, attr, value)</code>","text":"<p>Sets an attribute on an object using dot notation.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Callable</code> <p>The object on which to set the attribute.</p> required <code>attr</code> <code>str</code> <p>The attribute name, which can use dot notation for nested attributes.</p> required <code>value</code> <code>Any</code> <p>The value to set the attribute to.</p> required Source code in <code>src/lighter/utils/misc.py</code> <pre><code>def setattr_dot_notation(obj: Callable, attr: str, value: Any) -&gt; None:\n    \"\"\"\n    Sets an attribute on an object using dot notation.\n\n    Args:\n        obj: The object on which to set the attribute.\n        attr: The attribute name, which can use dot notation for nested attributes.\n        value: The value to set the attribute to.\n    \"\"\"\n    if \".\" not in attr:\n        if not hasattr(obj, attr):\n            raise AttributeError(f\"`{get_name(obj, True)}` has no attribute `{attr}`.\")\n        setattr(obj, attr, value)\n    # Solve recursively if the attribute is defined in dot-notation\n    else:\n        obj_name, attr = attr.split(\".\", maxsplit=1)\n        setattr_dot_notation(getattr(obj, obj_name), attr, value)\n</code></pre>"},{"location":"reference/utils/model/","title":"model","text":"<p>This module provides utility functions for manipulating PyTorch models, such as replacing layers or loading state_dicts.</p>"},{"location":"reference/utils/model/#lighter.utils.model.adjust_prefix_and_load_state_dict","title":"<code>adjust_prefix_and_load_state_dict(model, ckpt_path, ckpt_to_model_prefix=None, layers_to_ignore=None)</code>","text":"<p>This function loads a state dictionary from a checkpoint file into a model using <code>torch.load(strict=False)</code>. It supports remapping layer names between the checkpoint and model through the <code>ckpt_to_model_prefix</code> parameter.</p> <p>This is useful when loading weights from a model that was trained as part of a larger architecture, where the layer names may not match the standalone version of the model.</p> <p>Before using <code>ckpt_to_model_prefix</code>, it's recommended to: 1. Check the layer names in both the checkpoint and target model 2. Map the mismatched prefixes accordingly</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to load the state_dict into.</p> required <code>ckpt_path</code> <code>str</code> <p>The path to the checkpoint file.</p> required <code>ckpt_to_model_prefix</code> <code>dict[str, str] | None</code> <p>Mapping of checkpoint prefixes to model prefixes.</p> <code>None</code> <code>layers_to_ignore</code> <code>list[str] | None</code> <p>Layers to ignore when loading the state_dict.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Module</code> <code>Module</code> <p>The model with the loaded state_dict.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If there is no overlap between the checkpoint's and model's state_dict.</p> Source code in <code>src/lighter/utils/model.py</code> <pre><code>def adjust_prefix_and_load_state_dict(\n    model: Module,\n    ckpt_path: str,\n    ckpt_to_model_prefix: dict[str, str] | None = None,\n    layers_to_ignore: list[str] | None = None,\n) -&gt; Module:\n    \"\"\"\n    This function loads a state dictionary from a checkpoint file into a model using `torch.load(strict=False)`.\n    It supports remapping layer names between the checkpoint and model through the `ckpt_to_model_prefix` parameter.\n\n    This is useful when loading weights from a model that was trained as part of a larger architecture,\n    where the layer names may not match the standalone version of the model.\n\n    Before using `ckpt_to_model_prefix`, it's recommended to:\n    1. Check the layer names in both the checkpoint and target model\n    2. Map the mismatched prefixes accordingly\n\n    Args:\n        model: The model to load the state_dict into.\n        ckpt_path: The path to the checkpoint file.\n        ckpt_to_model_prefix: Mapping of checkpoint prefixes to model prefixes.\n        layers_to_ignore: Layers to ignore when loading the state_dict.\n\n    Returns:\n        Module: The model with the loaded state_dict.\n\n    Raises:\n        ValueError: If there is no overlap between the checkpoint's and model's state_dict.\n    \"\"\"\n    # Load checkpoint and handle if state_dict is nested.\n    ckpt = torch.load(ckpt_path)  # nosec B614\n    if \"state_dict\" in ckpt:\n        # System has a model attribute that contains the actual model, remove the \"model.\" prefix\n        ckpt = {key.replace(\"model.\", \"\"): value for key, value in ckpt[\"state_dict\"].items()}\n\n    # Adjust checkpoint keys based on prefix mapping\n    adjusted_ckpt = {}\n    if ckpt_to_model_prefix:\n        for ckpt_prefix, model_prefix in ckpt_to_model_prefix.items():\n            ckpt_prefix = f\"{ckpt_prefix}.\" if ckpt_prefix and not ckpt_prefix.endswith(\".\") else ckpt_prefix\n            model_prefix = f\"{model_prefix}.\" if model_prefix and not model_prefix.endswith(\".\") else model_prefix\n\n            if ckpt_prefix:\n                adjusted_ckpt.update(\n                    {key.replace(ckpt_prefix, model_prefix): value for key, value in ckpt.items() if ckpt_prefix in key}\n                )\n            else:\n                adjusted_ckpt.update({f\"{model_prefix}{key}\": value for key, value in ckpt.items()})\n\n        if not adjusted_ckpt:\n            adjusted_ckpt = ckpt\n    else:\n        adjusted_ckpt = ckpt\n\n    # Remove ignored layers if specified\n    if layers_to_ignore:\n        for layer in layers_to_ignore:\n            adjusted_ckpt.pop(layer)\n\n    # Verify overlap between model and checkpoint keys\n    model_keys = list(model.state_dict().keys())\n    ckpt_keys = list(adjusted_ckpt.keys())\n    if not set(model_keys) &amp; set(ckpt_keys):\n        raise ValueError(\n            \"There is no overlap between checkpoint's and model's state_dict.\"\n            f\"\\nModel keys: {model_keys[0] + ', ..., ' + model_keys[-1] if model_keys else '[]'}\"\n            f\"\\nCheckpoint keys: {ckpt_keys[0] + ', ..., ' + ckpt_keys[-1] if ckpt_keys else '[]'}\"\n        )\n    # Load state dict and handle incompatible keys\n    incompatible_keys = model.load_state_dict(adjusted_ckpt, strict=False)\n    if incompatible_keys.missing_keys or incompatible_keys.unexpected_keys:\n        logger.info(f\"Encountered incompatible keys during checkpoint loading. If intended, ignore.\\n{incompatible_keys}\")\n    else:\n        logger.info(\"Checkpoint loaded successfully.\")\n\n    return model\n</code></pre>"},{"location":"reference/utils/model/#lighter.utils.model.remove_n_last_layers_sequentially","title":"<code>remove_n_last_layers_sequentially(model, num_layers=1)</code>","text":"<p>Removes a specified number of layers from the end of a model and returns it as a Sequential model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module()</code> <p>The model to modify.</p> required <code>num_layers</code> <p>The number of layers to remove from the end.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>Sequential</code> <code>Sequential</code> <p>The modified model as a Sequential container.</p> Source code in <code>src/lighter/utils/model.py</code> <pre><code>def remove_n_last_layers_sequentially(model: Module(), num_layers=1) -&gt; Sequential:\n    \"\"\"\n    Removes a specified number of layers from the end of a model and returns it as a Sequential model.\n\n    Args:\n        model: The model to modify.\n        num_layers: The number of layers to remove from the end.\n\n    Returns:\n        Sequential: The modified model as a Sequential container.\n    \"\"\"\n    return Sequential(*list(model.children())[:-num_layers])\n</code></pre>"},{"location":"reference/utils/model/#lighter.utils.model.replace_layer_with","title":"<code>replace_layer_with(model, layer_name, new_layer)</code>","text":"<p>Replaces a specified layer in a PyTorch model with a new layer.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to modify.</p> required <code>layer_name</code> <code>str</code> <p>The name of the layer to replace, using dot notation if necessary (e.g. \"layer10.fc.weights\").</p> required <code>new_layer</code> <code>Module</code> <p>The new layer to insert.</p> required <p>Returns:</p> Name Type Description <code>Module</code> <code>Module</code> <p>The modified model with the new layer.</p> Source code in <code>src/lighter/utils/model.py</code> <pre><code>def replace_layer_with(model: Module, layer_name: str, new_layer: Module) -&gt; Module:\n    \"\"\"\n    Replaces a specified layer in a PyTorch model with a new layer.\n\n    Args:\n        model: The model to modify.\n        layer_name: The name of the layer to replace,\n            using dot notation if necessary (e.g. \"layer10.fc.weights\").\n        new_layer: The new layer to insert.\n\n    Returns:\n        Module: The modified model with the new layer.\n    \"\"\"\n    setattr_dot_notation(model, layer_name, new_layer)\n    return model\n</code></pre>"},{"location":"reference/utils/model/#lighter.utils.model.replace_layer_with_identity","title":"<code>replace_layer_with_identity(model, layer_name)</code>","text":"<p>Replaces a specified layer in a PyTorch model with an Identity layer.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>The model to modify.</p> required <code>layer_name</code> <code>str</code> <p>The name of the layer to replace with an Identity layer, using dot notation if necessary (e.g. \"layer10.fc.weights\").</p> required <p>Returns:</p> Name Type Description <code>Module</code> <code>Module</code> <p>The modified model with the Identity layer.</p> Source code in <code>src/lighter/utils/model.py</code> <pre><code>def replace_layer_with_identity(model: Module, layer_name: str) -&gt; Module:\n    \"\"\"\n    Replaces a specified layer in a PyTorch model with an Identity layer.\n\n    Args:\n        model: The model to modify.\n        layer_name: The name of the layer to replace with an Identity layer,\n            using dot notation if necessary (e.g. \"layer10.fc.weights\").\n\n    Returns:\n        Module: The modified model with the Identity layer.\n    \"\"\"\n    return replace_layer_with(model, layer_name, Identity())\n</code></pre>"},{"location":"reference/utils/patches/","title":"patches","text":"<p>Contains code that patches certain issues from other libraries that we expect will be resolved in the future.</p>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict","title":"<code>PatchedModuleDict</code>","text":"<p>               Bases: <code>ModuleDict</code></p> <p>This class provides a workaround for key conflicts in PyTorch's ModuleDict by ensuring unique internal keys.</p> Source code in <code>src/lighter/utils/patches.py</code> <pre><code>class PatchedModuleDict(ModuleDict):\n    \"\"\"\n    This class provides a workaround for key conflicts in PyTorch's ModuleDict by ensuring unique internal keys.\n    \"\"\"\n\n    # https://github.com/pytorch/pytorch/issues/71203\n    def __init__(self, modules=None):\n        \"\"\"\n        Initializes the PatchedModuleDict with optional modules.\n\n        Args:\n            modules (dict, optional): A dictionary of modules to initialize the ModuleDict.\n        \"\"\"\n        self._key_map = {}\n        super().__init__(modules)\n\n    def __setitem__(self, key, module):\n        \"\"\"\n        Sets the module for the given key, ensuring a unique internal key.\n\n        Args:\n            key (str): The key to associate with the module.\n            module (torch.nn.Module): The module to store.\n        \"\"\"\n        internal_key = f\"_{key}\"\n        while internal_key in self._modules:\n            internal_key = f\"_{internal_key}\"\n        self._key_map[key] = internal_key\n        super().__setitem__(internal_key, module)\n\n    def __getitem__(self, key):\n        \"\"\"\n        Retrieves the module associated with the given key.\n\n        Args:\n            key (str): The key for which to retrieve the module.\n\n        Returns:\n            torch.nn.Module: The module associated with the key.\n        \"\"\"\n        internal_key = self._key_map.get(key, key)\n        return super().__getitem__(internal_key)\n\n    def __delitem__(self, key):\n        \"\"\"\n        Deletes the module associated with the given key.\n\n        Args:\n            key (str): The key for which to delete the module.\n        \"\"\"\n        internal_key = self._key_map.pop(key, key)\n        super().__delitem__(internal_key)\n\n    def __contains__(self, key):\n        \"\"\"\n        Checks if a module is associated with the given key.\n\n        Args:\n            key (str): The key to check.\n\n        Returns:\n            bool: True if the key exists, False otherwise.\n        \"\"\"\n        internal_key = self._key_map.get(key, key)\n        return super().__contains__(internal_key)\n\n    def keys(self):\n        \"\"\"\n        Returns the keys of the modules.\n\n        Returns:\n            KeysView: A view of the keys in the dictionary.\n        \"\"\"\n        return self._key_map.keys()\n\n    def items(self):\n        \"\"\"\n        Returns the items (key, module) in the dictionary.\n\n        Returns:\n            Generator: A generator yielding key, module pairs.\n        \"\"\"\n        return ((key, self._modules[internal_key]) for key, internal_key in self._key_map.items())\n\n    def values(self):\n        \"\"\"\n        Returns the modules in the dictionary.\n\n        Returns:\n            Generator: A generator yielding modules.\n        \"\"\"\n        return (self._modules[internal_key] for internal_key in self._key_map.values())\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.__contains__","title":"<code>__contains__(key)</code>","text":"<p>Checks if a module is associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the key exists, False otherwise.</p> Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def __contains__(self, key):\n    \"\"\"\n    Checks if a module is associated with the given key.\n\n    Args:\n        key (str): The key to check.\n\n    Returns:\n        bool: True if the key exists, False otherwise.\n    \"\"\"\n    internal_key = self._key_map.get(key, key)\n    return super().__contains__(internal_key)\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.__delitem__","title":"<code>__delitem__(key)</code>","text":"<p>Deletes the module associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key for which to delete the module.</p> required Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def __delitem__(self, key):\n    \"\"\"\n    Deletes the module associated with the given key.\n\n    Args:\n        key (str): The key for which to delete the module.\n    \"\"\"\n    internal_key = self._key_map.pop(key, key)\n    super().__delitem__(internal_key)\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.__getitem__","title":"<code>__getitem__(key)</code>","text":"<p>Retrieves the module associated with the given key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key for which to retrieve the module.</p> required <p>Returns:</p> Type Description <p>torch.nn.Module: The module associated with the key.</p> Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def __getitem__(self, key):\n    \"\"\"\n    Retrieves the module associated with the given key.\n\n    Args:\n        key (str): The key for which to retrieve the module.\n\n    Returns:\n        torch.nn.Module: The module associated with the key.\n    \"\"\"\n    internal_key = self._key_map.get(key, key)\n    return super().__getitem__(internal_key)\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.__init__","title":"<code>__init__(modules=None)</code>","text":"<p>Initializes the PatchedModuleDict with optional modules.</p> <p>Parameters:</p> Name Type Description Default <code>modules</code> <code>dict</code> <p>A dictionary of modules to initialize the ModuleDict.</p> <code>None</code> Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def __init__(self, modules=None):\n    \"\"\"\n    Initializes the PatchedModuleDict with optional modules.\n\n    Args:\n        modules (dict, optional): A dictionary of modules to initialize the ModuleDict.\n    \"\"\"\n    self._key_map = {}\n    super().__init__(modules)\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.__setitem__","title":"<code>__setitem__(key, module)</code>","text":"<p>Sets the module for the given key, ensuring a unique internal key.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to associate with the module.</p> required <code>module</code> <code>Module</code> <p>The module to store.</p> required Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def __setitem__(self, key, module):\n    \"\"\"\n    Sets the module for the given key, ensuring a unique internal key.\n\n    Args:\n        key (str): The key to associate with the module.\n        module (torch.nn.Module): The module to store.\n    \"\"\"\n    internal_key = f\"_{key}\"\n    while internal_key in self._modules:\n        internal_key = f\"_{internal_key}\"\n    self._key_map[key] = internal_key\n    super().__setitem__(internal_key, module)\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.items","title":"<code>items()</code>","text":"<p>Returns the items (key, module) in the dictionary.</p> <p>Returns:</p> Name Type Description <code>Generator</code> <p>A generator yielding key, module pairs.</p> Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def items(self):\n    \"\"\"\n    Returns the items (key, module) in the dictionary.\n\n    Returns:\n        Generator: A generator yielding key, module pairs.\n    \"\"\"\n    return ((key, self._modules[internal_key]) for key, internal_key in self._key_map.items())\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.keys","title":"<code>keys()</code>","text":"<p>Returns the keys of the modules.</p> <p>Returns:</p> Name Type Description <code>KeysView</code> <p>A view of the keys in the dictionary.</p> Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def keys(self):\n    \"\"\"\n    Returns the keys of the modules.\n\n    Returns:\n        KeysView: A view of the keys in the dictionary.\n    \"\"\"\n    return self._key_map.keys()\n</code></pre>"},{"location":"reference/utils/patches/#lighter.utils.patches.PatchedModuleDict.values","title":"<code>values()</code>","text":"<p>Returns the modules in the dictionary.</p> <p>Returns:</p> Name Type Description <code>Generator</code> <p>A generator yielding modules.</p> Source code in <code>src/lighter/utils/patches.py</code> <pre><code>def values(self):\n    \"\"\"\n    Returns the modules in the dictionary.\n\n    Returns:\n        Generator: A generator yielding modules.\n    \"\"\"\n    return (self._modules[internal_key] for internal_key in self._key_map.values())\n</code></pre>"},{"location":"reference/utils/types/","title":"types","text":"<ul> <li>containers</li> <li>enums</li> </ul>"},{"location":"reference/utils/types/containers/","title":"containers","text":""},{"location":"reference/utils/types/containers/#lighter.utils.types.containers.Adapters","title":"<code>Adapters</code>  <code>dataclass</code>","text":"<p>Root configuration class for all adapters across different modes.</p> Source code in <code>src/lighter/utils/types/containers.py</code> <pre><code>@nested\n@dataclass\nclass Adapters:\n    \"\"\"Root configuration class for all adapters across different modes.\"\"\"\n\n    train: Train = field(default_factory=Train)\n    val: Val = field(default_factory=Val)\n    test: Test = field(default_factory=Test)\n    predict: Predict = field(default_factory=Predict)\n</code></pre>"},{"location":"reference/utils/types/containers/#lighter.utils.types.containers.Predict","title":"<code>Predict</code>  <code>dataclass</code>","text":"<p>Predict mode sub-dataclass for Adapters.</p> Source code in <code>src/lighter/utils/types/containers.py</code> <pre><code>@dataclass\nclass Predict:\n    \"\"\"Predict mode sub-dataclass for Adapters.\"\"\"\n\n    batch: BatchAdapter = field(default_factory=lambda: BatchAdapter(input_accessor=lambda batch: batch))\n    logging: LoggingAdapter = field(default_factory=LoggingAdapter)\n</code></pre>"},{"location":"reference/utils/types/containers/#lighter.utils.types.containers.Test","title":"<code>Test</code>  <code>dataclass</code>","text":"<p>Test mode sub-dataclass for Adapters.</p> Source code in <code>src/lighter/utils/types/containers.py</code> <pre><code>@dataclass\nclass Test:\n    \"\"\"Test mode sub-dataclass for Adapters.\"\"\"\n\n    batch: BatchAdapter = field(default_factory=lambda: BatchAdapter(input_accessor=0, target_accessor=1))\n    metrics: MetricsAdapter = field(default_factory=lambda: MetricsAdapter(pred_argument=0, target_argument=1))\n    logging: LoggingAdapter = field(default_factory=LoggingAdapter)\n</code></pre>"},{"location":"reference/utils/types/containers/#lighter.utils.types.containers.Train","title":"<code>Train</code>  <code>dataclass</code>","text":"<p>Train mode sub-dataclass for Adapters.</p> Source code in <code>src/lighter/utils/types/containers.py</code> <pre><code>@dataclass\nclass Train:\n    \"\"\"Train mode sub-dataclass for Adapters.\"\"\"\n\n    batch: BatchAdapter = field(default_factory=lambda: BatchAdapter(input_accessor=0, target_accessor=1))\n    criterion: CriterionAdapter = field(default_factory=lambda: CriterionAdapter(pred_argument=0, target_argument=1))\n    metrics: MetricsAdapter = field(default_factory=lambda: MetricsAdapter(pred_argument=0, target_argument=1))\n    logging: LoggingAdapter = field(default_factory=LoggingAdapter)\n</code></pre>"},{"location":"reference/utils/types/containers/#lighter.utils.types.containers.Val","title":"<code>Val</code>  <code>dataclass</code>","text":"<p>Val mode sub-dataclass for Adapters.</p> Source code in <code>src/lighter/utils/types/containers.py</code> <pre><code>@dataclass\nclass Val:\n    \"\"\"Val mode sub-dataclass for Adapters.\"\"\"\n\n    batch: BatchAdapter = field(default_factory=lambda: BatchAdapter(input_accessor=0, target_accessor=1))\n    criterion: CriterionAdapter = field(default_factory=lambda: CriterionAdapter(pred_argument=0, target_argument=1))\n    metrics: MetricsAdapter = field(default_factory=lambda: MetricsAdapter(pred_argument=0, target_argument=1))\n    logging: LoggingAdapter = field(default_factory=LoggingAdapter)\n</code></pre>"},{"location":"reference/utils/types/containers/#lighter.utils.types.containers.nested","title":"<code>nested(cls)</code>","text":"<p>Decorator to handle nested dataclass creation. Example:     <pre><code>@nested\n@dataclass\nclass Example:\n    ...\n</code></pre></p> Source code in <code>src/lighter/utils/types/containers.py</code> <pre><code>def nested(cls):\n    \"\"\"\n    Decorator to handle nested dataclass creation.\n    Example:\n        ```\n        @nested\n        @dataclass\n        class Example:\n            ...\n        ```\n    \"\"\"\n    original_init = cls.__init__\n\n    def __init__(self, *args, **kwargs):\n        for f in fields(cls):\n            if is_dataclass(f.type) and f.name in kwargs:\n                kwargs[f.name] = f.type(**kwargs[f.name])\n        original_init(self, *args, **kwargs)\n\n    cls.__init__ = __init__\n    return cls\n</code></pre>"},{"location":"reference/utils/types/enums/","title":"enums","text":""},{"location":"reference/utils/types/enums/#lighter.utils.types.enums.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum class that inherits from str. This allows for the enum values to be accessed as strings.</p> Source code in <code>src/lighter/utils/types/enums.py</code> <pre><code>class StrEnum(str, Enum):\n    \"\"\"\n    Enum class that inherits from str. This allows for the enum values to be accessed as strings.\n    \"\"\"\n\n    # Remove this class when Python 3.10 support is dropped, as Python &gt;=3.11 has StrEnum built-in.\n    def __str__(self) -&gt; str:\n        return str(self.value)\n</code></pre>"},{"location":"tutorials/get-started/","title":"Get Started with Lighter","text":"<p>This guide takes you from installation to running experiments in 15 minutes, using proper project structure from the start.</p>"},{"location":"tutorials/get-started/#installation","title":"Installation","text":"<pre><code>pip install lighter\n</code></pre>"},{"location":"tutorials/get-started/#the-core-idea","title":"The Core Idea","text":"<p>Traditional PyTorch Lightning requires writing training loops:</p> <pre><code>class MyModule(LightningModule):\n    def __init__(self):\n        self.model = Model()\n        self.criterion = nn.CrossEntropyLoss()\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        pred = self.model(x)\n        loss = self.criterion(pred, y)\n        return loss\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.model.parameters(), lr=0.001)\n\ntrainer = Trainer(max_epochs=10)\ntrainer.fit(module, train_loader, val_loader)\n</code></pre> <p>Lighter replaces this with configuration:</p> <pre><code>trainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 10\n\nsystem:\n  _target_: lighter.System\n  model:\n    _target_: MyModel\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n  dataloaders:\n    train: ...\n    val: ...\n</code></pre> <pre><code>lighter fit config.yaml\n</code></pre>"},{"location":"tutorials/get-started/#step-1-create-your-project","title":"Step 1: Create Your Project","text":"<p>Set up a proper project structure (this will pay off as you add experiments):</p> <pre><code>mkdir -p my_experiments/experiments\ncd my_experiments\ntouch __init__.py\n</code></pre> <p>Your project structure: <pre><code>my_experiments/\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 experiments/\n    \u2514\u2500\u2500 (configs will go here)\n</code></pre></p>"},{"location":"tutorials/get-started/#step-2-minimal-example","title":"Step 2: Minimal Example","text":"<p>Create <code>experiments/minimal.yaml</code>:</p> <pre><code>project: .  # Import from my_experiments/\n\ntrainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 3\n\nsystem:\n  _target_: lighter.System\n\n  model:\n    _target_: torch.nn.Linear\n    in_features: 784  # MNIST: 28x28 flattened\n    out_features: 10  # 10 digits\n\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n\n  dataloaders:\n    train:\n      _target_: torch.utils.data.DataLoader\n      batch_size: 64\n      dataset:\n        _target_: torchvision.datasets.MNIST\n        root: ./data\n        train: true\n        download: true\n        transform:\n          _target_: torchvision.transforms.Compose\n          transforms:\n            - _target_: torchvision.transforms.ToTensor\n            - _target_: torchvision.transforms.Lambda\n              lambd: \"$lambda x: x.view(-1)\"  # Flatten to 784\n</code></pre> <p>Run it:</p> <pre><code>lighter fit experiments/minimal.yaml\n</code></pre> <p>You just trained a neural network using only YAML configuration.</p>"},{"location":"tutorials/get-started/#step-3-real-example-cifar-10","title":"Step 3: Real Example (CIFAR-10)","text":"<p>Create <code>experiments/cifar10.yaml</code>:</p> <pre><code>project: .\n\ntrainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 10\n  accelerator: auto\n\nsystem:\n  _target_: lighter.System\n\n  model:\n    _target_: torchvision.models.resnet18\n    num_classes: 10\n\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n\n  metrics:\n    train:\n      - _target_: torchmetrics.Accuracy\n        task: multiclass\n        num_classes: 10\n    val: \"%system::metrics::train\"  # Reuse train metrics\n\n  dataloaders:\n    train:\n      _target_: torch.utils.data.DataLoader\n      batch_size: 128\n      shuffle: true\n      num_workers: 4\n      dataset:\n        _target_: torchvision.datasets.CIFAR10\n        root: ./data\n        train: true\n        download: true\n        transform:\n          _target_: torchvision.transforms.Compose\n          transforms:\n            - _target_: torchvision.transforms.RandomHorizontalFlip\n            - _target_: torchvision.transforms.RandomCrop\n              size: 32\n              padding: 4\n            - _target_: torchvision.transforms.ToTensor\n            - _target_: torchvision.transforms.Normalize\n              mean: [0.4914, 0.4822, 0.4465]\n              std: [0.2470, 0.2435, 0.2616]\n\n    val:\n      _target_: torch.utils.data.DataLoader\n      batch_size: 256\n      num_workers: 4\n      dataset:\n        _target_: torchvision.datasets.CIFAR10\n        root: ./data\n        train: false\n        download: true\n        transform:\n          _target_: torchvision.transforms.Compose\n          transforms:\n            - _target_: torchvision.transforms.ToTensor\n            - _target_: torchvision.transforms.Normalize\n              mean: [0.4914, 0.4822, 0.4465]\n              std: [0.2470, 0.2435, 0.2616]\n</code></pre> <p>Run it:</p> <pre><code>lighter fit experiments/cifar10.yaml\n</code></pre> <p>You now have automatic: - Training and validation loops - Metrics computation and logging - Loss tracking - Checkpointing</p>"},{"location":"tutorials/get-started/#step-4-add-custom-models","title":"Step 4: Add Custom Models","text":"<p>Now here's why we set up a proper project structure. Let's add a custom CNN.</p> <p>Create <code>models/__init__.py</code> and <code>models/simple_cnn.py</code>:</p> <pre><code>mkdir models\ntouch models/__init__.py\n</code></pre> models/simple_cnn.py<pre><code>import torch.nn as nn\n\nclass SimpleCNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(2)\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n        self.fc = nn.Linear(64 * 8 * 8, num_classes)\n\n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1(x)))\n        x = self.pool(self.relu(self.conv2(x)))\n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n</code></pre> <p>Your project now looks like: <pre><code>my_experiments/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 experiments/\n\u2502   \u251c\u2500\u2500 minimal.yaml\n\u2502   \u2514\u2500\u2500 cifar10.yaml\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 simple_cnn.py\n\u2514\u2500\u2500 data/               # Created by datasets\n</code></pre></p> <p>Create <code>experiments/custom_model.yaml</code>:</p> <pre><code>project: .  # This imports my_experiments/\n\ntrainer:\n  _target_: pytorch_lightning.Trainer\n  max_epochs: 10\n\nsystem:\n  _target_: lighter.System\n\n  model:\n    _target_: models.simple_cnn.SimpleCNN  # Your custom model!\n    num_classes: 10\n\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n\n  dataloaders:\n    train:\n      _target_: torch.utils.data.DataLoader\n      batch_size: 128\n      shuffle: true\n      dataset:\n        _target_: torchvision.datasets.CIFAR10\n        root: ./data\n        train: true\n        download: true\n        transform:\n          _target_: torchvision.transforms.ToTensor\n</code></pre> <p>Run it:</p> <pre><code>lighter fit experiments/custom_model.yaml\n</code></pre> <p>This is the key insight: By setting up proper structure from the start, adding custom components is natural, not a separate concept to learn.</p>"},{"location":"tutorials/get-started/#understanding-the-syntax","title":"Understanding the Syntax","text":"<p>Lighter uses Sparkwheel for configuration. Here are the essentials:</p>"},{"location":"tutorials/get-started/#_target_-instantiate-a-class","title":"<code>_target_:</code> Instantiate a Class","text":"<pre><code>model:\n  _target_: torch.nn.Linear\n  in_features: 784\n  out_features: 10\n</code></pre> <p>Equivalent to: <code>model = torch.nn.Linear(in_features=784, out_features=10)</code></p> <p>Works with any Python class\u2014PyTorch, third-party, or your custom code.</p>"},{"location":"tutorials/get-started/#project-import-custom-modules","title":"<code>project:</code> Import Custom Modules","text":"<pre><code>project: .  # Import from current directory as a Python module\n</code></pre> <p>This makes <code>models/</code>, <code>datasets/</code>, <code>transforms/</code> etc. importable via <code>_target_</code>.</p>"},{"location":"tutorials/get-started/#evaluate-python-expression","title":"<code>$</code> Evaluate Python Expression","text":"<pre><code>optimizer:\n  lr: \"$0.001 * 2\"  # Evaluates to 0.002\n</code></pre>"},{"location":"tutorials/get-started/#resolved-reference","title":"<code>@</code> Resolved Reference","text":"<pre><code>optimizer:\n  params: \"$@system::model.parameters()\"  # Gets actual model instance, calls parameters()\n</code></pre> <p>Gets the instantiated object (after <code>_target_</code> processing).</p>"},{"location":"tutorials/get-started/#raw-reference","title":"<code>%</code> Raw Reference","text":"<pre><code>metrics:\n  train:\n    - _target_: torchmetrics.Accuracy\n      task: multiclass\n      num_classes: 10\n  val: \"%system::metrics::train\"  # Gets raw YAML, creates new instance\n</code></pre> <p>Gets the unprocessed YAML configuration (before instantiation).</p>"},{"location":"tutorials/get-started/#path-notation","title":"<code>::</code> Path Notation","text":"<pre><code>system::model         # Navigate to model definition\nsystem::optimizer::lr # Navigate to nested value\n</code></pre> <p>Navigate nested config with <code>::</code> separator\u2014more concise than <code>[\"system\"][\"model\"]</code>.</p> <p>Learn More</p> <p>For complete Sparkwheel documentation including advanced features, see Sparkwheel docs.</p>"},{"location":"tutorials/get-started/#cli-overrides","title":"CLI Overrides","text":"<p>Change hyperparameters without editing files:</p> <pre><code># Change learning rate\nlighter fit experiments/cifar10.yaml system::optimizer::lr=0.01\n\n# Train longer\nlighter fit experiments/cifar10.yaml trainer::max_epochs=100\n\n# Use multiple GPUs\nlighter fit experiments/cifar10.yaml trainer::devices=2\n\n# Combine multiple overrides\nlighter fit experiments/cifar10.yaml \\\n  trainer::max_epochs=100 \\\n  system::optimizer::lr=0.001 \\\n  trainer::devices=4\n</code></pre>"},{"location":"tutorials/get-started/#organizing-multiple-experiments","title":"Organizing Multiple Experiments","text":"<p>As your project grows, organize configs by purpose:</p> <pre><code>my_experiments/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 experiments/\n\u2502   \u251c\u2500\u2500 baselines/\n\u2502   \u2502   \u251c\u2500\u2500 resnet18.yaml\n\u2502   \u2502   \u2514\u2500\u2500 resnet50.yaml\n\u2502   \u251c\u2500\u2500 ablations/\n\u2502   \u2502   \u251c\u2500\u2500 no_augmentation.yaml\n\u2502   \u2502   \u2514\u2500\u2500 different_optimizer.yaml\n\u2502   \u2514\u2500\u2500 production/\n\u2502       \u2514\u2500\u2500 final_model.yaml\n\u251c\u2500\u2500 models/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 simple_cnn.py\n\u2514\u2500\u2500 datasets/           # Add custom datasets here\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 my_dataset.py\n</code></pre>"},{"location":"tutorials/get-started/#merging-configs","title":"Merging Configs","text":"<p>Create reusable config components:</p> experiments/base.yaml<pre><code>project: .\n\ntrainer:\n  _target_: pytorch_lightning.Trainer\n  accelerator: auto\n\nsystem:\n  _target_: lighter.System\n  criterion:\n    _target_: torch.nn.CrossEntropyLoss\n</code></pre> experiments/resnet18.yaml<pre><code>system:\n  model:\n    _target_: torchvision.models.resnet18\n    num_classes: 10\n  optimizer:\n    _target_: torch.optim.Adam\n    params: \"$@system::model.parameters()\"\n    lr: 0.001\n</code></pre> <p>Combine them:</p> <pre><code>lighter fit experiments/base.yaml,experiments/resnet18.yaml\n</code></pre> <p>Later configs override earlier ones, enabling modular experiment design.</p>"},{"location":"tutorials/get-started/#testing-and-prediction","title":"Testing and Prediction","text":"<pre><code># Test trained model\nlighter test experiments/cifar10.yaml args::test::ckpt_path=checkpoints/best.ckpt\n\n# Generate predictions\nlighter predict experiments/cifar10.yaml args::predict::ckpt_path=checkpoints/best.ckpt\n</code></pre>"},{"location":"tutorials/get-started/#when-you-need-adapters","title":"When You Need Adapters","text":"<p>Your dataset returns a dict but your model needs tensors? Use adapters:</p> <pre><code>system:\n  adapters:\n    train:\n      batch:\n        _target_: lighter.adapters.BatchAdapter\n        input_accessor: \"image\"  # Extract from dict\n        target_accessor: \"label\"\n</code></pre> <p>Your loss expects <code>(target, pred)</code> instead of <code>(pred, target)</code>? Swap them:</p> <pre><code>system:\n  adapters:\n    train:\n      criterion:\n        _target_: lighter.adapters.CriterionAdapter\n        pred_argument: 1\n        target_argument: 0\n</code></pre> <p>Adapters make Lighter task-agnostic\u2014they connect any data format to any model/loss/metric.</p> <p>Learn more about adapters \u2192</p>"},{"location":"tutorials/get-started/#continue-learning","title":"Continue Learning","text":"<ul> <li>Configuration Guide - Complete syntax reference</li> <li>Adapters - Handle any data format</li> <li>Recipes - Ready-to-use patterns</li> <li>Architecture - How Lighter works internally</li> </ul>"},{"location":"tutorials/get-started/#quick-reference","title":"Quick Reference","text":"<pre><code># Essential Sparkwheel syntax\nproject: .                          # Import custom modules\n_target_: module.ClassName          # Instantiate class\n$expression                         # Evaluate Python expression\n@path::to::object                   # Resolved reference (instantiated object)\n%path::to::config                   # Raw reference (unprocessed YAML)\npath::nested::key                   # Path notation (navigate config)\n::sibling::key                      # Relative reference (sibling in same section)\n=key:                               # Replace operator (override default merge)\n~key: null                          # Delete entire key\n~key::1: null                       # Delete single list item\n~key: [0, 2]                        # Delete multiple items (batch syntax)\n\n# Lighter CLI commands\nlighter fit experiments/config.yaml             # Train\nlighter validate experiments/config.yaml        # Validate\nlighter test experiments/config.yaml            # Test\nlighter predict experiments/config.yaml         # Predict\n\n# Override from CLI\nlighter fit experiments/cfg.yaml key::path=value\n\n# Merge configs (automatic by default)\nlighter fit experiments/base.yaml,experiments/exp.yaml\n</code></pre>"},{"location":"tutorials/get-started/#project-structure","title":"Project Structure","text":"<pre><code>my_experiments/\n\u251c\u2500\u2500 __init__.py                # Make it a module\n\u251c\u2500\u2500 experiments/               # All configs here\n\u2502   \u251c\u2500\u2500 base.yaml\n\u2502   \u251c\u2500\u2500 exp1.yaml\n\u2502   \u2514\u2500\u2500 exp2.yaml\n\u251c\u2500\u2500 models/                    # Custom models\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 my_model.py\n\u251c\u2500\u2500 datasets/                  # Custom datasets\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 my_dataset.py\n\u2514\u2500\u2500 transforms/                # Custom transforms\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 my_transform.py\n</code></pre>"},{"location":"tutorials/get-started/#getting-help","title":"Getting Help","text":"<ul> <li>Stuck? Troubleshooting Guide</li> <li>Questions? FAQ</li> <li>Coming from Lightning? Migration Guide</li> <li>Community? Discord</li> </ul>"},{"location":"tutorials/get-started/#complete-example","title":"Complete Example","text":"<p>See full examples with this structure in the repository's projects directory.</p>"}]}